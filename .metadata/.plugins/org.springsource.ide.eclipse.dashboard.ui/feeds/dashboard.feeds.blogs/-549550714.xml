<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Spring</title>
  <link rel="alternate" href="https://spring.io/blog" />
  <link rel="self" href="https://spring.io/blog.atom" />
  <id>http://spring.io/blog.atom</id>
  <icon>https://spring.io/favicon.ico</icon>
  <updated>2021-01-06T00:00:00Z</updated>
  <entry>
    <title>YMNNALFT: Reactive Dataflow with Project Reactor</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/06/ymnnalft-reactive-dataflow-with-project-reactor" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-30:4317</id>
    <updated>2021-01-06T00:00:00Z</updated>
    <content type="html">&lt;p&gt;Welcome to another installment of &lt;em&gt;You May Not Need Another Library For That&lt;/em&gt; (YMNNALFT)! I&amp;rsquo;ve spent a lot of time since 2016 illuminating (or trying to, anyway!) some of the more enormous opportunities in the Spring ecosystem in &lt;a href="http://bit.ly/spring-tips-playlist"&gt;my Spring Tips videos&lt;/a&gt;. Today, however, I come to you in a different spirit, wanting to focus on the little, sometimes hidden, gems that do fantastic things and that might spare you an additional third-party dependency and its implied complexity. &lt;/p&gt;
&lt;p&gt;And it&amp;rsquo;s a good thing we&amp;rsquo;re covering some of these complexity-reducing gems, too, you see, because the world is a confusing, complex, and dizzying place, and nowhere is that more evident than in the world of reactive data stream composition. Life comes at you fast and data, even more so. Data originates from everything (network services, databases, in-memory computation, threaded code, etc.). Data comes in many different sizes and shapes (one record, ten records, infinite records, etc.). Data comes in different volumes, starving or overwhelming its consumers. Data arrives at different cadences and times: now, later, all at once, periodically, etc. It&amp;rsquo;s much more natural to talk about data that&amp;rsquo;s already in memory, in hand, so to speak, than data that hasn&amp;rsquo;t yet materialized. And it&amp;rsquo;s more natural to talk about data in the single-threaded case than to deal with it in the concurrent case. &lt;/p&gt;
&lt;img src = "https://media1.tenor.com/images/e6494f3096cf60a3832e0775936bf9cb/tenor.gif" /&gt;
&lt;p&gt;It&amp;rsquo;s confusing to think about! Historically, it&amp;rsquo;s been even more tedious to address the different data dimensions in code. That is, until reactive programming.&lt;/p&gt;
&lt;p&gt;Reactive programming offers a unified world view, allowing us to think about the messy world of (potentially asynchronous and potentially concurrent) integration in terms of an easy to use DSL with operators. The operators support the definition and composition of reactive stream data flow pipelines. Reactive programming offers a structured concurrency paradigm, greatly simplifying writing safe, scalable, resource-efficient code. &lt;/p&gt;
&lt;p&gt;There are some great libraries out there (like &lt;a href="https://github.com/ReactiveX/RxJava"&gt;RxJava&lt;/a&gt; and &lt;a href="https://doc.akka.io/docs/akka/current/stream/index.html"&gt;Akka Streams&lt;/a&gt;) that work in much the same way. If you haven&amp;rsquo;t got a particular one in mind but want a world-class option and are already using Spring, then you might as well use &lt;a href="http://ProjectReactor.io"&gt;Project Reactor&lt;/a&gt;. It&amp;rsquo;s included in the box!&lt;/p&gt;
&lt;p&gt;The Spring team developed Project Reactor to support the reactive efforts in the Spring ecosystem. You don&amp;rsquo;t need Spring to use Project Reactor, but all the reactive APIs in the Spring ecosystem build on Project Reactor for the dataflow options. Microsoft &lt;a href="https://azure.github.io/azure-sdk/java_introduction.html#async-service-clients"&gt;mandates&lt;/a&gt; that all their SDK clients and APIs be created using &lt;a href="https://devblogs.microsoft.com/azure-sdk/async-programming-with-project-reactor/"&gt;Project Reactor&lt;/a&gt;. &lt;a href="https://github.com/rsocket/rsocket-java"&gt;Facebook&lt;/a&gt; developed the Java client for their RSocket protocol using Project Reactor. Project Reactor is mature - it&amp;rsquo;s been around since 2010! - but growing new features all the time. If you&amp;rsquo;re &lt;em&gt;still&lt;/em&gt; not getting what you need, it works flawlessly with other reactive data flow libraries through the interoperable &lt;a href="http://www.reactive-streams.org/"&gt;Reactive Streams&lt;/a&gt; types. &lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s look at an example of how Project Reactor makes short work of the composition of different data flow sources and sinks and all but eliminates any manual threading code. This is a &lt;em&gt;huge&lt;/em&gt; win. Remember: only one person &lt;em&gt;truly&lt;/em&gt; understands how to write safe, useful, multithreaded Java code&amp;hellip;. and it&amp;rsquo;s &lt;em&gt;not&lt;/em&gt; you! I don&amp;rsquo;t know &lt;em&gt;who&lt;/em&gt; it is. It doesn&amp;rsquo;t matter. Don&amp;rsquo;t tempt fate; let Project Reactor help. &lt;/p&gt;
&lt;p&gt;You&amp;rsquo;ll need the following dependencies. &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Reactive Web on &lt;a href="http://start.spring.io"&gt;the Spring Initializr&lt;/a&gt; - &lt;code&gt;org.springframework.boot&lt;/code&gt; : &lt;code&gt;spring-boot-starter-webflux&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now, let&amp;rsquo;s look at a sample. This example demonstrates how easy it is to normalize processing given disparate kinds of data. In this example, we look at a Java 8 &lt;code&gt;java.util.Stream&amp;lt;T?&amp;gt;&lt;/code&gt; and a &lt;code&gt;CompletableFuture&amp;lt;T&amp;gt;&lt;/code&gt;, but the sky&amp;rsquo;s the limit. In most reactive applications, you won&amp;rsquo;t necessarily be in the business of converting non-reactive types to reactive types (like &lt;code&gt;Flux&amp;lt;T&amp;gt;&lt;/code&gt; or &lt;code&gt;Mono&amp;lt;T&amp;gt;&lt;/code&gt;). Those examples would be even more straightforward. This example assumes that you&amp;rsquo;ve got two data sources and need to compose them. &lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;package bootiful.rx;&#xD;
&#xD;
import org.springframework.boot.SpringApplication;&#xD;
import org.springframework.boot.autoconfigure.SpringBootApplication;&#xD;
import org.springframework.boot.context.event.ApplicationReadyEvent;&#xD;
import org.springframework.context.ApplicationListener;&#xD;
import org.springframework.context.annotation.Bean;&#xD;
import reactor.core.publisher.Flux;&#xD;
import reactor.core.publisher.Mono;&#xD;
&#xD;
import java.util.concurrent.CompletableFuture;&#xD;
import java.util.stream.Stream;&#xD;
&#xD;
@SpringBootApplication&#xD;
public class BootifulApplication {&#xD;
&#xD;
	CompletableFuture&amp;lt;String&amp;gt; returnCompletableFuture(int counter) {&#xD;
		return CompletableFuture.supplyAsync(() -&amp;gt; {&#xD;
			var start = System.currentTimeMillis();&#xD;
			try {&#xD;
				Thread.sleep((long) (Math.max((Math.random() * 10), 5) * 1000));&#xD;
			}&#xD;
			catch (InterruptedException e) {&#xD;
				// threads smdh&#xD;
			}&#xD;
			var stop = System.currentTimeMillis();&#xD;
			var delta = stop - start;&#xD;
			return &amp;quot;(&amp;quot; + Thread.currentThread().getName() + &amp;quot;) Hello, #&amp;quot; + counter + &amp;quot;! (after &amp;quot; + delta + &amp;quot; ms.)&amp;quot;;&#xD;
		});&#xD;
	}&#xD;
&#xD;
	Stream&amp;lt;Integer&amp;gt; returnStream() {&#xD;
		return Stream.iterate(0, integer -&amp;gt; integer + 1);&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	ApplicationListener&amp;lt;ApplicationReadyEvent&amp;gt; begin() {&#xD;
		return event -&amp;gt; {&#xD;
&#xD;
			Flux&amp;lt;String&amp;gt; count = Flux//&#xD;
					.fromStream(this.returnStream()) //&#xD;
					.take(10) //&#xD;
					.flatMap(c -&amp;gt; Flux.zip(Mono.just(c), Mono.fromCompletionStage(this.returnCompletableFuture(c)))) //&#xD;
					.map(tuple -&amp;gt; tuple.getT2() + &amp;quot; #&amp;quot; + tuple.getT1()); //&#xD;
&#xD;
			count.subscribe(System.out::println);&#xD;
		};&#xD;
	}&#xD;
&#xD;
	public static void main(String[] args) {&#xD;
		SpringApplication.run(BootifulApplication.class, args);&#xD;
	}&#xD;
&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Do you know what else you get with Reactor? Operators supporting retries, error handling, timeouts, etc., all of which you would also farm out to yet another third-party library if they weren&amp;rsquo;t included in Project Reactor. Win-win. &lt;/p&gt;
&lt;p&gt;I could go on and on about the opportunities that present themselves given something like Project Reactor. Indeed, I &lt;em&gt;did&lt;/em&gt;. Check out my book &lt;a href="http://ReactiveSpring.io"&gt;&lt;em&gt;Reactive Spring&lt;/em&gt;&lt;/a&gt; for (a lot) more. &lt;/p&gt;
&lt;p&gt;Well? Did you have fun, and maybe learn something? As always, I&amp;rsquo;m keen on hearing from you, so &lt;a href="http://twitter.com/starbuxman"&gt;please sound off on Twitter (@starbuxman) &lt;/a&gt;! I&amp;rsquo;ll be back with another installment of &lt;em&gt;YMNNALFT&lt;/em&gt; later this week, so be sure not to miss that. I&amp;rsquo;ve got installments on, among other things, Easy RPC, The Garden of &lt;code&gt;*Utils&lt;/code&gt; objects, Dimensional Metrics with Micrometer, and many, many more topics. &lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>This Week in Spring, January 5th, 2020 - 10th Anniversary Edition</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/05/this-week-in-spring-january-5th-2020-10th-anniversary-edition" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2021-01-05:4328</id>
    <updated>2021-01-05T21:10:37Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! Happy new year! And welcome to another installment of &lt;em&gt;This Week in Spring&lt;/em&gt;! Today is a significant installment because it marks a decade of &lt;em&gt;This Week in Spring&lt;/em&gt;! &lt;/p&gt;
&lt;p&gt;I started this roundup after a fun discussion with the legendarily nice guy and SpringSource co-founder Keith Donald in late 2010 over the holiday. Lo, the first &lt;a href="http://web.archive.org/web/20110107071916/http://www.springsource.org/node/2986"&gt;week of January 2011&lt;/a&gt;, the first edition of this roundup went out the door on the old SpringSource.org blog. &lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s been so much fun putting together this roundup, without fail, every Tuesday for the last decade. You wouldn&amp;rsquo;t believe the lengths to which I went to get this out on Tuesday, well, &lt;em&gt;my&lt;/em&gt; Tuesday, no matter where I was. I&amp;rsquo;d be on planes all the time and the original blog software on SpringSource.org didn&amp;rsquo;t support scheduling posts, so I&amp;rsquo;d either publish it a little early or - if I was going to be on a plane for the entirety of the useful day - I&amp;rsquo;d have my then manager &lt;a href="https://twitter.com/devrelchap"&gt;Adam Fitzgerald&lt;/a&gt; post it for me. He reviewed the content for the first few years of the blog, too. What a legend that guy is. I learned a ton (about everything really, but also writing in particular) working with him. Nowadays, most flights longer than an hour or two have wi-fi onboard; but not so back then. Nowadays the software we use to blog - custom, open-source software that we built with Spring back in 2013 that underpins the &lt;a href="https://github.com/spring-io/sagan"&gt;spring.io&lt;/a&gt;) experience - supports scheduled posts, as well, so it&amp;rsquo;s much easier to get this post out on time. &lt;/p&gt;
&lt;p&gt;This Week in Spring has two other variants: &lt;em&gt;This Month in Spring&lt;/em&gt; is an email digest that goes out once a month; go to the blog page and find the &lt;a href="http://spring.io/blog"&gt;&lt;em&gt;Get the Spring Newsletter&lt;/em&gt;&lt;/a&gt; sign up form to get that digest. &lt;em&gt;This Year in Spring&lt;/em&gt; goes out as the last post of any given year, right here on the blog. &lt;/p&gt;
&lt;p&gt;I love this roundup because it&amp;rsquo;s a constant, and much appreciated, reminder of just how vibrant this community is. Thank you, as usual, Spring fans, and here&amp;rsquo;s to another decade (at least) of &lt;em&gt;This Week in Spring&lt;/em&gt;!&lt;/p&gt;
&lt;p&gt;Now, we&amp;rsquo;ve got a ton to get to this week so let&amp;rsquo;s get into it. &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Before we move forward, I&amp;rsquo;d like to briefly look back. 2020 had its share of struggles, generally, but Spring itself and its ambient communities continued to grow at breakneck speeds. Let&amp;rsquo;s look at the year that was in &lt;a href="https://spring.io/blog/2020/12/31/this-year-in-spring-2020-edition"&gt;&lt;em&gt;This Year in Spring - 2020 Edition&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/prattm/status/1344719453767008257?s=21"&gt;&amp;quot;Thanks for the reminder there was some good in 2020 @starbuxman! We successfully migrated @PedalPalApp to Kubernetes this year, and it was pretty simple with Spring Boot&amp;rsquo;s cloud-native support &#x1f60e; &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/31/a-bootiful-podcast-google-cloud-s-daniel-zou-on-spring-cloud-gcp-teaching-the-youths-and-happy-new-year"&gt;A Bootiful Podcast: Google Cloud&amp;rsquo;s Daniel Zou on Spring Cloud GCP, teaching the youths, and Happy New Year!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/Cosium/spring-data-jpa-entity-graph"&gt;Spring Data JPA extension allowing full dynamic usage of EntityGraph on repositories&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.infoq.com/presentations/measuring-service-level-objectives/?itm_source=infoq&amp;itm_medium=videos_homepage&amp;itm_campaign=videos_row1"&gt;Cultivating Production Excellence&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://blog.frankel.ch/feedback-log4j2-hack-spring-boot/"&gt;Feedback on the Log4J2 hack in Spring Boot&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://itmodel4dnadamagerepair.blogspot.com/"&gt;IT Model for DNA Damage Repair&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/arttom/cqs-spring-boot-starter"&gt;Interesting! A third party library to allow people to easily follow CQS principles in Spring Boot.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/qaware/openapi-generator-for-spring"&gt;Interesting: Open API v3 Generator for Spring Boot applications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.mitchellbosecke.com/post/java-proxies-from-dog-to-transactionaldog"&gt;Java Proxies: From &lt;code&gt;Dog&lt;/code&gt; to &lt;code&gt;TransactionalDog&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://sizovs.net/2020/11/24/java-libraries-i-like/"&gt;Java libraries I like ? Eduards Sizovs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.javaadvent.com/2020/12/resilient-applications-spring-resilience4j.html"&gt;Resilient applications with Spring and Resilience4J - JVM Advent&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://piotrminkowski.com/2019/12/06/spring-boot-best-practices-for-microservices/"&gt;Spring Boot Best Practices for Microservices - Piotr&amp;rsquo;s TechBlog&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=8sgi_xs5opw&amp;feature=share"&gt;This is a neat introduction to Spring Data JPA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;This isn&amp;rsquo;t, strictly speaking, Spring related, but it&amp;rsquo;s interesting. It&amp;rsquo;s an API to fluidly build up regular expressions. &lt;a href="https://github.com/VerbalExpressions/JavaVerbalExpressions"&gt;VerbalExpressions/JavaVerbalExpressions: Java regular expressions made easy.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.reddit.com/r/java/comments/khflbg/what_courses_both_free_and_paid_on_spring_boot/"&gt;What courses (both free and paid) on Spring Boot would you recommend? : java&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>YMNNALFT: Easy Docker Image Creation with the Spring Boot Maven Plugin and Buildpacks</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/04/ymnnalft-easy-docker-image-creation-with-the-spring-boot-maven-plugin-and-buildpacks" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-30:4315</id>
    <updated>2021-01-04T12:00:00Z</updated>
    <content type="html">&lt;p&gt;Welcome to another installment of &lt;em&gt;You May Not Need Another Library For That&lt;/em&gt; (&lt;code&gt;#YMNNALFT&lt;/code&gt;)! I&amp;rsquo;ve spent a lot of time since 2016 illuminating (or trying to, anyway!) some of the more enormous opportunities in the Spring ecosystem in &lt;a href="http://bit.ly/spring-tips-playlist"&gt;my Spring Tips videos&lt;/a&gt;. Today, however, I come to you in a different spirit, wanting to focus on the little, sometimes hidden, gems that do fantastic things and that might spare you an additional third-party dependency and its implied complexity. &lt;/p&gt;
&lt;p&gt;Have you tried out &lt;a href="https://paketo.io"&gt;Paketo&lt;/a&gt;? It&amp;rsquo;s neat-o! It alleviates one of the biggest pains of cloudy software these days:&lt;a href="https://docs.docker.com/engine/reference/builder/"&gt;Dockerfiles&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;As an aside: the &lt;em&gt;biggest&lt;/em&gt; pain point is, of course, YAML. YAML is why people leave IT! YAML: when you want the indentation-sensitive treachery of Python, with the nonexistent design-time validation of Python and &lt;em&gt;none&lt;/em&gt; of the benefits of Python. YAML: because life is, clearly, not hard enough. 9/10 dentists agree: YAML causes production rot!&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&amp;ldquo;Indeed it has been said that YAML is the best form of configuration except for all those other forms that have been tried from time to time.&amp;rdquo; - Not Winston Churchill &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;blockquote class="twitter-tweet"&gt;&lt;p lang="en" dir="ltr"&gt;No pressure debugging YAML ;) &lt;a href="https://t.co/vwCCYKTZY2"&gt;pic.twitter.com/vwCCYKTZY2&lt;/a&gt;&lt;/p&gt;&amp;mdash; Arun Gupta (@arungupta) &lt;a href="https://twitter.com/arungupta/status/1340676192588890112?ref_src=twsrc%5Etfw"&gt;December 20, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;Aaaanyway, YAML is a whole, other, &amp;ldquo;Oprah,&amp;rdquo; and we just don&amp;rsquo;t have a ton of time to get into it, so let&amp;rsquo;s move on: we want to simplify the creation of Dockerfiles. Dockerfiles are tedious and they require us to re-specify the complete environment required to run our applications in production. It&amp;rsquo;s possible to get something working in a fairly minimal number of lines, but as I learned while avoiding the COVID-19 virus, &amp;ldquo;minimal&amp;rdquo; is not &amp;ldquo;none!&amp;rdquo; And besides, something working does not a production environment make. We can do better.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://paketo.io/"&gt;Paketo&lt;/a&gt; is a Cloud Foundry foundation project based on the &lt;a href="https://buildpacks.io/"&gt;buildpacks project&lt;/a&gt; from &lt;a href="https://www.cncf.io/"&gt;CNCF&lt;/a&gt; (which stands for &amp;ldquo;Code Never Comes Finished,&amp;rdquo; or maybe it was &amp;ldquo;Common Network Code Foundation,&amp;rdquo; or was it &amp;ldquo;Cloud Native Computing Foundation&amp;rdquo;?). From the website: &amp;ldquo;buildpacks transform your application source code to images that can run on any cloud. Paketo Buildpacks provide language runtime support for applications. They leverage the Cloud Native Buildpacks framework to make image builds easy, performant, and secure.&amp;rdquo; Basically: application in; container out. See? Neat!&lt;/p&gt;
&lt;p&gt;Buildpacks come from the Heroku and Cloud Foundry Platform-as-a-service offerings. You give the buildpack an application artifact (like, say, a Java &lt;code&gt;.jar&lt;/code&gt;), and the buildpack gives you back your application in a container. More specifically, it&amp;rsquo;ll create a sensible filesystem containing your application artifact and everything needed to run that application artifact. So, given a &lt;code&gt;.jar&lt;/code&gt;, it might create a filesystem with a JVM configured with reasonable memory bounds and any required Java agents configured. All of &lt;em&gt;that&lt;/em&gt; is what eventually gets turned into a container. You&amp;rsquo;d be &lt;em&gt;shocked&lt;/em&gt; what you can get containerized with virtually no configuration at all! Buildpacks work because, no matter how much we may protest, most applications aren&amp;rsquo;t special. A &lt;code&gt;.jar&lt;/code&gt; is a &lt;code&gt;.jar&lt;/code&gt; for everybody, and a Node.js/NPM project builds the same for everybody. Buildpacks support several different languages and runtime (way too many to name). You can use the Paketo CLI to make short work of containerizing various applications, like this: &lt;code&gt;pack build .&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;Or, anyway, that&amp;rsquo;s what you &lt;em&gt;would&lt;/em&gt; do if you were not using &lt;a href="https://docs.spring.io/spring-boot/docs/2.4.1/maven-plugin/reference/htmlsingle/#build-image"&gt;Spring Boot 2.3 or later&lt;/a&gt;. But, you are, _ aren&amp;rsquo;t you_? Buildpack support is now in the Spring Boot build plugins themselves. &lt;/p&gt;
&lt;p&gt;If you were using Maven, you could type the following incantation: &lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;./mvnw spring-boot:build-image -Dspring-boot.build-image.imageName=bootiful/demo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you were using Gradle, you could type the following incantation: &lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;./gradlew bootBuildImage --imageName=bootiful/demo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Stand back for a minute while it does all the work. It&amp;rsquo;ll dump out the Docker image at the end of its work. You can then &lt;code&gt;docker tag&lt;/code&gt; and then &lt;code&gt;docker push&lt;/code&gt; that image to your container registry of choice (&lt;a href="https://goharbor.io/"&gt;VMware Harbor&lt;/a&gt;, &lt;a href="https://cloud.google.com/container-registry/"&gt;Google Container Registry&lt;/a&gt;, &lt;a href="https://jfrog.com/container-registry/"&gt;JFrog Container Registry&lt;/a&gt;, &lt;a href="https://hub.docker.com/"&gt;DockerHub&lt;/a&gt;, etc.). &lt;/p&gt;
&lt;p&gt;Do you want to take that to production? That&amp;rsquo;s pretty trivial, too! Here&amp;rsquo;s the right incantation for Kubernetes, assuming your image is on Google Container Registry, has an artifact ID of &lt;code&gt;demo&lt;/code&gt;. The version specified in &lt;code&gt;pom.xml&lt;/code&gt; becomes a tag for the version of the container, too.&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;kubectl create deployment demo --image=gcr.io/bootiful/demo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hopefully, this is enough to get you to production without so much as even having to configure something like Jib or the Spotify Maven plugin or crafting a long, byzantine shell script to do the &lt;code&gt;docker build&lt;/code&gt; itself. Now, don&amp;rsquo;t get me wrong. You &lt;em&gt;might&lt;/em&gt; still need to create your own `Dockerfile&amp;rsquo;s for whatever reason, as you might have something to say about the ordering or contents of particular layers, and if so, then Spring Boot &lt;a href="https://docs.spring.io/spring-boot/docs/2.4.1/maven-plugin/reference/htmlsingle/#build-image-customization"&gt;has your back here&lt;/a&gt;, too. &lt;/p&gt;
&lt;p&gt;Alright, that&amp;rsquo;s more than enough to get going. Go to the &lt;a href="http://start.Spring.io"&gt;Spring Initializr&lt;/a&gt; (my second favorite place on the internet, &lt;em&gt;after&lt;/em&gt; production) and generate a new project and take your containerized application to the platform of your choice. &lt;/p&gt;
&lt;p&gt;Did you like this gem at a glance approach? Did you learn anything? As always, I&amp;rsquo;m keen on hearing from you, so &lt;a href="http://twitter.com/starbuxman"&gt;please sound off on Twitter (@starbuxman) &lt;/a&gt;! I&amp;rsquo;ll be back with another installment of &lt;em&gt;YMNNALFT&lt;/em&gt; later this week, so be sure not to miss that. I&amp;rsquo;ve got installments on, among other things, Easy RPC, The Garden of &lt;code&gt;*Utils&lt;/code&gt; objects, Dimensional Metrics with Micrometer, and many, many more topics. &lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>A Bootiful Podcast: Google Cloud's Daniel Zou on Spring Cloud GCP, teaching the youths, and Happy New Year!</title>
    <link rel="alternate" href="https://spring.io/blog/2020/12/31/a-bootiful-podcast-google-cloud-s-daniel-zou-on-spring-cloud-gcp-teaching-the-youths-and-happy-new-year" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-31:4326</id>
    <updated>2020-12-31T02:45:36Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! Welcome to another installment of A Bootiful Podcast and happy new year! In this episode, &lt;a href="http://twitter.com/starbuxman"&gt;Josh Long (@starbuxman)&lt;/a&gt; talks to Google&amp;rsquo;s &lt;a href="https://github.com/dzou"&gt;Daniel Zou &lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;Happy New Year! &lt;/p&gt;
&lt;iframe title="Google's Daniel Zou on Spring Cloud GCP, GraalVM and more" height="122" width="100%" style="border: none;" scrolling="no" data-name="pb-iframe-player" src="https://www.podbean.com/media/player/kkk5w-f64f08?from=pb6admin&amp;download=1&amp;version=1&amp;auto=0&amp;share=1&amp;download=1&amp;rtl=0&amp;fonts=Helvetica&amp;skin=1&amp;pfauth=&amp;btn-skin=107"&gt;&lt;/iframe&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>This Year in Spring - 2020 Edition</title>
    <link rel="alternate" href="https://spring.io/blog/2020/12/31/this-year-in-spring-2020-edition" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-31:4325</id>
    <updated>2020-12-31T00:23:56Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! &lt;/p&gt;
&lt;p&gt;You know what I did? I goofed, people. I accidentally &lt;a href="https://spring.io/blog/2020/12/29/this-week-in-spring-december-29th-2020"&gt;released &lt;em&gt;This Week in Spring&lt;/em&gt;&lt;/a&gt; on this the last week of December, the last month of the year! And I shouldn&amp;rsquo;t have. I should &lt;em&gt;not&lt;/em&gt; have done that. Usually, you see, I turn the final installment of &lt;em&gt;This Week in Spring&lt;/em&gt; for a given year into the aptly named &lt;em&gt;This Year in Spring&lt;/em&gt;, a celebration of the big tentpole themes that have defined the year (well, from my perspective, anyway). Then I include the usual &lt;em&gt;This Week in Spring&lt;/em&gt; roundup inline. I forgot to do that first part, so I am publishing this as a separate post. Hey, &lt;em&gt;it&amp;rsquo;s tradition&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;Ah, 2020. The year that just keeps on giving. This was the year of Tiger King. If you&amp;rsquo;d told me in 2019 that in 2020 I&amp;rsquo;d be glued to my couch watching the adventures of a Tiger trainer on Netflix, afraid of my delivery groceries, and that I&amp;rsquo;d be eager to get on a plane for the first time in ten months, I would&amp;rsquo;ve laughed off of my chair! &lt;/p&gt;
&lt;p&gt;This year, 2020, started off fabulous. 2020 is the Spring team&amp;rsquo;s first year (or so) back in the fold after VMware acquired Pivotal. Some of you might know that the Spring team was at VMware for a few years before we spun out in 2013 to form Pivotal. And now we&amp;rsquo;re back. You&amp;rsquo;d &lt;em&gt;think&lt;/em&gt; that would be disruptive, but it simply wasn&amp;rsquo;t. Pivotal and VMware are cut from the same help-customers-get-to-production cloth. We hit the ground running and have continued to deliver big things and deliver often. &lt;/p&gt;
&lt;p&gt;This excitement was most palpable in the epic &lt;a href="https://springone.io/2020/speakers"&gt;SpringOne 2020&lt;/a&gt; (virtual) event this year, which drew around 40,000 people from all walks of life, creeds, countries, and continents. It was such sweet nectar, and I&amp;rsquo;ll never forget it. &lt;/p&gt;
&lt;p&gt;It helps that the Spring team has always been pretty geographically distributed. I, for example, have technically been a work-from-home employee since 2010. While this year was extra stressful and just plain &lt;em&gt;extra&lt;/em&gt; for &lt;em&gt;plenty&lt;/em&gt; of reasons, having to figure out a work-from-home routine simply wasn&amp;rsquo;t one of them for a lot of us.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s December 30th, 2020, as I write this, one year since the pandemic news started trickling into the west. I don&amp;rsquo;t be mean to be &lt;em&gt;that&lt;/em&gt; guy, but I&amp;rsquo;ve lost family from COVID-19 this year. I&amp;rsquo;ve got friends that spent time on a ventilator this year. I know people who&amp;rsquo;ve lost family and friends, too. It&amp;rsquo;s been an absolute horror show for so many people worldwide. And yet, somehow, I&amp;rsquo;ve been privileged enough to continue writing blogs about software. That&amp;rsquo;s because of you, dear community. While I have always been very grateful for you, I am especially so this year. It&amp;rsquo;s a privilege to work for you. &lt;/p&gt;
&lt;p&gt;The pandemic has spread like wildfire (some things should &lt;em&gt;not&lt;/em&gt; be open source!), and it has drowned out so much other, sometimes more positive, news. In that spirit, I&amp;rsquo;d like to review some of the highlights - some tentpole themes - from the year that was 2020.&lt;/p&gt;&lt;h2&gt;&lt;a href="#kubernetes" class="anchor" name="kubernetes"&gt;&lt;/a&gt;Kubernetes&lt;/h2&gt;
&lt;p&gt;You may have heard of &lt;a href="https://tanzu.vmware.com/tanzu"&gt;VMware Tanzu&lt;/a&gt;. You may have heard that the Spring team is part of Tanzu. Did you also know that two of the three founders of Kubernetes are also part of Tanzu? Did you know that VMware is the &lt;a href="https://k8s.devstats.cncf.io/d/9/companies-table?orgId=1&amp;var-period_name=Last%20decade&amp;var-metric=contributions"&gt;third-largest contributor to Kubernetes&lt;/a&gt;? We are cuckoo for Kubernetes!&lt;/p&gt;
&lt;p&gt;Tanzu Kubernetes Grid is our extra awesome Kubernetes distribution that works on-prem or on public infrastructure. Harbor is an enterprise-grade container registry. &lt;a href="https://tanzu.vmware.com/mission-control"&gt;Tanzu Mission Control&lt;/a&gt; provides multi-cluster Kubernetes management across clouds. VMware is also a significant contributor to &lt;a href="https://carvel.dev/"&gt;Carvell&lt;/a&gt;, which provides a set of reliable, single-purpose, composable tools that aid in your application building, configuration, and deployment to Kubernetes. We&amp;rsquo;ve got &lt;a href="https://tanzu.vmware.com/build-service"&gt;the Tanzu Build Service&lt;/a&gt;, which automates container creation, management, and governance at enterprise scale. I&amp;rsquo;m sure I&amp;rsquo;m missing a zillion other things.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ve even retrofitted &lt;a href="http://cloudfoundry.org"&gt;Cloud Foundry&lt;/a&gt;, our platform-as-a-service offering, to work on top of Kubernetes. Same silky-smooth developer-centric workflow taste with whole-fat Kubernetes container orchestration. &lt;/p&gt;
&lt;img src = "https://pbs.twimg.com/media/EqhnSM7U0AAhnYO?format=jpg&amp;name=4096x4096"/&gt;
&lt;p&gt;There&amp;rsquo;s been a &lt;em&gt;ton&lt;/em&gt; of work in recent years to make Java and Spring even more relevant in containerized cloud infrastructure like Kubernetes.&lt;/p&gt;
&lt;p&gt;This year, Spring Boot introduced built-in support for buildpacks through the CNCF Paketo buildpacks project. Got a Spring Boot project using 2.3 or later? Try this out: &lt;code&gt;mvn spring-boot:build-image&lt;/code&gt; (there&amp;rsquo;s a Gradle equivalent, too), and you&amp;rsquo;ll have a containerized application in about a minute. You can then &lt;code&gt;docker tag&lt;/code&gt; and &lt;code&gt;docker push&lt;/code&gt; that containerized application to your Kubernetes cluster of choice. Or, really, to anything that supports OCI/Docker images.&lt;/p&gt;
&lt;p&gt;Spring Boot itself can now draw configuration from &lt;em&gt;config trees&lt;/em&gt;. A config tree is the directory of configuration you get when you mount a Kubernetes &lt;code&gt;ConfigMap&lt;/code&gt; as a volume in Kubernetes. It&amp;rsquo;s yet another kind of configuration source, like classpath configuration (&lt;code&gt;application.properties&lt;/code&gt;, &lt;code&gt;application.yaml&lt;/code&gt;, etc.), environment variables, files (&lt;code&gt;file://${user.home}/config/my-config.properties&lt;/code&gt;) and so on. &lt;/p&gt;
&lt;p&gt;Spring Boot&amp;rsquo;s Actuator module can expose endpoints to serve as Kubernetes liveness and readiness probes. The readiness probe tells Kubernetes whether a just-launched service is ready to be put into rotation. The liveness probe tells Kubernetes whether the service is still alive. If the service, for whatever reason, should fall sick, it&amp;rsquo;ll be taken out of the rotation. &lt;/p&gt;
&lt;p&gt;The question the application faces then is: should Kubernetes destroy the application immediately, or should it wait a configured interval to allow in-flight transactions to finish? This behavior is configurable in Kubernetes. Spring Boot supports draining off any inflight transactions and rejecting any new requests with a new feature we call graceful shutdowns.&lt;/p&gt;
&lt;p&gt;Spring Boot and the ecosystem around it, including Spring Cloud for Kubernetes, are the best ways to build software designed for a cloud-native Kubernetes environment, and things are only improving every day. We&amp;rsquo;ve only really just gotten started, though, so stay tuned!&lt;/p&gt;&lt;h2&gt;&lt;a href="#reactive-programming" class="anchor" name="reactive-programming"&gt;&lt;/a&gt;Reactive Programming&lt;/h2&gt;
&lt;p&gt;Reactive programming is a programming paradigm that delivers three benefits: resource efficiency, consistency and composability of data APIs, and robustness. It delivers better resource efficiency by making it trivial to write code that does a good job of freeing up otherwise idle threads for reuse. It delivers consistency because it gives us one abstraction, one way to think disparate streams of data. Got data coming in as a Java 8 &lt;code&gt;Stream&amp;lt;T&amp;gt;&lt;/code&gt;? A &lt;code&gt;Collection&amp;lt;T&amp;gt;&lt;/code&gt;? A &lt;code&gt;CompletableFuture&amp;lt;T&amp;gt;&lt;/code&gt;? A single value or an array? No problem. Reactive programming gives us a way to describe data flow pipelines in terms of all these APIs in a consistent fashion. &lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s a slight uphill battle in learning the reactive types. Still, amortized over all the possible applications of those types across the ecosystem, I think you&amp;rsquo;ll find that you will be able to &lt;em&gt;forget&lt;/em&gt; a lot of other abstractions and APIs. The Spring ecosystem has (modestly) supported reactive programming since 2011, but the real leap forward came in 2017 when we introduced reactive programming support in Spring Framework 5. Since then, reactive programming has permeated every aspect of the Spring ecosystem. I don&amp;rsquo;t remember the last time I&amp;rsquo;ve reached for something in the reactive world, only to be told that it was still under development. It certainly hasn&amp;rsquo;t happened in 2020! &lt;/p&gt;
&lt;p&gt;Everything I could want is here and generally available. Transactions, SQL data access, messaging and integration, reactive client-side load-balancing, retries, rate-limiting, API gateways, NoSQL data access, HTTP, WebSocket, RPC, metrics, distributed tracing, observability: &lt;em&gt;all&lt;/em&gt; of it (and everything else I can think of) &lt;em&gt;just work&lt;/em&gt;, now, out of the box. The future is non-blocking, and Spring, as it&amp;rsquo;s designed today, will be right there with you at the forefront. I wrote and released a book about &lt;a href="http://ReactiveSpring.io"&gt;this stuff&lt;/a&gt;, so please believe me when I say it&amp;rsquo;s extra dope. Reactive programming is a powerful way to make our services behave (and scale!) better in the cloud. &lt;/p&gt;&lt;h2&gt;&lt;a href="#native-images-with-graalvm" class="anchor" name="native-images-with-graalvm"&gt;&lt;/a&gt;Native Images with GraalVM&lt;/h2&gt;
&lt;p&gt;Native images are here to stay, and they are &lt;em&gt;awesome&lt;/em&gt;. It all seemed so simple. What if we took Java&amp;rsquo;s legendary just-in-time compiler (HotSpot) used it to compile the whole application, ahead of time, proactively? It seems absurdly simple. This process - of converting source into native code - is simply called &lt;em&gt;compilation&lt;/em&gt; in numerous other languages. The indirection introduced by the compilation into bytecode has forced us to adopt a new term for that new straight-pass journey: &lt;em&gt;ahead-of-time-compilation&lt;/em&gt; (AOT). Oooh. Ahhhh. &lt;/p&gt;
&lt;p&gt;Simple. Except, it turns out that it&amp;rsquo;s not. Because once compiled to a native image, the application doesn&amp;rsquo;t have the same runtime as it would&amp;rsquo;ve had were it running in a JVM. Once compiled to a native image, the runtime won&amp;rsquo;t be able to do some of the more dynamic party tricks that we&amp;rsquo;ve come to expect from the JVM. Want to load a class into a classloader? Use CGlib proxies? Do reflection on a class without &lt;em&gt;a priori&lt;/em&gt; runtime awareness? Load a resource (say, a &lt;code&gt;banner.txt&lt;/code&gt; file) from the class loader? All of that goes out the window in this wacky but wonderful world of GraalVM AOT compilation. &lt;/p&gt;
&lt;p&gt;The Spring GraalVM project can help you here. It&amp;rsquo;s got support for identifying all the places where a Spring application may want to do these sorts of things and provides help in registering anything you might do that needs configuration. The project is growing by leaps and bounds, and the goal is that by Spring Boot 3 and Spring Framework 6, all of this will just be built-in and working out of the box. &lt;/p&gt;
&lt;p&gt;GraalVM returns manifold increases in startup speed and a significantly reduced memory footprint in return for all this incidental complexity. This makes GraalVM a (much) better bin-packer, especially in containerized cloud environments, where resource consumption costs. I can&amp;rsquo;t wait to see what the future holds for Project Leydon, too! &lt;/p&gt;&lt;h2&gt;&lt;a href="#rsocket" class="anchor" name="rsocket"&gt;&lt;/a&gt;RSocket&lt;/h2&gt;
&lt;p&gt;RSocket is a binary protocol that makes message exchange between microservices a breeze. It reifies the reactive streams concepts for the network, supporting backpressure over the wire. I love RSocket. Its got new support built into Spring Framework and Spring Boot themselves, of course, and there&amp;rsquo;s also Spring Security support and Spring Batch support. &lt;/p&gt;
&lt;p&gt;RSocket is the first project we, along with Alibaba, Facebook, and Lightbend, collectively donated to the nascent Reactive Foundation. It&amp;rsquo;s a better HTTP 2 or gRPC right now, and that alone should pique your curiosity, but I&amp;rsquo;m equally excited about the future. One of the most exciting prospects is the new RSocket broker on which the Soring team and others have worked. This broker could obviate some of the use cases for service registries like Netflix Eureka, message buses like RabbitMQ. The RSocket JVM client uses Reactor, which gives it superpowers: easy retries, error handling, back pressure, etc. &lt;/p&gt;
&lt;p&gt;Organizations like Facebook and Alibaba are already using it at scale, and Spring makes it easier than ever. I can&amp;rsquo;t wait to see what people build with RSocket in the weeks, months, and years to come.&lt;/p&gt;&lt;h2&gt;&lt;a href="#java-and-kotlin" class="anchor" name="java-and-kotlin"&gt;&lt;/a&gt;Java and Kotlin&lt;/h2&gt;
&lt;p&gt;The last thing I&amp;rsquo;ve been very excited about is the deep integration with the latest versions of Java and Kotlin in the latest versions of Spring. Spring Boot releases every six months, lining up nicely with the Java release cadence. Using Spring Boot with Java 15 is a &lt;em&gt;dream&lt;/em&gt;. I did a video on Java 14 that looked at a ton of the new features in that release, including a ton of &lt;em&gt;preview&lt;/em&gt; features. But you don&amp;rsquo;t even need to look at all that. Just look at the stuff that&amp;rsquo;s included out of the box in Java 15! Multiline text strings and &lt;code&gt;var&lt;/code&gt; alone make life considerably more manageable. The new versions of Java are excellent, and let&amp;rsquo;s not even talk about all the under-the-hood stuff from the last several generations that make Java faster, more robust, more container-friendly, more secure, etc. &lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m using one of those new-fangled Apple Silicon M1 MacBook Pros and am using the Microsoft OpenJDK port support ARM chips. It is &lt;em&gt;fast&lt;/em&gt;. Most of my applications start in around 0.8 seconds! Remember, these chips were announced just a few months ago! The idea that Microsoft/Azul Systems have already got a working port of OpenJDK out there is a testament to the ecosystem&amp;rsquo;s vibrancy. Java is the name of fantastic technology and an even more fantastic community, and I love Java.&lt;/p&gt;
&lt;p&gt;Kotlin is another high point for me this year. I was made a Kotlin Google Developer Expert earlier this year, so I may be biased. Kotlin has this concept of coroutines. A coroutine in Kotlin is one language keyword that allows you to tag a particular piece of code as performing an asynchronous thing whose thread the runtime can reschedule. It&amp;rsquo;s effortless. Spring builds on this mechanism, integrating reactive programming through coroutines. So, you get the best of both worlds there: easy, imperative-style programming that benefits from the non-blocking nature of reactive code. Anywhere Spring supports reactive APIs, Spring and Kotlin now support coroutines. &lt;/p&gt;&lt;h2&gt;&lt;a href="#here-rsquo-s-to-the-year-ahead" class="anchor" name="here-rsquo-s-to-the-year-ahead"&gt;&lt;/a&gt;Here&amp;rsquo;s to the Year Ahead&lt;/h2&gt;
&lt;p&gt;My friends, I hope you&amp;rsquo;re persuaded as to the opportunity that 2020 represents. I look forward to talking with you all in the year ahead. And who knows, maybe, science and logistics permitting, we&amp;rsquo;ll even see each other. (Three cheers for doctors!) It&amp;rsquo;s going to be a fun one, indeed. I hope you are all taking care of yourself, keeping socially distant, wearing masks, etc., and I am sure that I can speak on behalf of the entire Spring team when I wish you and yours a very &lt;em&gt;Happy New Year&lt;/em&gt;! &lt;/p&gt;
&lt;img src="https://pbs.twimg.com/media/EqhjmSKVQAIdKuJ?format=jpg&amp;name=medium" /&gt;
&lt;div&gt; &#xD;
 &lt;span style ="font-size: smaller"&gt; (You would &lt;em&gt;not&lt;/em&gt; believe how hard it is to find socially distant stock photos!)&lt;/span&gt;&#xD;
&lt;/div&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>This Week in Spring - December 29th, 2020</title>
    <link rel="alternate" href="https://spring.io/blog/2020/12/29/this-week-in-spring-december-29th-2020" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-29:4314</id>
    <updated>2020-12-29T18:06:20Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! Welcome to another installment of &lt;em&gt;This Week in Spring&lt;/em&gt;!&lt;/p&gt;
&lt;p&gt;How are you? How&amp;rsquo;re things? I spent this morning on a fun two-hour panel hosted by the Barcelona JUG (who run the JBCN conference, among other things) talking about all sorts of things including GraalVM native images, new features in the Java language, cloud-native applications, and so much more. Thanks for having me! &lt;/p&gt;
&lt;p&gt;I am so happy about this week&amp;rsquo;s roundup and we&amp;rsquo;ve got a lot to cover so let&amp;rsquo;s get to it!&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/24/a-bootiful-podcast-alibaba-s-san-hong-li-on-tuning-openjdk-for-alibaba-scale"&gt;A Bootiful Podcast: Alibaba&amp;rsquo;s San-Hong Li on tuning OpenJDK for Alibaba Scale&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/23/cloud-events-and-spring-part-2"&gt;Cloud Events and Spring - part 2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/Cosium/spring-data-jpa-entity-graph"&gt;Cosium/spring-data-jpa-entity-graph: Spring Data JPA extension allowing full dynamic usage of EntityGraph on repositories&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Hah! This is so interesting! &lt;a href="https://github.com/SolarEdgeTech/pyctuator"&gt;Give Python applications Spring Boot Actuator endpoints&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/arttom/cqs-spring-boot-starter"&gt;Interesting! A third party library to allow people to easily follow CQS principles in Spring Boot.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/qaware/openapi-generator-for-spring"&gt;Interesting: Open API v3 Generator for Spring Boot applications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.mitchellbosecke.com/post/java-proxies-from-dog-to-transactionaldog"&gt;Java Proxies: From Dog to TransactionalDog&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://sizovs.net/2020/11/24/java-libraries-i-like/"&gt;Java libraries I like ? Eduards Sizovs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.javaadvent.com/2020/12/resilient-applications-spring-resilience4j.html"&gt;Resilient applications with Spring and Resilience4J - JVM Advent&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://piotrminkowski.com/2019/12/06/spring-boot-best-practices-for-microservices/"&gt;Spring Boot Best Practices for Microservices - Piotr&amp;rsquo;s TechBlog&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/22/spring-cloud-2020-0-0-aka-ilford-is-available"&gt;Spring Cloud 2020.0.0 (aka Ilford) Is Available&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/jonatan_ivanov/status/1341477187455655936?s=12"&gt;Spring cloud sleuth OpenTelemetry support has been released&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.infoq.com/minibooks/java-innovations/"&gt;The InfoQ eMag - Java Innovations That Are on Their Way&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.reddit.com/r/java/comments/khflbg/what_courses_both_free_and_paid_on_spring_boot/"&gt;What courses (both free and paid) on Spring Boot would you recommend? : java&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>A Bootiful Podcast: Alibaba's San-Hong Li on tuning OpenJDK for Alibaba Scale</title>
    <link rel="alternate" href="https://spring.io/blog/2020/12/24/a-bootiful-podcast-alibaba-s-san-hong-li-on-tuning-openjdk-for-alibaba-scale" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-24:4313</id>
    <updated>2020-12-24T11:18:54Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! This week &lt;a href="http://twitter.com/starbuxman"&gt;Josh Long (@starbuxman)&lt;/a&gt; talks to Alibaba&amp;rsquo;s &lt;a href="http://twitter.com/SanHong_li"&gt;San-Hong Li (@SanHong_Li)&lt;/a&gt; on tuning OpenJDK for Alibaba-scale. &lt;/p&gt;
&lt;p&gt;Merry Christmas / Happy Holidays to you! &lt;/p&gt;
&lt;iframe title="Alibaba's San-Hong Li on tuning OpenJDK for Alibaba Scale" height="122" width="100%" style="border: none;" scrolling="no" data-name="pb-iframe-player" src="https://www.podbean.com/media/player/n9hns-f5d984?from=pb6admin&amp;download=1&amp;version=1&amp;auto=0&amp;share=1&amp;download=1&amp;rtl=0&amp;fonts=Helvetica&amp;skin=1&amp;pfauth=&amp;btn-skin=107"&gt;&lt;/iframe&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Cloud Events and Spring - part 2</title>
    <link rel="alternate" href="https://spring.io/blog/2020/12/23/cloud-events-and-spring-part-2" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Oleg Zhurakousky</name>
    </author>
    <id>tag:spring.io,2020-12-09:4289</id>
    <updated>2020-12-23T16:11:00Z</updated>
    <content type="html">&lt;h3&gt;&lt;a href="#introduction" class="anchor" name="introduction"&gt;&lt;/a&gt;Introduction&lt;/h3&gt;
&lt;p&gt;We begin with a quick summary of the &lt;a href="https://spring.io/blog/2020/12/10/cloud-events-and-spring-part-1"&gt;previous post&lt;/a&gt;. &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://www.enterpriseintegrationpatterns.com/patterns/messaging/Message.html"&gt;Message&lt;/a&gt; is an adequate structure and abstraction with which to consume data that represents a Cloud Event in the context of Spring. We hope it was clear.&lt;/li&gt;
  &lt;li&gt;In Spring, our commitment to isolate functional versus non-functional concerns lets us address non-functional aspects (such as send, receive, retry, connect, convert, and others) at the framework level, letting you (mostly) concentrate on actual business logic and letting you keep your code simple and pluggable to a variety of &lt;em&gt;execution contexts&lt;/em&gt; (more on this later).&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#the-business-problem" class="anchor" name="the-business-problem"&gt;&lt;/a&gt;The Business Problem&lt;/h3&gt;
&lt;p&gt;As promised, this post is more technical, as it covers concrete examples available for you to try. So, without further ado, we begin by describing the three use cases that we will cover. Actually the use case is the same, but the execution context varies:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;&amp;ldquo;Receive data that represents a person to be hired, producing an employee record.&amp;rdquo;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The three different variations are in the execution context (an example of a typical non-functional concerns):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;HTTP request/response&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;From AMQP to Apache Kafka&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;From RSocket to Apache Kafka.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Neither the use case nor the execution contexts are really new or unique. In Spring, we&amp;rsquo;ve been handling them for decades, with thousands of applications running in production. So, would anything change by adding Cloud Event context? In other words, would anything change if incoming and outgoing data represents a Cloud Event? These are the questions we are attempting to answer in this post.&lt;/p&gt;
&lt;p&gt;The user code for these examples is:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;@SpringBootApplication&#xD;
public static class SampleApplication&#xD;
  public static void main(String[] args) throws Exception {&#xD;
    SpringApplication.run(SampleApplication.class, args);&#xD;
  }&#xD;
&#xD;
  @Bean&#xD;
  public Function&amp;lt;Person, Employee&amp;gt; hire() {&#xD;
    return person -&amp;gt; {&#xD;
	Employee employee = new Employee(person);&#xD;
	return employee;&#xD;
    };&#xD;
  }&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yes, it is kind of boring, since it does not show any of the non-functional aspects, as they are handled by the frameworks specific to the execution context. We also kept implementation details of the functions rather trivial, since they have no relevance to the topic. The framework does not really care what you do. It cares only about what you expect ? &lt;em&gt;input&lt;/em&gt; ? and what you produce ? &lt;em&gt;output&lt;/em&gt; ? and that information is available from the signature. &lt;/p&gt;&lt;h4&gt;&lt;a href="#use-case-1-over-http" class="anchor" name="use-case-1-over-http"&gt;&lt;/a&gt;Use Case 1 (over HTTP)&lt;/h4&gt;
&lt;p&gt;The full source code for this example is available &lt;a href="https://github.com/spring-cloud/spring-cloud-function/tree/master/spring-cloud-function-samples/function-sample-cloudevent"&gt;in the Spring Cloud Function samples&lt;/a&gt;.&lt;br/&gt;In it, we send a Cloud Event as an HTTP request and expect to receive a Cloud Event as an HTTP response. This means that, somehow, our &lt;code&gt;hire()&lt;/code&gt; function needs to become an HTTP endpoint. We can do this by using the &lt;a href="https://spring.io/projects/spring-cloud-function"&gt;Spring Cloud Function&lt;/a&gt; framework.&lt;br/&gt;By adding its &lt;code&gt;spring-cloud-function-web&lt;/code&gt; dependency, we add Spring Boot auto-configurations and components necessary to turn our function into an HTTP endpoint. Configuration options and defaults are out of scope for this post, but you can get them from the relevant section of the &lt;a href="https://docs.spring.io/spring-cloud-function/docs/3.1.0-M5/reference/html/spring-cloud-function.html#_standalone_web_applications"&gt;Spring Cloud Function documentation&lt;/a&gt;. The important thing is that, based on such defaults, the name of the function becomes part of the URL path running on &lt;code&gt;localhost&lt;/code&gt; port &lt;code&gt;8080&lt;/code&gt;, resulting in the &lt;code&gt;http://localhost:8080/hire&lt;/code&gt; endpoint.&lt;/p&gt;
&lt;p&gt;Now you can start the application and post to it.&lt;br/&gt;Once the application is running, you can &lt;code&gt;curl&lt;/code&gt; it with the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint bash"&gt;curl -w&amp;#39;\n&amp;#39; localhost:8080/hire \&#xD;
 -H &amp;quot;Content-Type: application/json&amp;quot; \&#xD;
 -d &amp;#39;{&amp;quot;firstName&amp;quot;:&amp;quot;John&amp;quot;, &amp;quot;lastName&amp;quot;:&amp;quot;Doe&amp;quot;}&amp;#39; -i
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should receive the following response:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint json"&gt;. . .&#xD;
{&amp;quot;person&amp;quot;:{&amp;quot;firstName&amp;quot;:&amp;quot;John&amp;quot;,&amp;quot;lastName&amp;quot;:&amp;quot;Doe&amp;quot;},&amp;quot;id&amp;quot;:172,&amp;quot;message&amp;quot;:&amp;quot;Employee 172 was hired on 17-12-2020&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Well&amp;hellip; . This really had nothing to do with Cloud Events! Right&amp;hellip;?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Correct, but the capabilities of the framework to expose a function as a REST endpoint, to take care of type conversion, invocation, and other non-functional aspects are clear and have direct relevance to Cloud Events. Read on&amp;hellip;&lt;/p&gt;
&lt;p&gt;At the center of such enablement is &lt;a href="https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/messaging/Message.html"&gt;Message&lt;/a&gt; - a structure and a type that lets an incoming HTTP (or any other) request take on a canonical form so that other frameworks can deal with its contents in uniformed way, regardless of its origin or destination.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;But wait, what about Cloud Events?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s turn this HTTP request into a Cloud Event by adding HTTP headers that represent the required Cloud Event attributes. Note that these headers are prefixed with a &lt;code&gt;ce-&lt;/code&gt; prefix required by the &lt;a href="https://github.com/cloudevents/spec/blob/v1.0.1/http-protocol-binding.md"&gt;HTTP Protocol Binding&lt;/a&gt; part of the Cloud Event specification.&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint bash"&gt;curl -w&amp;#39;\n&amp;#39; localhost:8080/hire \&#xD;
 -H &amp;quot;ce-id: 0001&amp;quot; \&#xD;
 -H &amp;quot;ce-specversion: 1.0&amp;quot; \&#xD;
 -H &amp;quot;ce-type: hire&amp;quot; \&#xD;
 -H &amp;quot;ce-source: spring.io/spring-event&amp;quot; \&#xD;
 -H &amp;quot;Content-Type: application/json&amp;quot; \&#xD;
 -d &amp;#39;{&amp;quot;firstName&amp;quot;:&amp;quot;John&amp;quot;, &amp;quot;lastName&amp;quot;:&amp;quot;Doe&amp;quot;}&amp;#39; -i
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After executing it, you will not see any difference. Your function acts the same way, and you receive the same response.&lt;/p&gt;
&lt;p&gt;That is, of course, until you look and analyze the response headers, which now contain the required Cloud Event attributes (albeit different than the ones in the request):&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint text"&gt;ce-source: http://spring.io/cloudevent&#xD;
ce-specversion: 1.0&#xD;
ce-type: sample&#xD;
ce-id: 76208faf-f8e5-4267-9028-bb4392d66765&#xD;
message-type: cloudevent&#xD;
timestamp: 1608211771624&#xD;
Content-Type: application/json&#xD;
Transfer-Encoding: chunked&#xD;
Date: Thu, 17 Dec 2020 13:29:31 GMT&#xD;
{&amp;quot;person&amp;quot;:{&amp;quot;firstName&amp;quot;:&amp;quot;John&amp;quot;,&amp;quot;lastName&amp;quot;:&amp;quot;Doe&amp;quot;},&amp;quot;id&amp;quot;:171,&amp;quot;message&amp;quot;:&amp;quot;Employee 171 was hired on 17-12-2020&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;But how?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This is the part where, once again, we remind you of our commitment to outsource non-functional aspects to the frameworks, as this is one of them. So, by default (established by the framework) we assume that, if a request were a Cloud Event, the response is expected to be a Cloud Event as well. You can also see that the four required Cloud Event attributes have values that were also generated by following certain default rules established by the framework. The &lt;code&gt;specversion&lt;/code&gt; defaults to &lt;code&gt;1.0&lt;/code&gt;, the &lt;code&gt;type&lt;/code&gt; to the type name of the returned object, the &lt;code&gt;id&lt;/code&gt; to the generated &lt;code&gt;UUID&lt;/code&gt; (to provide a reasonably safe expectation of uniqueness), and the &lt;code&gt;source&lt;/code&gt; to &lt;code&gt;http://spring.io/&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;But I don&amp;rsquo;t like default values. I want my own and I want to add additional attributes?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;As we mentioned in the &lt;a href="https://spring.io/blog/2020/12/10/cloud-events-and-spring-part-1"&gt;previous post&lt;/a&gt;: &lt;em&gt;&amp;ldquo;We also expose utilities, libraries, and configuration options that let you influence certain non-functional concerns, as doing so may still be required for a variety of reasons.&amp;rdquo;&lt;/em&gt;&lt;br/&gt;Here, you have two options.&lt;br/&gt;&lt;strong&gt;&lt;em&gt;First option:&lt;/em&gt;&lt;/strong&gt; You can change the function signature and return a &lt;code&gt;Message&amp;lt;Employee&amp;gt;&lt;/code&gt;, where you can add additional metadata (that is, Cloud Event attributes). Once the framework sees that that you returned a &lt;code&gt;Message&lt;/code&gt;, it does not attempt to do anything extra with regard to the metadata added by the user. That is the rule that actually applies to most if not all frameworks that rely on Spring Messaging. While this option is simple, it does leak non-functional aspects into your business logic. After all, you need to create an instance of &lt;code&gt;Message&lt;/code&gt;, you need to add headers that represent Cloud Event attributes (preferably with the correct &amp;ndash; specification mandated &amp;ndash; attribute prefix), and so on. But the biggest flaw for this option is that it would require you to change the signature of the function and mix functional and non-functional aspects together, which is a clear violation of the &lt;em&gt;separation of concerns&lt;/em&gt; rule.&lt;br/&gt;However, for the sake of argument, here is how you would do that:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;@Bean&#xD;
public Function&amp;lt;Message&amp;lt;Person&amp;gt;, Message&amp;lt;Employee&amp;gt;&amp;gt; hire() {&#xD;
  return message -&amp;gt; {&#xD;
    Person person = message.getPayload();&#xD;
    Employee employee = new Employee(person);&#xD;
      return CloudEventMessageBuilder.withData(employee).setId(&amp;quot;123456&amp;quot;)&#xD;
	.setSource(URI.create(&amp;quot;https://spring.cloudevenets.sample&amp;quot;)).build();&#xD;
  };&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The sample source code contains a commented version of it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Second option:&lt;/em&gt;&lt;/strong&gt; You can provide an implementation of a strategy called &lt;code&gt;CloudEventHeaderEnricher&lt;/code&gt;, which provides a separate place where you can implement logic for generating appropriate attributes and headers for the output. This strategy is invoked by the framework at the time of generating the output &lt;code&gt;Message&lt;/code&gt;. The following example shows a possible implementation of this strategy (also commented out in the example, so uncomment it, restart the app, and see the difference).&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;@Bean&#xD;
public CloudEventHeaderEnricher cloudEventEnricher() {&#xD;
  return messageBuilder -&amp;gt; messageBuilder.setSource(&amp;quot;http://spring.io/cloudevent&amp;quot;)&#xD;
	.setType(&amp;quot;sample&amp;quot;).setId(&amp;quot;987654&amp;quot;);&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, you can also see one of the utility classes that can assist you with building Cloud Event messages: &lt;a href="https://github.com/spring-cloud/spring-cloud-function/blob/master/spring-cloud-function-context/src/main/java/org/springframework/cloud/function/cloudevent/CloudEventMessageBuilder.java"&gt;&lt;code&gt;CloudEventMessageBuilder&lt;/code&gt;&lt;/a&gt;. It is modeled after a standard Spring &lt;a href="https://docs.spring.io/spring-integration/api/org/springframework/integration/support/MessageBuilder.html"&gt;&lt;code&gt;MessageBuilder&lt;/code&gt;&lt;/a&gt; but with Cloud Event specific setters .&lt;br/&gt;However, the main advantage of this approach is the separation of concerns. Your business logic (your functional code) stays clean. Also, the non-functional code that you still need to write is written in a separate place. &lt;/p&gt;
&lt;p&gt;One other thing &amp;hellip; The example code assumes that you&amp;rsquo;re interested only in the &lt;code&gt;data&lt;/code&gt; portion of a Cloud Event and that you want it in the form of a POJO. But what if that is not the case? What if you want the entire view in a Cloud Event? Or what if you also want Cloud Event data in its raw form (that is, &lt;code&gt;byte[]&lt;/code&gt;)?&lt;br/&gt;As mentioned earlier, the framework gets its instructions from the signature of the function. So, by declaring your input and output type as &lt;code&gt;Message&lt;/code&gt; you&amp;rsquo;re effectively instructing the framework to give you the entire Cloud Event (not just its &lt;code&gt;data&lt;/code&gt;). Also, by specifying the generic type of &lt;code&gt;Message&lt;/code&gt;, you instruct the framework to serve the &lt;code&gt;data&lt;/code&gt; portion of a Cloud Event as that Java type, essentially requesting it to perform type conversion, if necessary.&lt;br/&gt;So go ahead and try the following signatures: &lt;code&gt;public Function&amp;lt;Message&amp;lt;byte[]&amp;gt;, Message&amp;lt;Employee&amp;gt;&amp;gt; hire() {...}&lt;/code&gt; or &lt;code&gt;public Function&amp;lt;byte[], Employee&amp;gt; hire() {...}&lt;/code&gt; or others.&lt;/p&gt;
&lt;p&gt;That is pretty much all for now. The README file and comments in the source code also provide additional instructions where needed.&lt;/p&gt;&lt;h4&gt;&lt;a href="#use-case-2-from-amqp-to-kafka" class="anchor" name="use-case-2-from-amqp-to-kafka"&gt;&lt;/a&gt;Use Case 2 (from AMQP to Kafka)&lt;/h4&gt;
&lt;p&gt;The full source code for the example is available in the &lt;a href="https://github.com/spring-cloud/spring-cloud-function/tree/master/spring-cloud-function-samples/function-sample-cloudevent-stream"&gt;Spring Cloud Function samples&lt;/a&gt;. It assumes a certain level of familiarity with AMQP and Apache Kafka. For this example, we use RabbitMQ (as an AMQP message broker) and Apache Kafka.&lt;/p&gt;
&lt;p&gt;While this use case may appear to be more complex than the previous one, this and the subsequent section (the third use case) are surprisingly short. That is because everything that was explained in the previous section applies here as well. In fact, the only thing that we are changing here is the execution context. We do that by the same mechanism: adding the relevant Spring Boot based auto-configurations.&lt;br/&gt;So, in this case, we add two auto-configurations: one for the RabbitMQ (AMQP message broker) binder and one for the Apache Kafka binder available in the &lt;a href="https://spring.io/projects/spring-cloud-stream"&gt;Spring Cloud Stream&lt;/a&gt; framework.&lt;br/&gt;There is also some additional application configuration (which you can see in the &lt;code&gt;application.properties&lt;/code&gt; file) to instruct the framework how to bind the input side of the &lt;code&gt;hire&lt;/code&gt; function to RabbitMQ (through the RabbitMQ binder) and the output side to Apache Kafka (via Apache Kafka binder).&lt;/p&gt;
&lt;p&gt;Assuming you have RabbitMQ and Kafka running, start the application and send a Message to RabbitMQ. You can use the &lt;a href="http://localhost:15672/#/exchanges"&gt;RabbitMQ dashboard&lt;/a&gt; (if you have it installed) and send a message to &lt;code&gt;hire-in-0&lt;/code&gt; exchange.&lt;br/&gt;To stay compliant with the Cloud Event specification, you should provide attributes with AMQP appropriate prefixes (that is, &lt;code&gt;cloudEvents:&lt;/code&gt;). Consider the following example:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint text"&gt;cloudEvents:specversion=1.0&#xD;
cloudEvents:type=hire&#xD;
cloudEvents:source:spring.io/spring-event&#xD;
cloudEvents:id=0001
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then consider the following data:&lt;br/&gt;&lt;code&gt;{&amp;quot;firstName&amp;quot;:&amp;quot;John&amp;quot;, &amp;quot;lastName&amp;quot;:&amp;quot;Doe&amp;quot;}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To simplify this demo part, we included a &lt;a href="https://github.com/spring-cloud/spring-cloud-function/blob/master/spring-cloud-function-samples/function-sample-cloudevent-stream/src/test/java/io/spring/cloudevent/DemoApplicationTests.java"&gt;test case&lt;/a&gt; to effectively automate this demo by sending a Cloud Event to RabbitMQ and receiving one from Apache Kafka:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;Message&amp;lt;byte[]&amp;gt; messageToAMQP = CloudEventMessageBuilder&#xD;
	.withData(&amp;quot;{\&amp;quot;firstName\&amp;quot;:\&amp;quot;John\&amp;quot;, \&amp;quot;lastName\&amp;quot;:\&amp;quot;Doe\&amp;quot;}&amp;quot;.getBytes())&#xD;
	.setSource(&amp;quot;https://cloudevent.demo&amp;quot;)&#xD;
	.setHeader(MessageHeaders.CONTENT_TYPE, MimeTypeUtils.APPLICATION_JSON)&#xD;
	.build(CloudEventMessageUtils.AMQP_ATTR_PREFIX);&#xD;
&#xD;
rabbitTemplate.send(&amp;quot;hire-in-0&amp;quot;, &amp;quot;#&amp;quot;, messageToAMQP);&#xD;
Message&amp;lt;String&amp;gt; resultFromKafka = queue.poll(2000, TimeUnit.MILLISECONDS);&#xD;
System.out.println(&amp;quot;Result Message: &amp;quot; + resultFromKafka);&#xD;
. . .
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note how we use &lt;code&gt;CloudEventMessageBuilder&lt;/code&gt; here to set only &lt;code&gt;source&lt;/code&gt; as a Cloud Event attribute while relying on default values for the rest of the required Cloud Event attributes. We also use &lt;code&gt;build(CloudEventMessageUtils.AMQP_ATTR_PREFIX)&lt;/code&gt; to ensure that the attributes are prefixed with the &lt;code&gt;cloudEvents:&lt;/code&gt; prefix (see &lt;a href="https://github.com/cloudevents/spec/blob/v1.0.1/amqp-protocol-binding.md"&gt;Cloud Events AMQP protocol bindings&lt;/a&gt;).&lt;br/&gt;Also, note that, on the receiving end, Cloud Events attributes are now prefixed with a &lt;code&gt;ce_&lt;/code&gt; prefix (see &lt;a href="https://github.com/cloudevents/spec/blob/v1.0.1/kafka-protocol-binding.md"&gt;Cloud Events Kafka protocol bindings&lt;/a&gt;), since it was determined by the framework that the target destination is Apache Kafka.&lt;br/&gt;This last point is worth elaborating a bit. We already established that setting Cloud Event attributes is a non-functional aspect and that, because of it, we have exposed a mechanism to let you deal with it outside of your business logic. But what about attribute prefixes? Note that we are running the same code in different execution contexts. This means that the attribute prefixes actually depend on the execution context. So, by being aware of the execution context, the framework ensures the correctness of the Cloud Event attribute prefixes.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Here, we rely on the &lt;a href="https://spring.io/projects/spring-cloud-stream"&gt;Spring Cloud Stream&lt;/a&gt; framework and its defaults, such as destination auto-provisioning (both Kafka and Rabbit), binding names, connectivity, and more. The details of these defaults and configuration options are out of scope for this post, since none of them are relevant to Cloud Events. See the &lt;a href="https://docs.spring.io/spring-cloud-stream/docs/3.1.0-SNAPSHOT/reference/html/"&gt;Spring Cloud Stream documentation&lt;/a&gt; for more details on the framework itself and its configuration options.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Also, as with the previous example, this one also includes commented variations with which you are welcome to experiment.&lt;/p&gt;&lt;h4&gt;&lt;a href="#use-case-3-from-rsocket-to-kafka" class="anchor" name="use-case-3-from-rsocket-to-kafka"&gt;&lt;/a&gt;Use Case 3 (from RSocket to Kafka)&lt;/h4&gt;
&lt;p&gt;The full source code for the example is available in the &lt;a href="https://github.com/spring-cloud/spring-cloud-function/tree/master/spring-cloud-function-samples/function-sample-cloudevent-rsocket"&gt;Spring Cloud Function samples&lt;/a&gt;. It assumes a certain level of familiarity with RSocket and Apache Kafka.&lt;br/&gt;This section should be even shorter than the previous one, as it is very similar. However, there are a few interesting variants here that are worth discussing. Well, the obvious one is &lt;a href="https://rsocket.io/"&gt;RSocket&lt;/a&gt;. We&amp;rsquo;re introducing a different delivery mechanism. But what really makes it even more interesting is the fact that there is no protocol binding defined for RSocket. We can choose to adhere to one of the Kafka, HTTP, or AMQP specifications, or we can communicate a Cloud Event in a structured mode, where the entire event is encoded into some structure (such as JSON).&lt;/p&gt;
&lt;p&gt;A few implementation details also differ from the other use cases in this example. However, these details are not relevant in any way to Cloud Event. Rather, they are demonstrations of other mechanisms you can use. For example we use &lt;code&gt;Consumer&lt;/code&gt; instead of a &lt;code&gt;Function&lt;/code&gt; and manually send an output message by using a &lt;code&gt;StreamBridge&lt;/code&gt; component provided by Spring Cloud Stream framework.&lt;/p&gt;
&lt;p&gt;So, without further ado, here is our application code:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;@Bean&#xD;
public Consumer&amp;lt;Person&amp;gt; hire(StreamBridge streamBridge) {&#xD;
  return person -&amp;gt; {&#xD;
    Employee employee = new Employee(person);&#xD;
    streamBridge.send(&amp;quot;hire-out-0&amp;quot;, CloudEventMessageBuilder.withData(employee)&#xD;
	.setSource(&amp;quot;http://spring.io/rsocket&amp;quot;)&#xD;
	.setId(&amp;quot;1234567890&amp;quot;)&#xD;
	.build());&#xD;
  };&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note how we use &lt;code&gt;CloudEventMessageBuilder&lt;/code&gt; to generate the output &lt;code&gt;Message&lt;/code&gt; as a Cloud Event.&lt;/p&gt;
&lt;p&gt;We send a structured representation of a Cloud Event, encoded as JSON, over RSocket to the &lt;code&gt;hire()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;String payload = &amp;quot;{\n&amp;quot; +&#xD;
	&amp;quot;    \&amp;quot;specversion\&amp;quot; : \&amp;quot;1.0\&amp;quot;,\n&amp;quot; +&#xD;
	&amp;quot;    \&amp;quot;type\&amp;quot; : \&amp;quot;org.springframework\&amp;quot;,\n&amp;quot; +&#xD;
	&amp;quot;    \&amp;quot;source\&amp;quot; : \&amp;quot;https://spring.io/\&amp;quot;,\n&amp;quot; +&#xD;
	&amp;quot;    \&amp;quot;id\&amp;quot; : \&amp;quot;A234-1234-1234\&amp;quot;,\n&amp;quot; +&#xD;
	&amp;quot;    \&amp;quot;datacontenttype\&amp;quot; : \&amp;quot;application/json\&amp;quot;,\n&amp;quot; +&#xD;
	&amp;quot;    \&amp;quot;data\&amp;quot; : {\n&amp;quot; +&#xD;
	&amp;quot;        \&amp;quot;firstName\&amp;quot; : \&amp;quot;John\&amp;quot;,\n&amp;quot; +&#xD;
	&amp;quot;        \&amp;quot;lastName\&amp;quot; : \&amp;quot;Doe\&amp;quot;\n&amp;quot; +&#xD;
	&amp;quot;    }\n&amp;quot; +&#xD;
	&amp;quot;}&amp;quot;;&#xD;
&#xD;
rsocketRequesterBuilder.tcp(&amp;quot;localhost&amp;quot;, 55555)&#xD;
	.route(&amp;quot;hire&amp;quot;)        // target function&#xD;
	.data(payload).       // data we&amp;#39;re sending&#xD;
	.send()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The expected output should be similar to the previous use cases, since the target destination is the same. &lt;/p&gt;&lt;h4&gt;&lt;a href="#conclusion" class="anchor" name="conclusion"&gt;&lt;/a&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;As you can see, while dealing with Cloud Events in the context of Spring, you have options:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;You can chose to care only about the contents of the Cloud Event yet maintain full control over the appearance of the outbound Cloud Event.&lt;/li&gt;
  &lt;li&gt;You can chose to deal with the Cloud Event itself through a &lt;code&gt;Message&lt;/code&gt; and rely on the provided utilities to simplify access to Cloud Event specific data.&lt;/li&gt;
  &lt;li&gt;You can choose an execution context without affecting your business logic (user code) while delegating to the framework to ensure the correctness of certain Cloud Event specifics, such as attribute prefixes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are just a few that are relevant to the context of this post, but there are more.&lt;/p&gt;
&lt;p&gt;Established and proven patterns, frameworks that implement those patterns, and layered and opinionated Spring Boot auto-configuration(s) make it all possible. Layers are important, as they let you compartmentalize your problem into a solution that can be re-used in other projects and integrations where the same problem exists. This effectively made current Cloud Event integration rather a simple effort, since most of the non-functional aspects that are not related to Cloud Event (that is, connect, send, receive, convert, retry, and so on) were already addressed by the individual frameworks behind both Spring Cloud Function and Spring Cloud Stream.&lt;/p&gt;
&lt;p&gt;And last but not least there is an alternative way of dealing with Cloud Events and Spring and that is via &lt;a href="https://github.com/cloudevents/sdk-java"&gt;Cloud Events Java SDK&lt;/a&gt; where you can also find an &lt;a href="https://github.com/cloudevents/sdk-java/tree/master/examples/spring-reactive"&gt;example&lt;/a&gt;.&lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>This Week in Spring - December 22nd, 2020</title>
    <link rel="alternate" href="https://spring.io/blog/2020/12/22/this-week-in-spring-december-22nd-2020" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-22:4312</id>
    <updated>2020-12-22T23:04:17Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! Welcome to another installment of &lt;em&gt;This Week in Spring!&lt;/em&gt; &lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s December 22nd, 2020, as I write this and I &lt;em&gt;can not&lt;/em&gt; believe we&amp;rsquo;re smack dab in the middle of the week and only have two shopping days until Christmas! I don&amp;rsquo;t know if it&amp;rsquo;s just that time of year and I&amp;rsquo;m flush with the normal amount of warm-n-fuzzies or if it&amp;rsquo;s just that, after a year like 2020, I&amp;rsquo;m very keen on savoring this precious reprieve. Either way, couldn&amp;rsquo;t be happier. I&amp;rsquo;ve got a cold! I&amp;rsquo;m sick and sneezing and my nose is running, but at least it&amp;rsquo;s not COVID-19, and at least I&amp;rsquo;ve got my family and my job, and - all things considered - I feel very, &lt;em&gt;very&lt;/em&gt;, &lt;em&gt;veery&lt;/em&gt; fortunate. &lt;/p&gt;
&lt;p&gt;And yes, that&amp;rsquo;s right, I enumerated my health, my family, and my job because - after ten wonderful years (and counting) - I feel like the Spring team are family and I feel like working with you, dear community, is a true and exceptional privilege. I get so many wonderful messages from folks whenever I publish this weekly roundup or a blog or a video, and I appreciate that folks. I have always appreciated it, but especially this year when I, like so many in the world, am otherwise completely isolated from people. Thank you, and please let me wish you the warmest of greetings (if you don&amp;rsquo;t celebrate Christmas) and the happiest of holidays (if you do celebrate Christmas). &lt;/p&gt;
&lt;p&gt;In that spirit, I was so happy when I assembled this week&amp;rsquo;s roundup and realized there&amp;rsquo;s a &lt;em&gt;ton&lt;/em&gt; of great stuff for us to dive into, so with that, let&amp;rsquo;s get to it! &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/18/a-bootiful-podcast-cloud-foundry-developer-advocate-shedrack-akintayo"&gt;A Bootiful Podcast: Cloud Foundry Developer Advocate Shedrack Akintayo&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/21/announcing-spring-cloud-stream-applications-2020-0-0-ga-release"&gt;Announcing Spring Cloud Stream Applications 2020.0.0 GA Release&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://inside.java/2020/12/21/podcast-010/"&gt;Episode 10 Project Panama - The Foreign Linker API with Maurizio Cimadamore and Jorn Vernee&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/making/status/1339155831145648129?s=12"&gt;Help us develop Spring Socks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/barcelonajug/status/1339695591891349506?s=12"&gt;Ill be joining a fun panel for the Barcelona JUG on the 28th and I hope to see you there&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://javarevisited.blogspot.com/2018/01/how-to-enable-http-basic-authentication-spring-security-java-xml-configuration.html?m=1#.X9mIqS3ZJ24.twitter"&gt;Javarevisited: How to enable HTTP Basic Authentication in Spring Security using Java and XML Configuration&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://netty.io/news/2020/12/09/quic-0-0-1-Final.html"&gt;Netty/Incubator/Codec/Quic 0.0.1.Final released&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://inside.java/2020/12/16/new-panama-ea-builds/"&gt;New Panama/Foreign EA builds, December 2020 edition&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://inside.java/2020/12/18/security-roadmap-update/"&gt;Oracle JRE and JDK Cryptographic Roadmap&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/ljcjug/status/1339508388728889344?s=12"&gt;My &amp;ldquo;Reactive Spring&amp;rdquo; at the LJC talk&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.vinsguru.com/reactor-repeat-vs-reactor-retry/amp/?__twitter_impression=true"&gt;Reactor retry vs. repeat&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/jonashackt/status/1341305148061192192?s=12"&gt;Some cool Spring Boot and GraalVM native image support in this issue&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/22/spring-cloud-2020-0-0-aka-ilford-is-available"&gt;Spring Cloud 2020.0.0 (aka Ilford) Is Available&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/16/spring-tools-4-9-0-released"&gt;Spring Tools 4.9.0 released&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/jonatan_ivanov/status/1341477187455655936?s=12"&gt;Spring cloud sleuth OpenTelemetry support has been released&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=jrCwx9qzutM&amp;feature=youtu.be"&gt;Tanzu GemFire for Kubernetes - Lets Review and Deploy an App - YouTube&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://blogs.vmware.com/opensource/2020/12/22/the-top-open-source-blogs-of-2020/"&gt;The Top Open Source Blogs of 2020&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.thymeleaf.org/releasenotes.html#thymeleaf-3.0.12"&gt;Thymeleaf 3.0.1.2 is now available&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://inside.java/2020/12/17/troubleshooting-native-memory-leaks/"&gt;Troubleshooting Native Memory Leaks in Java Applications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.training/understanding-inter-bean-method-reference-in-spring-configuration/"&gt;Understanding inter-bean method reference in Spring configuration ? Spring Training&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://google.dev/badges/playlists/cloud/springboot"&gt;Earn the &amp;ldquo;Use Spring Boot&amp;rdquo; on Google Cloud &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=1f10gr2pbvq&amp;feature=share"&gt;My GOTO 2019 Reactive Spring video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Spring Cloud 2020.0.0 (aka Ilford) Is Available</title>
    <link rel="alternate" href="https://spring.io/blog/2020/12/22/spring-cloud-2020-0-0-aka-ilford-is-available" />
    <category term="releases" label="Releases" />
    <author>
      <name>Ryan Baxter</name>
    </author>
    <id>tag:spring.io,2020-12-22:4311</id>
    <updated>2020-12-22T19:08:00Z</updated>
    <content type="html">&lt;p&gt;On behalf of the community, I am pleased to announce that the GA release of the &lt;a href="https://cloud.spring.io"&gt;Spring Cloud 2020.0&lt;/a&gt; Release Train is available today. The release can be found in &lt;a href="https://repo1.maven.org/maven2/org/springframework/cloud/spring-cloud-dependencies/2020.0.0/"&gt;Maven Central&lt;/a&gt;. You can check out the 2020.0 &lt;a href="https://github.com/spring-projects/spring-cloud/wiki/Spring-Cloud-2020.0-Release-Notes"&gt;release notes for more information&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;&lt;a href="#notable-changes-in-the-2020-0-release-train" class="anchor" name="notable-changes-in-the-2020-0-release-train"&gt;&lt;/a&gt;Notable Changes in the 2020.0 Release Train&lt;/h2&gt;
&lt;p&gt;This release requires Spring Boot 2.4.1. In general, this release was to fix bugs prior to release.&lt;/p&gt;
&lt;p&gt;See &lt;a href="https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes#known-issues"&gt;this page&lt;/a&gt; for a list of Known Issues.&lt;/p&gt;
&lt;p&gt;See the &lt;a href="https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes#breaking-changes"&gt;wiki&lt;/a&gt; for a list of all breaking changes in this release train.&lt;/p&gt;
&lt;p&gt;See all of the included issues and pull requests at the &lt;a href="https://github.com/orgs/spring-cloud/projects/51"&gt;Github project&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;&lt;a href="#spring-cloud-commons" class="anchor" name="spring-cloud-commons"&gt;&lt;/a&gt;Spring Cloud Commons&lt;/h3&gt;
&lt;p&gt;NOTE: Bootstrap has been disabled by default. The new way of importing configuration is via the new &lt;code&gt;spring.config.import&lt;/code&gt; functionality provided by Spring Boot 2.4. Please see the appropriate documentation for &lt;a href="https://docs.spring.io/spring-cloud-config/docs/3.0.0/reference/html/#config-data-import"&gt;Config Client&lt;/a&gt;, &lt;a href="https://docs.spring.io/spring-cloud-consul/docs/3.0.0/reference/html/#config-data-import"&gt;Consul&lt;/a&gt;, &lt;a href="https://docs.spring.io/spring-cloud-vault/docs/3.0.0/reference/html/#client-side-usage"&gt;Vault&lt;/a&gt;, and &lt;a href="https://docs.spring.io/spring-cloud-zookeeper/docs/3.0.0/reference/html/#config-data-import"&gt;Zookeeper&lt;/a&gt; for details on how to use them with the new config import.&lt;/p&gt;
&lt;p&gt;If you require the legacy bootstrap functionality add the &lt;code&gt;org.springframework.cloud:spring-cloud-starter-bootstrap&lt;/code&gt; dependency to your project.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Spring Cloud LoadBalancer now supports server statistics (&lt;a href="https://github.com/spring-cloud/spring-cloud-commons/issues/674"&gt;PR&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;General Security functionality was moved here from the now defunct Spring Cloud Security project &lt;a href="https://github.com/spring-cloud/spring-cloud-commons/pull/870/files"&gt;PR&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Support for decryption with &lt;code&gt;spring.config.import&lt;/code&gt; was added (&lt;a href="https://github.com/spring-cloud/spring-cloud-commons/issues/815"&gt;issue&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#spring-cloud-contract" class="anchor" name="spring-cloud-contract"&gt;&lt;/a&gt;Spring Cloud Contract&lt;/h3&gt;
&lt;p&gt;Documented how to clone the project on windows.&lt;/p&gt;&lt;h3&gt;&lt;a href="#spring-cloud-function" class="anchor" name="spring-cloud-function"&gt;&lt;/a&gt;Spring Cloud Function&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Support for Cloud Events. See &lt;a href="https://spring.io/blog/2020/12/10/cloud-events-and-spring-part-1"&gt;Cloud Events and Spring - part 1&lt;/a&gt; and &lt;a href="https://spring.io/blog/2020/12/23/cloud-events-and-spring-part-2"&gt;Cloud Events and Spring - part 2&lt;/a&gt;. You can also check out several samples available &lt;a href="https://github.com/spring-cloud/spring-cloud-function/tree/master/spring-cloud-function-samples"&gt;here&lt;/a&gt; and described in details in the blog posts mentioned before.&lt;/li&gt;
  &lt;li&gt;Support for &lt;a href="https://github.com/spring-cloud/spring-cloud-function/tree/master/spring-cloud-function-rsocket"&gt;RSocket&lt;/a&gt;. Separate blog post will be published shortly however &lt;a href="https://spring.io/blog/2020/12/23/cloud-events-and-spring-part-2"&gt;Cloud Events and Spring - part 2&lt;/a&gt; provides an example that uses RSocket.&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#spring-cloud-kubernetes" class="anchor" name="spring-cloud-kubernetes"&gt;&lt;/a&gt;Spring Cloud Kubernetes&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Added reactive discovery client implementation based on the Kubernetes Java Client (&lt;a href="https://github.com/spring-cloud/spring-cloud-kubernetes/pull/701"&gt;PR&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;Added Spring Cloud Loadbalancer implementation based on the Kubernetes Java Client (&lt;a href="https://github.com/spring-cloud/spring-cloud-kubernetes/pull/700"&gt;PR&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#spring-cloud-openfeign" class="anchor" name="spring-cloud-openfeign"&gt;&lt;/a&gt;Spring Cloud Openfeign&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Added support for wrapping feign clients in Spring Cloud CircuitBreakers (&lt;a href="https://github.com/spring-cloud/spring-cloud-openfeign/pull/446"&gt;PR&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;Spring Cloud OpenFeign security code moved from Spring Cloud Security to Spring Cloud OpenFeign (&lt;a href="https://github.com/spring-cloud/spring-cloud-openfeign/pull/445"&gt;PR&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;Support for LoadBalancer statistics has been added (&lt;a href="https://github.com/spring-cloud/spring-cloud-openfeign/pull/447"&gt;PR&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#spring-cloud-security" class="anchor" name="spring-cloud-security"&gt;&lt;/a&gt;Spring Cloud Security&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;This project was removed and code was moved to the individual Spring Cloud projects.&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#spring-cloud-gateway" class="anchor" name="spring-cloud-gateway"&gt;&lt;/a&gt;Spring Cloud Gateway&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Support for LoadBalancer statistics has been added (&lt;a href="https://github.com/spring-cloud/spring-cloud-gateway/pull/2086"&gt;PR&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#spring-cloud-netflix" class="anchor" name="spring-cloud-netflix"&gt;&lt;/a&gt;Spring Cloud Netflix&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;A number of deprecated modules have been removed. See the &lt;a href="https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes#breaking-changes"&gt;wiki&lt;/a&gt; for details&lt;/li&gt;
  &lt;li&gt;TLS properties now supported with the &lt;code&gt;RestTemplate&lt;/code&gt; based Eureka Client (&lt;a href="https://github.com/spring-cloud/spring-cloud-netflix/issues/3935"&gt;PR&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#spring-cloud-task" class="anchor" name="spring-cloud-task"&gt;&lt;/a&gt;Spring Cloud Task&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Added documentation for single step batch jobs. (&lt;a href="https://github.com/spring-cloud/spring-cloud-task/issues/755"&gt;PR&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following modules were updated as part of 2020.0.0:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Module &lt;/th&gt;
      &lt;th&gt;Version &lt;/th&gt;
      &lt;th&gt;Issues&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Circuitbreaker &lt;/td&gt;
      &lt;td&gt;2.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Contract &lt;/td&gt;
      &lt;td&gt;3.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Kubernetes &lt;/td&gt;
      &lt;td&gt;2.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Commons &lt;/td&gt;
      &lt;td&gt;3.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Openfeign &lt;/td&gt;
      &lt;td&gt;3.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Cloudfoundry &lt;/td&gt;
      &lt;td&gt;3.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Security &lt;/td&gt;
      &lt;td&gt;3.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Bus &lt;/td&gt;
      &lt;td&gt;3.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Cli &lt;/td&gt;
      &lt;td&gt;3.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Zookeeper &lt;/td&gt;
      &lt;td&gt;3.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Sleuth &lt;/td&gt;
      &lt;td&gt;3.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Consul &lt;/td&gt;
      &lt;td&gt;3.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Starter Build &lt;/td&gt;
      &lt;td&gt;2020.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Gateway &lt;/td&gt;
      &lt;td&gt;3.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Netflix &lt;/td&gt;
      &lt;td&gt;3.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Vault &lt;/td&gt;
      &lt;td&gt;3.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Config &lt;/td&gt;
      &lt;td&gt;3.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Task &lt;/td&gt;
      &lt;td&gt;2.3.0 &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-task/releases/tag/2.3.0"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As always, we welcome feedback on &lt;a href="https://github.com/spring-cloud/"&gt;GitHub&lt;/a&gt;, on &lt;a href="https://gitter.im/spring-cloud/spring-cloud"&gt;Gitter&lt;/a&gt;, on &lt;a href="https://stackoverflow.com/questions/tagged/spring-cloud"&gt;Stack Overflow&lt;/a&gt;, or on &lt;a href="https://twitter.com/SpringCloud"&gt;Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To get started with Maven with a BOM (dependency management only):&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint xml"&gt;&amp;lt;dependencyManagement&amp;gt;&#xD;
    &amp;lt;dependencies&amp;gt;&#xD;
        &amp;lt;dependency&amp;gt;&#xD;
            &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
            &amp;lt;artifactId&amp;gt;spring-cloud-dependencies&amp;lt;/artifactId&amp;gt;&#xD;
            &amp;lt;version&amp;gt;2020.0.0&amp;lt;/version&amp;gt;&#xD;
            &amp;lt;type&amp;gt;pom&amp;lt;/type&amp;gt;&#xD;
            &amp;lt;scope&amp;gt;import&amp;lt;/scope&amp;gt;&#xD;
        &amp;lt;/dependency&amp;gt;&#xD;
    &amp;lt;/dependencies&amp;gt;&#xD;
&amp;lt;/dependencyManagement&amp;gt;&#xD;
&amp;lt;dependencies&amp;gt;&#xD;
    &amp;lt;dependency&amp;gt;&#xD;
        &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
        &amp;lt;artifactId&amp;gt;spring-cloud-starter-config&amp;lt;/artifactId&amp;gt;&#xD;
    &amp;lt;/dependency&amp;gt;&#xD;
    &amp;lt;dependency&amp;gt;&#xD;
        &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
        &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-client&amp;lt;/artifactId&amp;gt;&#xD;
    &amp;lt;/dependency&amp;gt;&#xD;
    ...&#xD;
&amp;lt;/dependencies&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or with Gradle:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint groovy"&gt;buildscript {&#xD;
  dependencies {&#xD;
    classpath &amp;quot;io.spring.gradle:dependency-management-plugin:1.0.10.RELEASE&amp;quot;&#xD;
  }&#xD;
}&#xD;
&#xD;
apply plugin: &amp;quot;io.spring.dependency-management&amp;quot;&#xD;
&#xD;
dependencyManagement {&#xD;
  imports {&#xD;
    mavenBom &amp;#39;org.springframework.cloud:spring-cloud-dependencies:2020.0.0&amp;#39;&#xD;
  }&#xD;
}&#xD;
&#xD;
dependencies {&#xD;
  compile &amp;#39;org.springframework.cloud:spring-cloud-starter-config&amp;#39;&#xD;
  compile &amp;#39;org.springframework.cloud:spring-cloud-starter-netflix-eureka-client&amp;#39;&#xD;
  //...&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Announcing  Spring Cloud Stream Applications 2020.0.0 GA Release</title>
    <link rel="alternate" href="https://spring.io/blog/2020/12/21/announcing-spring-cloud-stream-applications-2020-0-0-ga-release" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Soby Chacko</name>
    </author>
    <id>tag:spring.io,2020-12-21:4309</id>
    <updated>2020-12-21T18:53:59Z</updated>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;We are glad to announce the GA release of the newly redesigned Spring Cloud Stream applications - &lt;a href="https://github.com/spring-cloud/stream-applications/releases/tag/v2020.0.0"&gt;2020.0.0&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We would like to use this release announcement as an opportunity to wrap up the blog series that we started in the summer. Therefore, consider this as part 15 of the blog series. In this blog, we are going to give a rundown of all the previous episodes in the series, but first, let us go through some release details.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="release-overview"&gt;&lt;a class="anchor" href="#release-overview"&gt;&lt;/a&gt;Release Overview&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;a href="https://github.com/spring-cloud/stream-applications/releases/tag/v2020.0.0"&gt;2020.0.0 GA&lt;/a&gt; release contains the completely revamped functional foundation for the event-streaming applications. The old structure was based on an &lt;a href="https://github.com/spring-cloud-stream-app-starters"&gt;app starter&lt;/a&gt; model in which the critical logic for the applications is provided as part of a starter module. The starters then form the foundation for the applications. While it worked for the previous four generations of these app starters (Avogadro, Bacon, Celsius, Darwin, and Einstein), it deemed necessary to rewrite these starters as reusable functions so that they can be used for a wide array of use cases beyond what is required in the out of the box applications. Therefore, many of the old app starters were refactored and redesigned as functions, suppliers, and consumers. For the out of the box Spring Cloud Stream binder based applications, we take these functional components and use them as the base to build them. Other custom applications, even non-streaming use cases, can be designed using these functional components as a foundation. The functions can be &lt;a href="https://github.com/spring-cloud/stream-applications/blob/master/docs/FunctionComposition.adoc"&gt;composed&lt;/a&gt; together to implement many other data integration use cases.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;There is a new single &lt;a href="https://github.com/spring-cloud/stream-applications"&gt;mono repository&lt;/a&gt; that hosts all the stream application components. The source for all the currently available functions and applications can be found there. These collections comprise components that satisfy a wide spectrum of use cases such as data ingestion, ETL, machine learning, analytics, file processing, etc. among many others. Take a look at the &lt;a href="https://github.com/spring-cloud/stream-applications/blob/master/README.adoc"&gt;README&lt;/a&gt; to get more information on what is available.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="version-changes"&gt;&lt;a class="anchor" href="#version-changes"&gt;&lt;/a&gt;Version Changes&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Starting with this release, we are moving to a &lt;a href="https://calver.org/"&gt;Calendar&lt;/a&gt; based versioning scheme. This is different from the old release train names which used the alphabetical scheme (scientists names). The new version is named &lt;code&gt;2020.0.0&lt;/code&gt;. It follows from the pattern &lt;code&gt;YYYY.MINOR.MICRO&lt;/code&gt;, where &lt;code&gt;MINOR&lt;/code&gt; is an incrementing number that starts at zero each year. The MICRO segment represents the suffixes previously used, where .0 is the first GA release, &lt;code&gt;.1&lt;/code&gt; analogous to &lt;code&gt;.SR1&lt;/code&gt;,  &lt;code&gt;.2&lt;/code&gt; analogous to &lt;code&gt;.SR2&lt;/code&gt;, so on and so forth. It is worth noting that although the release train is following the calendar versioning, the individual components (functions and applications) in it are named using a numbering scheme. For example, the functions are starting from &lt;code&gt;1.0.0&lt;/code&gt; and the applications are starting from &lt;code&gt;3.0.0&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Here is the project site for the new &lt;a href="https://spring.io/projects/spring-cloud-stream-applications"&gt;Stream Applications&lt;/a&gt;. The &lt;a href="https://docs.spring.io/stream-applications/docs/2020.0.0/reference/html/"&gt;reference docs&lt;/a&gt; contain more details on the various aspects of the applications.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Although noted on the release page, it is worth mentioning that the new applications are built using Spring Boot &lt;code&gt;2.3.7.RELEASE&lt;/code&gt;, Spring Cloud Stream &lt;code&gt;3.0.10.RELEASE&lt;/code&gt;, Spring Integration &lt;code&gt;5.3.4.RELEASE&lt;/code&gt;, and Spring Cloud Function &lt;code&gt;3.0.12.RELEASE&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="using-the-applications-on-spring-cloud-data-flow"&gt;&lt;a class="anchor" href="#using-the-applications-on-spring-cloud-data-flow"&gt;&lt;/a&gt;Using the Applications on Spring Cloud Data Flow&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The &lt;a href="https://github.com/spring-cloud/stream-applications/blob/master/README.adoc"&gt;out of the box applications&lt;/a&gt; in the release are primarily used to build data pipelines on &lt;a href="https://dataflow.spring.io/"&gt;Spring Cloud Data Flow&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For those who are using Spring Cloud Data Flow, here are the bulk update links for these new applications.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://dataflow.spring.io/kafka-maven-latest-v2" class="bare"&gt;https://dataflow.spring.io/kafka-maven-latest-v2&lt;/a&gt; -  Maven artifacts for Kafka&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://dataflow.spring.io/rabbitmq-maven-latest-v2" class="bare"&gt;https://dataflow.spring.io/rabbitmq-maven-latest-v2&lt;/a&gt; - Maven artifacts for RabbitMQ&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://dataflow.spring.io/kafka-docker-latest-v2" class="bare"&gt;https://dataflow.spring.io/kafka-docker-latest-v2&lt;/a&gt; - Docker artifacts for Kafka&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://dataflow.spring.io/rabbitmq-docker-latest-v2" class="bare"&gt;https://dataflow.spring.io/rabbitmq-docker-latest-v2&lt;/a&gt; - Docker artifacts for Kafka&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Note that these new links have a &lt;code&gt;-v2&lt;/code&gt; attached to them, but that is temporary. As many users are still using the &lt;a href="https://github.com/spring-cloud-stream-app-starters/app-starters-release/releases/tag/vEinstein.SR9"&gt;Einstein&lt;/a&gt; version of the applications, we want them to continue accessing them using the old links. Eventually, in a few months, we will switch these &lt;code&gt;-v2&lt;/code&gt; links as the main links.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;These applications can also run as standalone deployments. Here are some handy links to use these applications as standalone. This is good for testing something really quick for example. You can just copy the URL for the application you want and download it using &lt;code&gt;wget&lt;/code&gt;, &lt;code&gt;curl&lt;/code&gt; etc.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://repo.maven.apache.org/maven2/org/springframework/cloud/stream/app/stream-applications-descriptor/2020.0.0/stream-applications-descriptor-2020.0.0.kafka-apps-maven-repo-url.properties"&gt;Kafka based maven applications&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://repo.maven.apache.org/maven2/org/springframework/cloud/stream/app/stream-applications-descriptor/2020.0.0/stream-applications-descriptor-2020.0.0.rabbit-apps-maven-repo-url.properties"&gt;RabbitMQ based maven applications&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="maven-plugin-for-generating-applications"&gt;&lt;a class="anchor" href="#maven-plugin-for-generating-applications"&gt;&lt;/a&gt;Maven Plugin for Generating Applications&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We use a &lt;a href="https://github.com/spring-cloud/spring-cloud-dataflow-apps-plugin/tree/master/spring-cloud-dataflow-apps-generator-plugin"&gt;maven plugin&lt;/a&gt; to generate out of the box applications. This plugin is also redesigned from the ground up for this release. This &lt;a href="https://github.com/spring-cloud/spring-cloud-dataflow-apps-plugin/blob/master/spring-cloud-dataflow-apps-generator-plugin/README.adoc"&gt;README&lt;/a&gt; contains instructions for how to use the plugin to generate applications.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="building-custom-applications-using-a-github-template-repository"&gt;&lt;a class="anchor" href="#building-custom-applications-using-a-github-template-repository"&gt;&lt;/a&gt;Building Custom Applications Using a GitHub Template Repository&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We provide &lt;a href="https://docs.github.com/en/free-pro-team@latest/github/creating-cloning-and-archiving-repositories/creating-a-repository-from-a-template"&gt;GitHub template repositories&lt;/a&gt;, using which we can build custom stream applications that provide all the necessary infrastructure needed to run these applications on Spring Cloud Data Flow. In other words, when you use the template repositories for creating a custom application, you can take the application and run it on Spring Cloud Data Flow in the same way as the out of the box applications work.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Here are the links to the template repositories.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/spring-cloud/dataflow-app-kafka"&gt;GitHub template repositories for Kafka binder based applications&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/spring-cloud/dataflow-app-rabbit"&gt;GitHub template repositories for RabbitMQ binder based applications&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You can click on the &lt;code&gt;Use this template&lt;/code&gt; at the top of the repository to create a new custom repository for the new application.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="wrapping-up-the-blog-series"&gt;&lt;a class="anchor" href="#wrapping-up-the-blog-series"&gt;&lt;/a&gt;Wrapping up the Blog Series&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now that we covered all the &lt;code&gt;2020.0.0&lt;/code&gt; release details, as mentioned before, let us use this as an opportunity to wrap up the blog series that we started in the summer. The series covered many different topics and use cases. Below, you can find links to all of them and a summary description of what was covered in each blog.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;Blog 1&lt;/strong&gt;: &lt;a href="https://spring.io/blog/2020/07/13/introducing-java-functions-for-spring-cloud-stream-applications-part-0"&gt;Introducing Java Functions for Spring Cloud Stream Applications - Part 0&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The first blog in this series gives us an overall vision and direction for this project. It starts with some historical context of how we got here. It then set the stage for these new functions and the Spring Cloud Stream applications based on them.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;Blog 2&lt;/strong&gt;: &lt;a href="https://spring.io/blog/2020/07/20/introducing-java-functions-for-spring-cloud-stream-applications-part-1"&gt;Introducing Java Functions for Spring Cloud Stream Applications - Part 1&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This episode gives a detailed analysis of functional composition and then delved deep into how function composition works in Spring Cloud Stream. This blog provides us some good directions on how we can use the existing source applications to make use of other functions bundled with them and auto-configured. It also demonstrates how task launch requests can be made from a source application.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;Blog 3&lt;/strong&gt;: &lt;a href="https://spring.io/blog/2020/07/27/creating-a-supplier-function-and-generating-spring-cloud-stream-source"&gt;Creating a Supplier Function and generating Spring Cloud Stream Source&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this part, we see how to write a new Supplier function from the ground up and use it to build a Spring Cloud Stream source. We used the existing RSS feed adapter in Spring Integration as an example to create a feed-supplier which we then used to build a feed source. This blog gives enough templates for new suppliers and sources.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;Blog 4&lt;/strong&gt;: &lt;a href="https://spring.io/blog/2020/08/03/creating-a-function-for-consuming-data-and-generating-spring-cloud-stream-sink-applications"&gt;Creating a function for consuming data and generating Spring Cloud Stream Sink applications&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Similar to blog &lt;code&gt;#3&lt;/code&gt;, this one demonstrates writing a new consumer function and using that to build a Spring Cloud Stream sink application. We used RSocket as an example and built a consumer function using the fire-and-forget strategy in RSocket. This blog also gives enough recipes for creating new consumer functions and sinks.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;Blog 5&lt;/strong&gt;: &lt;a href="https://spring.io/blog/2020/08/10/case-study-build-and-run-a-streaming-application-using-an-http-source-and-a-jdbc-sink"&gt;Case Study: Build and Run a Streaming Application Using an HTTP Source and a JDBC Sink&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this blog, we demonstrate a data pipeline using &lt;code&gt;HTTP | JDBC&lt;/code&gt;. This is a very detailed blog that shows invoking an HTTP POST endpoint and then inserts the data posted through the endpoint into a relational database. This one also is very interesting in that it demonstrates the full gamut of the lifecycle of these applications by going all the way from functions, applications and then finally showing how to deploy this pipeline on Spring Cloud Data Flow.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;Blog 6&lt;/strong&gt;: &lt;a href="https://spring.io/blog/2020/08/17/case-study-http-request-function-and-processor"&gt;Case Study: HTTP Request Function and Processor&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This is a very intriguing blog in which we see how HTTP request functions are used. HTTP request function is a generic component that can be used to satisfy many different use cases that require the invocation of an HTTP endpoint. The function gives many different configuration options. This blog shows how this function works standalone and as part of a pipeline. The blog explores some image processing use cases and file sources.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;Blog 7&lt;/strong&gt;: &lt;a href="https://spring.io/blog/2020/08/25/case-study-reading-from-a-file-and-writing-to-mongodb"&gt;Case Study: Reading from a file and writing to MongoDB&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This one looks at a simple data pipeline for &lt;code&gt;File | MongoDB&lt;/code&gt;. Data is received through a file source and then inserted into a MongoDB database. The blog looks at the underlying file supplier/source and MongoDB consumer/sink. Then it shows how to run the pipeline as standalone deployments. Finally, it shows how to orchestrate and run the pipeline on Spring Cloud Data Flow.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;Blog 8&lt;/strong&gt;: &lt;a href="https://spring.io/blog/2020/09/10/case-study-relational-database-source-and-file-sink"&gt;Case Study: Relational Database Source and File Sink&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This blog looks at another use case in which a database is used as a source and the information extracted from it is sent to a destination file. It explores the supporting functions - JDBC supplier and file consumer&amp;#8201;&amp;#8212;&amp;#8201;and then shows us its configuration options. Then it shows, how the applications (JDBC source and File sink) from these components are used standalone. The blog ends by showing how commercial JDBC drivers can be added to customize the existing JDBC source application.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;Blog 9&lt;/strong&gt;: &lt;a href="https://spring.io/blog/2020/09/29/case-study-remote-file-ingest-with-spring-cloud-data-flow"&gt;Case Study: Remote File Ingest with Spring Cloud Data Flow&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this part, we looked at another popular use case that we see in Spring Cloud Data Flow applications pipelines. It shows us how remote file ingest workloads are deployed on Spring Cloud Data Flow. As part of the use case, the blog touches on a handful of different functions and applications such as FTP and SFTP suppliers and sources, Amazon S3 supplier and source, task launcher function and its sink, etc. This blog teaches us several insights into how various components can be chained together to build powerful applications with demanding use cases. This blog ends by demonstrating the remote file ingest use case on Spring Cloud Data Flow using S3 buckets as an example.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;Blog 10&lt;/strong&gt;: &lt;a href="https://spring.io/blog/2020/10/26/case-study-aggregator-function-and-processor"&gt;Case Study: Aggregator Function and Processor&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Data aggregation is yet another widely popular use case in data integration workloads. In this blog, we see how the aggregator function can act as a conduit to build applications that require data aggregation. It shows us how the aggregator pattern works using the support for this in Spring Integration. The blog teaches us how this function is configured using various options and how it is pre-loaded with the support for many different persistent stores for aggregation. This blog also demonstrates how the aggregator function can be composed with other functions such as splitter and other custom functions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;Blog 11&lt;/strong&gt;: &lt;a href="https://spring.io/blog/2020/11/16/case-study-elasticsearch-sink"&gt;Case Study: Elasticsearch sink&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this episode, we look at the consumer function for Elasticsearch and its corresponding sink application. It looks at the various configuration options and explains how the consumer can be used standalone in custom applications. The blog ends by demonstrating how the Elasticsearch sink can run as a standalone application deployment.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;Blog 12&lt;/strong&gt;: &lt;a href="https://spring.io/blog/2020/12/14/case-study-change-data-capture-cdc-analysis-with-cdc-debezium-source-and-analytics-sink-in-real-time"&gt;Case Study: Change Data Capture (CDC) Analysis with CDC Debezium source and Analytics sink in Real-Time&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This is a very detailed blog in which we see the change data capture (CDC) pattern in live-action. The author gives us an analysis of how CDC works by diving deep into the CDC-debezium supplier and its internal intricacies. It then explains, how the CDC-debezium source is made from the supplier and used, by going over the various configuration options. This blog also looks at the analytics consumer function and its corresponding sink application. Finally, this blog goes into the depths of how the data pipeline of &lt;code&gt;CDC | analytics&lt;/code&gt; works on Spring Cloud Data Flow. Once deployed on Spring Cloud Data Flow and the pipeline is activated, it shows how the analytics from the CDC source application is displayed on a Grafana dashboard. This blog ends by giving us some pointers on the future direction of these particular classes of functions and applications.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;Blog 13&lt;/strong&gt;: &lt;a href="https://spring.io/blog/2020/12/15/testing-spring-cloud-stream-applications-part-1"&gt;Testing Spring Cloud Stream Applications - Part 1&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This is also another very detailed blog with two parts (series within a series) that expounds all things related to how testing works with the functions and applications. It jumps deep into the heart of testing by explaining various testing strategies and demonstrating how it works with &lt;a href="https://www.testcontainers.org/"&gt;testcontainers&lt;/a&gt; which is a technology we use a lot in testing the components in stream-applications. The blog demonstrates the concepts by developing a consumer for &lt;code&gt;Couchbase&lt;/code&gt; and its analogous sink. It ends the discussion by showing how Spring Cloud Stream test binder can function as a good testing strategy to integration test the sink application.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;Blog 14&lt;/strong&gt;: &lt;a href="https://spring.io/blog/2020/12/15/testing-spring-cloud-stream-applications-part-2"&gt;Testing Spring Cloud Stream Applications - Part 2&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This is a continuation of blog #13 in which we now see how we can do the integration and acceptance testing for the sink application developed (Couchbase sink) with real environments rather than using the test binder. Reading together, blog #13 and #14 can give us a lot of invaluable insights into using good testing strategies not only for stream application components but to a greater extent for generic data integration use cases as well.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;Blog 15&lt;/strong&gt;: The very blog that you are reading. If you are reading up to this point, you are now about to finish reading the 15th part of this blog series. This blog goes over the &lt;code&gt;2020.0.0&lt;/code&gt; release of the stream-applications that contain all the components and applications we discussed. As you see, we are also giving a rundown through all the blogs in the series in this final edition.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="in-conclusion"&gt;&lt;a class="anchor" href="#in-conclusion"&gt;&lt;/a&gt;In Conclusion&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;There are many other functions, applications, components, and use cases that we did not cover as part of this blog series. You can find them certainly in the &lt;a href="https://github.com/spring-cloud/stream-applications"&gt;stream-applications repository&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Thank you for coming with us on this journey through this blog series. We hope you enjoyed it. We certainly value your suggestions, opinions, and ideas. Please continue to engage with us by creating bug reports and feature requests on the &lt;a href="https://github.com/spring-cloud/stream-applications"&gt;Github repository&lt;/a&gt; and asking questions on StackOverflow using the &lt;a href="https://stackoverflow.com/questions/tagged/spring-cloud-stream"&gt;spring-cloud-stream&lt;/a&gt; or &lt;a href="https://stackoverflow.com/questions/tagged/spring-cloud-dataflow"&gt;spring-cloud-dataflow&lt;/a&gt; tag. Here are some &lt;a href="https://github.com/spring-cloud/stream-applications/blob/master/docs/Contributing.adoc"&gt;contribution guidelines&lt;/a&gt; for adding new features and components to the repository or modifying the existing ones. Speaking of contributions to the repository, we welcome any pull requests from the community.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>A Bootiful Podcast: Cloud Foundry Developer Advocate Shedrack Akintayo</title>
    <link rel="alternate" href="https://spring.io/blog/2020/12/18/a-bootiful-podcast-cloud-foundry-developer-advocate-shedrack-akintayo" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-18:4308</id>
    <updated>2020-12-18T00:52:25Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! In this episode, &lt;a href="http://twitter.com/starbuxman"&gt;Josh Long (@starbuxman)&lt;/a&gt; talks to Cloud Foundry Developer Advocate &lt;a href="https://twitter.com/coder_blvck"&gt;Shedrack Akintayo (@coder_blvck) &lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;Also: Happy Holidays! &lt;/p&gt;
&lt;iframe title="Cloud Foundry Developer Advocate Shedrack Akintayo" height="122" width="100%" style="border: none;" scrolling="no" data-name="pb-iframe-player" src="https://www.podbean.com/media/player/apa96-f5559d?from=pb6admin&amp;download=1&amp;version=1&amp;auto=0&amp;share=1&amp;download=1&amp;rtl=0&amp;fonts=Helvetica&amp;skin=1&amp;pfauth=&amp;btn-skin=107"&gt;&lt;/iframe&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Spring Tools 4.9.0 released</title>
    <link rel="alternate" href="https://spring.io/blog/2020/12/16/spring-tools-4-9-0-released" />
    <category term="releases" label="Releases" />
    <author>
      <name>Martin Lippert</name>
    </author>
    <id>tag:spring.io,2020-12-16:4307</id>
    <updated>2020-12-16T16:02:01Z</updated>
    <content type="html">&lt;p&gt;Dear Spring Community,&lt;/p&gt;
&lt;p&gt;I am happy to announce the 4.9.0 release of the Spring Tools 4 for Eclipse, Visual Studio Code, and Theia.&lt;/p&gt;&lt;h4&gt;&lt;a href="#major-changes-to-the-spring-tools-4-for-eclipse-distribution" class="anchor" name="major-changes-to-the-spring-tools-4-for-eclipse-distribution"&gt;&lt;/a&gt;major changes to the Spring Tools 4 for Eclipse distribution&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;updated to Eclipse 2020-12 release (including support for Java 15)&lt;/li&gt;
&lt;/ul&gt;&lt;h4&gt;&lt;a href="#reminder" class="anchor" name="reminder"&gt;&lt;/a&gt;reminder&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;the Eclipse-based distribution of the Spring Tools 4 requires a JDK11 (or newer) to run on&lt;/li&gt;
  &lt;li&gt;ships with an embedded JDK15 runtime, no need to install or configure a specific JDK to run the IDE on anymore&lt;/li&gt;
&lt;/ul&gt;&lt;h4&gt;&lt;a href="#additional-changes" class="anchor" name="additional-changes"&gt;&lt;/a&gt;additional changes&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;(Spring Boot)&lt;/em&gt; new: show bean startup performance metrics in live hovers and code lenses (details in the user guide)&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;(Spring Boot)&lt;/em&gt; new: show basic request mapping performance metrics in live hovers and code lensses (details in the user guide)&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;(Spring Boot)&lt;/em&gt; new: provide content-assist for constructor-arg name in Spring XML config files (&lt;a href="https://github.com/spring-projects/sts4/issues/562"&gt;#562&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;(Spring Boot)&lt;/em&gt; fixed: language-server-internal exception happening when saving a file that has a space or other special characters in its name or path&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;(Eclipse)&lt;/em&gt; improvement: added support for custom scripts to create docker images when deploying a boot app to docker in the boot dashboard (details in the user guide)&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;(Eclipse)&lt;/em&gt; fixed: enable live hover action for more docker-related nodes in the boot dashboard&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;(Concourse)&lt;/em&gt; fixed: navigation in pipeline files with VSCode Concourse CI extension doesn&amp;rsquo;t work everytime (&lt;a href="https://github.com/spring-projects/sts4/issues/483"&gt;#483&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To download the distribution for Eclipse and find links to the marketplace entries for Visual Studio Code and Theia, please go visit:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Spring Tools 4: &lt;a href="https://spring.io/tools/"&gt;https://spring.io/tools/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Detailed changes can be found here: &lt;a href="https://github.com/spring-projects/sts4/wiki/Changelog#2020-12-16-490-release-incl-language-servers-version-1240"&gt;https://github.com/spring-projects/sts4/wiki/Changelog#2020-12-16-490-release-incl-language-servers-version-1240&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Spring Tools 4.9.1 is scheduled to be released in early Feb 2021.&lt;/p&gt;
&lt;p&gt;Enjoy!&lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>This Week in Spring - December 15th, 2020</title>
    <link rel="alternate" href="https://spring.io/blog/2020/12/16/this-week-in-spring-december-15th-2020" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-16:4306</id>
    <updated>2020-12-16T03:21:19Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! Welcome to another installment of &lt;em&gt;This Week in Spring&lt;/em&gt;! Can you believe it&amp;rsquo;s already December 15th? Me either! Another few weeks and this soul annhilating year will be over with and we&amp;rsquo;ll be staring down 2021 filled with new hopes and possibilities! How are you? (Have you dipped into the eggnog yet?) I&amp;rsquo;m doing alright, thanks! I&amp;rsquo;ve been busy, as usual. &lt;/p&gt;
&lt;p&gt;Most of that was fun stuff. But, some of that, I confess, was a mess of my own making. I spent Monday cleaning up a fire I&amp;rsquo;d set for myself. You see, I got a little sloppy with last week&amp;rsquo;s podcast episode. Last week, I was editing the audio for an episode with Spring Batch colead Mahmoud Ben Hassine and - in the middle of that - was pushing an interview I&amp;rsquo;d done with Dion Almaer out the door for publication that week. So, two episodes: one with Dion, one with Mahmoud. Dion was slated for last week. Mahmoud&amp;rsquo;s was slated for a future week. On top of that I&amp;rsquo;ve been toiling night and day it feels like on &lt;a href="http://github.com/bootiful-podcast"&gt;the production pipeline for my podcasts&lt;/a&gt;, living that &lt;code&gt;kubectl apply -k $WORKING_DIR&lt;/code&gt; life, and I was tired of some of the issues still lingering but figured I could, basically trust the system. So I published the episode with Dion. I got everything right, &lt;em&gt;except&lt;/em&gt; the interview was with Mahmoud. Not Dion. So it said Dion. But I&amp;rsquo;d accidentally sent out the wrong episode. Awkward. Worse, after I published that episode, figuring I had a week to make a mess before I&amp;rsquo;d next have to publish an episode, I started making a mess of the codebase. I broke stuff. Would&amp;rsquo;ve been no big deal. I would&amp;rsquo;ve sorted it out! But yesterday, Monday, I realize people are complaining that I&amp;rsquo;d bungled the audio: published the preface and description for Dion but published the audio interview with Mahmoud. So I raced to fix it, except production was down! So I spent Monday dodging between meetings and calls and trying to get the system restored. I finally got the system on its feet again late last night - both episodes with the correct titling and audio and links and photos went out and it was good. Thank you so much for your patience, community. I have egg on my face. &lt;/p&gt;
&lt;p&gt;Anyway, everything&amp;rsquo;s fine now. I&amp;rsquo;m not gonna touch a thing until the new episode, due later this week, rolls out! And, bonus, you get not one, but &lt;em&gt;two&lt;/em&gt; episodes this week: I published both episodes last night. So, in total, you&amp;rsquo;ll get three episodes in a seven-day period, not one. Huzzah. &lt;/p&gt;
&lt;p&gt;This morning I had the privilege of speaking at the Warsaw JUG at their last meeting for the year. Thank you so much for a lively crowd and a wonderful event, Warsaw! &lt;/p&gt;
&lt;p&gt;Now then, we&amp;rsquo;ve got a lot of good stuff to get to this week so, without further ado&amp;hellip; &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/15/a-bootiful-podcast-spring-batch-co-lead-mahmoud-ben-hassine"&gt;A Bootiful Podcast: Spring Batch co-lead Mahmoud Ben Hassine&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/14/a-bootiful-podcast-open-web-legend-dion-almaer"&gt;A Bootiful Podcast: open-web legend Dion Almaer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://blog.frankel.ch/hack-ease-usage-log4j2-spring-boot/"&gt;A dirty hack to ease the usage of Log4J2 in Spring Boot&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/14/case-study-change-data-capture-cdc-analysis-with-cdc-debezium-source-and-analytics-sink-in-real-time"&gt;Case Study: Change Data Capture (CDC) Analysis with CDC Debezium source and Analytics sink in Real-Time&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/10/cloud-events-and-spring-part-1"&gt;Cloud Events and Spring - part 1&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://stackoverflow.com/questions/65254112/correct-usage-of-loadbalancersocketclient-with-springs-rsocketrequester/65268468#65268468"&gt;Correct usage of LoadbalanceRSocketClient with Spring&amp;rsquo;s RSocketRequester - Stack Overflow&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://inside.java/2020/12/11/podcast-009/"&gt;Episode 9 Project Panama - The Foreign Memory Access API with Maurizio Cimadamore and Jorn Vernee&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://blog.jetbrains.com/kotlin/2020/12/expedia-group-bootiful-apis-with-graphql-and-kotlin/"&gt;Expedia Group: Bootiful APIs With GraphQL and Kotlin ? Kotlin Blog | JetBrains&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/09/first-milestone-of-spring-data-2021-0-0-released"&gt;First milestone of Spring Data 2021.0.0 released&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/KotlinKbug/status/1337328725348716546"&gt;Kotlin Belfast User Group (KBUG) on Twitter: &amp;quot;In lieu of a Dec event please accept our Kotlin Christmas Stocking. 16 sets of recommendations, from recognised experts, to improve your @kotlin coding. We hope you enjoy. Thanks to all our contributors. Merry&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.infoq.com/news/2020/12/kubernetes-120-rickard/"&gt;Kubernetes 1.20: Q&amp;amp;A with Release Lead and VMware Engineer Jeremy Rickard&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=cEjU6-WOb3Q&amp;list=PLKKQHTLcxDVbJtlef15003TYaEkq1ZY8c&amp;index=15"&gt;Reactive Summit 2020: Josh Long, Bootiful RSocket - YouTube&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://blogs.vmware.com/opensource/2020/12/09/salt-open-source-projects/"&gt;Salt Enhances a Number of Key Open Source Projects&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://developer.okta.com/blog/2020/12/14/spring-session-redis"&gt;Scaling Secure Applications with Spring Session and Redis | Okta Developer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/10/spring-boot-2-2-12-available-now"&gt;Spring Boot 2.2.12 available now&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/11/spring-boot-2-3-7-available-now"&gt;Spring Boot 2.3.7 available now&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/11/spring-boot-2-4-1-available-now"&gt;Spring Boot 2.4.1 available now&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/15/spring-cloud-2020-0-0-rc1-aka-ilford-is-available"&gt;Spring Cloud 2020.0.0-RC1 (aka Ilford) Is Available&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://developer.okta.com/blog/2020/12/07/spring-cloud-config"&gt;Spring Cloud Config for Shared Microservice Configuration | Okta Developer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://developer.okta.com/blog/2020/12/07/spring-cloud-config?fbclid=IwAR05sW4ucHtjyqKIpzFn7OS6tjaaYzj86Ll3Y1aaUPi-X1HhztW_uix3BAs"&gt;Spring Cloud Config for Shared Microservice Configuration | Okta Developer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://tanzu.vmware.com/content/blog/spring-cloud-data-flow-for-kubernetes-1-2-offers-real-time-alerts-and-new-dashboard"&gt;Spring Cloud Data Flow for Kubernetes 1.2 is now available for desert&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/09/spring-data-2020-0-2-neumann-sr6-and-moore-sr12-available"&gt;Spring Data 2020.0.2, Neumann-SR6, and Moore-SR12 available&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/09/spring-framework-5-3-2-5-2-12-5-1-20-5-0-20-and-4-3-30-available-now"&gt;Spring Framework 5.3.2, 5.2.12, 5.1.20, 5.0.20, and 4.3.30 available now&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/11/spring-statemachine-3-0-0-rc1-released"&gt;Spring Statemachine 3.0.0-RC1 Released&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/10/spring-vault-2-2-3-release-available"&gt;Spring Vault 2.2.3.RELEASE available&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/10/spring-vault-2-3-0-rc1-available"&gt;Spring Vault 2.3.0 RC1 available&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/15/testing-spring-cloud-stream-applications-part-1"&gt;Testing Spring Cloud Stream Applications - Part 1&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2020/12/15/testing-spring-cloud-stream-applications-part-2"&gt;Testing Spring Cloud Stream Applications - Part 2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?app=desktop&amp;v=rWNYPRxihno"&gt;vSphere With Tanzu DDS - Ep 5 - Exploring a Tanzu Kubernetes Cluster - YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Testing Spring Cloud Stream Applications - Part 2</title>
    <link rel="alternate" href="https://spring.io/blog/2020/12/15/testing-spring-cloud-stream-applications-part-2" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>David Turanski</name>
    </author>
    <id>tag:spring.io,2020-12-11:4301</id>
    <updated>2020-12-15T19:05:52Z</updated>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;This is Part 2 of Testing Stream Applications. In &lt;a href="https://spring.io/blog/2020/12/15/testing-spring-cloud-stream-applications-part-1"&gt;Part 1&lt;/a&gt; we implemented and tested the core function needed for our sample &lt;a href="https://github.com/spring-cloud/spring-cloud-stream-samples/tree/master/function-based-stream-app-samples/couchbase-stream-applications"&gt;couchbase-sink&lt;/a&gt; application. The tests at the function level covered expected success and error scenarios and relied on &lt;a href="https://www.testcontainers.org/"&gt;Testcontainers&lt;/a&gt; to provision a Couchbase cluster. This post assumes you have read Part 1 and continues where it left off.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="couchbase-sink"&gt;&lt;a class="anchor" href="#couchbase-sink"&gt;&lt;/a&gt;Couchbase Sink&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In Part 1 we verified that the function we wrote for upserting data into Couchbase works as expected.  We can now use the function,  exposed as a &lt;code&gt;java.util.Consumer&lt;/code&gt;,  to implement a sink to use in a data pipeline built with Spring Cloud Stream. Like most of the pre-packaged stream applications, we simply embed the function configuration into a Spring Boot application. Unlike the pre-packaged applications which generate identical applications configured for Kafka and Rabbit, we will roll our own to use the Kafka binder.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Here&amp;#8217;s the main application class:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;@SpringBootApplication
@Import(CouchbaseConsumerConfiguration.class)
public class CouchbaseSinkApplication {
	public static void main(String... args) {
		new SpringApplication(CouchbaseSinkApplication.class).run(args);
	}
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We also need to add some dependencies: The function, Spring Cloud Stream, and the Kafka binder.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="xml"&gt;&amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;io.spring.example&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;couchbase-consumer&amp;lt;/artifactId&amp;gt;
    &amp;lt;/dependency&amp;gt;
    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-cloud-stream&amp;lt;/artifactId&amp;gt;
    &amp;lt;/dependency&amp;gt;
    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-boot-starter-actuator&amp;lt;/artifactId&amp;gt;
    &amp;lt;/dependency&amp;gt;
    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-cloud-stream-binder-kafka&amp;lt;/artifactId&amp;gt;
    &amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;And, since we are rolling our own, we can set some required properties in &lt;code&gt;application.properties&lt;/code&gt;. Since &lt;code&gt;couchbase-consumer&lt;/code&gt; includes 2 candidate functions, we need to tell Spring Cloud Stream to use the &lt;code&gt;Consumer&lt;/code&gt; wrapper. Also, we alias the default consumer input binding name &lt;code&gt;couchbaseConsumer-in-0&lt;/code&gt; to &lt;code&gt;input&lt;/code&gt; so the sink to work with Spring Cloud Data Flow.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code&gt;spring.cloud.function.definition=couchbaseConsumer
spring.cloud.stream.function.bindings.couchbaseConsumer-in-0=input&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;That&amp;#8217;s literally it! At least we think so. How can we be sure? The kind of tests we need, not surprisingly, are similar to the function level tests. But we don&amp;#8217;t really need to run every test case, since we already know how the function will behave within a boot application with various property settings. But we haven&amp;#8217;t actually invoked the function via Spring Cloud Stream yet. Also, it doesn&amp;#8217;t cost so much since we can reuse much of the test code we wrote for the function. So we only need a "smoke test" to run the happy path to make sure we didn&amp;#8217;t leave out some required dependency, or that there are typos in our configuration properties, are that there are no gotchas now, or whenever we upgrade some dependency down the road. Here we configure a Couchbase TestContainer, as we did to test the function. But instead of invoking the function directly, we will let Spring Cloud Stream do it when we send a message to an input destination configured for the sink. For this test, we use the &lt;code&gt;TestChannelBinder&lt;/code&gt;, an in-memory binder provided by the following dependency:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="xml"&gt;&amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-cloud-stream&amp;lt;/artifactId&amp;gt;
        &amp;lt;type&amp;gt;test-jar&amp;lt;/type&amp;gt;
        &amp;lt;classifier&amp;gt;test-binder&amp;lt;/classifier&amp;gt;
        &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We use &lt;code&gt;TestChannelBinderConfiguration.getCompleteConfiguration(CouchbaseSinkApplication.class)&lt;/code&gt; to add the TestChannelBinder to our application context for our test.
This gives us an &lt;code&gt;InputDestination&lt;/code&gt; bean to send messages to the sink. As in the function test, we use the &lt;code&gt;Cluster&lt;/code&gt; object to verify the data is present in Couchbase.
Since the &lt;em&gt;upsert&lt;/em&gt; operation is asynchronous, we need to poll the data store for some time until the data is there.
The &lt;a href="https://github.com/awaitility/awaitility"&gt;awaitility&lt;/a&gt; library is great for testing asynchronous systems.
In this case, we&amp;#8217;ll give it 10 seconds before we assume the operation has failed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;@Testcontainers
public class CouchbaseSinkApplicationTests {
  @Container
  static CouchbaseContainer container =
          new CouchbaseContainer("couchbase/server:6.6.0")
             .withBucket(new BucketDefinition("test"));

  static Map&amp;lt;String, Object&amp;gt; connectProperties = new HashMap&amp;lt;&amp;gt;();

  @BeforeAll
  static void initialize() {
    connectProperties.put("spring.couchbase.connection-string", container.getConnectionString());
    connectProperties.put("spring.couchbase.username", container.getUsername());
    connectProperties.put("spring.couchbase.password", container.getPassword());
  }

  @Test
  void test() {
    try (ConfigurableApplicationContext context = new SpringApplicationBuilder(
      TestChannelBinderConfiguration
        .getCompleteConfiguration(CouchbaseSinkApplication.class))
	.web(WebApplicationType.NONE)
        .properties(connectProperties)
        .run("--couchbase.consumer.bucketExpression='test'",
               "--couchbase.consumer.keyExpression=payload.email")) {
        InputDestination inputDestination = context.getBean(InputDestination.class);
        Cluster cluster = context.getBean(Cluster.class);
        inputDestination.send(new GenericMessage&amp;lt;&amp;gt;(
           new User("Bart Simpson", "bart@simpsons.com")));

       await().atMost(Duration.ofSeconds(10)).untilAsserted(() -&amp;gt; {
          User user = cluster.bucket("test")
                .defaultCollection().get("bart@simpsons.com")
                .contentAs(User.class);
         assertThat(user).isNotNull();
         assertThat(user.getName()).isEqualTo("Bart Simpson");
       });
     }
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="integration-testing"&gt;&lt;a class="anchor" href="#integration-testing"&gt;&lt;/a&gt;Integration Testing&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;At this point, we have good test coverage between the application and function tests. But we have not yet verified that the application binary that we want to build and deploy works in a true integration environment.
Since the sink application uses the Kafka binder, the integration test environment requires a Kafka broker, a Couchbase cluster, and our deployed application.
We can deploy and run the Spring Boot executable jar directly. More often these days, it is a container image.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Generally, it is not too risky to assume that the sink built as a container will work, but we at least want to make sure that we know how to configure the application to use an external Kafka broker and Couchbase cluster, and that we built our image correctly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For the pre-built Spring Cloud Stream applications, we have further reason to test the built artifacts. The core applications do not provide any additional code. Instead, we use the &lt;a href="https://github.com/spring-cloud/spring-cloud-dataflow-apps-plugin/tree/master/spring-cloud-dataflow-apps-generator-plugin"&gt;spring-cloud-dataflow-apps-generator-plugin&lt;/a&gt; to automatically generate identical applications that can run with either Kafka or  RabbitMQ. The plugin requires Maven configuration which we manually add for each application. Just because our function works with the TestChannelBinder, we can&amp;#8217;t be sure that the built artifact works until we run it. Misconfiguring the apps generator plugin, changes to the plugin itself, or the base image, or any dependencies, may break something. Testcontainers and Junit 5 give us a relatively straightforward way to integration test the pre-built applications with both Kafka and RabbitMQ. To help us write integration tests, we provide additional support in &lt;a href="https://github.com/spring-cloud/stream-applications/tree/master/applications/stream-applications-core/stream-applications-test-support#stream-application-integration-testing"&gt;stream-applications-test-suport&lt;/a&gt;. This library is available to the community by adding the dependency:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="xml"&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.cloud.stream.app&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;stream-applications-test-support&amp;lt;/artifactId&amp;gt;
    &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The sample includes an integration test to test the built image, in this case built with the &lt;a href="https://docs.spring.io/spring-boot/docs/current/maven-plugin/reference/htmlsingle/#goals-build-image"&gt;Spring Boot Maven plugin&lt;/a&gt;.
Like the application test, we will just plug in Kafka, Couchbase, and our image, turn on the power, and make sure we don&amp;#8217;t see or smell any smoke.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The complete integration test is:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;@KafkaStreamAppTest
@Tag("integration")
public class CouchbaseSinkIntegrationTests {

  static StreamAppContainer sink =
        new KafkaStreamAppContainer("couchbase-sink:0.0.1-SNAPSHOT");

  @Container
  static CouchbaseContainer container =
      new CouchbaseContainer("couchbase/server:6.6.0")
          .withNetwork(KafkaConfig.kafka.getNetwork())
          .withNetworkAliases("couchbase-server")
          .withBucket(new BucketDefinition("test"));

  static Cluster cluster;

  @Autowired
  TestTopicSender testTopicSender;

  @BeforeAll
  static void initialize() {
    await().until(() -&amp;gt; container.isRunning());
    String connectionString = "couchbase://couchbase-server";
    sink.waitingFor(Wait.forLogMessage(".*Started CouchbaseSink.*", 1))
          .withLogConsumer(appLog("couchbase-sink"))
          .withCommand(
            "--spring.couchbase.connection-string=couchbase://couchbase-server",
            "--spring.couchbase.username=" + container.getUsername(),
            "--spring.couchbase.password=" + container.getPassword(),
            "--couchbase.consumer.bucket-expression='test'",
            "--couchbase.consumer.key-expression=payload.email")
          .start();

    cluster = Cluster.connect(container.getConnectionString(),
    ClusterOptions.clusterOptions(container.getUsername(), container.getPassword()));
  }
  @AfterAll
  static void stop() {
    sink.stop();
  }

  @Test
  void test() throws JsonProcessingException {
    ObjectMapper objectMapper = new ObjectMapper();
    testTopicSender.send(sink.getInputDestination(),
    objectMapper.writeValueAsString(
       new User("Bart Simpson", "bart@simpsons.com")));

    await().atMost(Duration.ofSeconds(10)).untilAsserted(() -&amp;gt; {
       ExistsResult result = cluster.bucket("test")
         .defaultCollection().exists("bart@simpsons.com");
      assertThat(result.exists()).isTrue();
    });

    User user = objectMapper.readValue(
    cluster.bucket("test").defaultCollection().get("bart@simpsons.com")
   .contentAs(String.class), User.class);

    assertThat(user.getName()).isEqualTo("Bart Simpson");
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To unpack this, let&amp;#8217;s start with the &lt;code&gt;@KafkaStreamAppTest&lt;/code&gt; class annotation. This starts a Kafka test container, and configures Kafka components, using Spring for Apache Kafka, that we can use to produce and consume messages with Kafka. The Kafka container is started in a static initializer, which makes it a true singleton, allowing every test that runs in a JVM to use it. In addition to Spring configuration, the annotation includes &lt;code&gt;@TestContainers&lt;/code&gt; as a meta annotation. For this test, we do not let Testcontainers manage the lifecycle of the &lt;code&gt;StreamAppContainer&lt;/code&gt;, since we want to start it after we know the Couchbase cluster is running. The Couchbase container has some additional configuration. For convenience, it shares a virtual network with the &lt;code&gt;StreamAppContainer&lt;/code&gt; (automatically configured to use the same network as the Kafka container). This allows the Stream App Container to connect to the Couchbase server using an alias of our choosing, &lt;code&gt;couchbase-server&lt;/code&gt; (remember, &lt;code&gt;localhost&lt;/code&gt; inside a container refers to its own IP address).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;@Container
static CouchbaseContainer container = new CouchbaseContainer("couchbase/server:6.6.0")
        .withNetwork(KafkaConfig.kafka.getNetwork())
        .withNetworkAliases("couchbase-server")
        .withBucket(new BucketDefinition("test"));&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The StreamAppContainer is a &lt;a href="https://www.testcontainers.org/features/creating_container/"&gt;GenericContainer&lt;/a&gt; with the required configuration to connect to Kafka and use the Kafka binder.
The Spring Configuration also sets up a listener on a known topic to consume any output from the container. This is not used in this case, since we only have an input for the sink.
The input destination is randomly generated and accessed via &lt;code&gt;getInputDestination()&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;static StreamAppContainer sink = new KafkaStreamAppContainer("couchbase-sink:0.0.1-SNAPSHOT");
...

@BeforeAll
static void initialize() {
    await().until(() -&amp;gt; container.isRunning());
    String connectionString = "couchbase://couchbase-server";
    sink.waitingFor(Wait.forLogMessage(".*Started CouchbaseSink.*", 1))
            .withLogConsumer(appLog("couchbase-sink"))
            .withCommand(
                    "--spring.couchbase.connection-string=couchbase://couchbase-server",
                    "--spring.couchbase.username=" + container.getUsername(),
                    "--spring.couchbase.password=" + container.getPassword(),
                    "--couchbase.consumer.bucket-expression='test'",
                    "--couchbase.consumer.key-expression=payload.email")
            .start();&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Once the Couchbase container is running, we will start the sink. We wait for the standard Spring Boot start up message to confirm the sink has started.
We also add a LogConsumer to output all the log messages in case there is an error. Note the connection string is simply using the Couchbase container&amp;#8217;s network alias.
This is possible because the sink and Couchbase are using the same virtual network.
Here, we pass all properties on the command line, but we could just as well set them as environment variables, via &lt;code&gt;withEnvironment()&lt;/code&gt;.
Since we control the sink lifecycle, we need to stop it after all the tests are complete.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The test uses an autowired &lt;code&gt;TestTopicSender&lt;/code&gt;. This is a middleware agnostic interface, backed by KafkaTemplate in this case.
This interface is useful for run the same test cases for Kafka and Rabbit. Here, we could just as well autowire the &lt;code&gt;KafkaTemplate&lt;/code&gt;.
At the time of this writing, only the String serdes are configured for the Kafka template, so we use an &lt;code&gt;ObjectMapper&lt;/code&gt; to work with Strings.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;@Test
  void test() throws JsonProcessingException {
    ObjectMapper objectMapper = new ObjectMapper();
    testTopicSender.send(sink.getInputDestination(),
    objectMapper.writeValueAsString(
       new User("Bart Simpson", "bart@simpsons.com")));

    await().atMost(Duration.ofSeconds(10)).untilAsserted(() -&amp;gt; {
       ExistsResult result = cluster.bucket("test")
         .defaultCollection().exists("bart@simpsons.com");
      assertThat(result.exists()).isTrue();
    });

    User user = objectMapper.readValue(
    cluster.bucket("test").defaultCollection().get("bart@simpsons.com")
   .contentAs(String.class), User.class);

    assertThat(user.getName()).isEqualTo("Bart Simpson");
  }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Since this tests requires the sink image, we use the Junit 5 &lt;code&gt;@Tag&lt;/code&gt; annotation to mark it as an integration test.
We also configured Maven to exclude this from the normal build, and only build the image and run it when the &lt;em&gt;integration&lt;/em&gt; profile is set.
The complete source code is &lt;a href="https://github.com/spring-cloud/spring-cloud-stream-samples/tree/master/function-based-stream-app-samples/couchbase-stream-applications"&gt;here&lt;/a&gt; and requires Java 8+ and Docker.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="conclusion"&gt;&lt;a class="anchor" href="#conclusion"&gt;&lt;/a&gt;Conclusion&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this post we explored strategies for testing Spring Cloud Stream applications that integrate with external services, such as Couchbase. The majority of the testing, described in Part 1, was done at the function level. The application and integration tests are really smoke tests to verify that we have everything built, configured and integrated correctly. We also showed how to use TestContainers for testing Stream Applications.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="stay-tuned"&gt;&lt;a class="anchor" href="#stay-tuned"&gt;&lt;/a&gt;Stay tuned&amp;#8230;&amp;#8203;&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Thanks for coming! We hope you found this content helpful. We have a couple more posts until we conclude this series.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Testing Spring Cloud Stream Applications - Part 1</title>
    <link rel="alternate" href="https://spring.io/blog/2020/12/15/testing-spring-cloud-stream-applications-part-1" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>David Turanski</name>
    </author>
    <id>tag:spring.io,2020-12-09:4292</id>
    <updated>2020-12-15T19:04:00Z</updated>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;This post is part  of a blog series that explores the newly redesigned Spring Cloud Stream applications based on Java Functions.
This episode, presented in two parts, explores strategies for testing functions used to implement stream applications.
We will pay special attention to functions that integrate with external resources, which presents additional testing challenges. Such is the case with most of the &lt;a href="https://github.com/spring-cloud/stream-applications/tree/master/applications"&gt;pre-packaged source and sink applications&lt;/a&gt;.  To illustrate this, we will walk through a sample &lt;a href="https://github.com/spring-cloud/spring-cloud-stream-samples/tree/master/function-based-stream-app-samples/couchbase-stream-applications"&gt;couchbase-sink&lt;/a&gt; application.  Here in Part 1, we will focus on the core function on which the sink is based. In &lt;a href="https://spring.io/blog/2020/12/15/testing-spring-cloud-stream-applications-part-2"&gt;Part 2&lt;/a&gt;, we will look at writing tests for for the application.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Here are all the previous entries in this blog series.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/07/13/introducing-java-functions-for-spring-cloud-stream-applications-part-0"&gt;Introducing Function Based Streaming Applications&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/07/20/introducing-java-functions-for-spring-cloud-stream-applications-part-1"&gt;Function Composition with Streaming Applications&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/07/27/creating-a-supplier-function-and-generating-spring-cloud-stream-source"&gt;How to Build a Supplier and Source Application&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/08/03/creating-a-function-for-consuming-data-and-generating-spring-cloud-stream-sink-applications"&gt;How to Build a Consumer and Sink Application&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/08/10/case-study-build-and-run-a-streaming-application-using-an-http-source-and-a-jdbc-sink"&gt;Build and Run a Simple Stream Application&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/08/17/case-study-http-request-function-and-processor"&gt;Case Study: HTTP Request Function and Processor&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/08/25/case-study-reading-from-a-file-and-writing-to-mongodb"&gt;Case Study: File Source and MongoDB Sink&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/09/10/case-study-relational-database-source-and-file-sink"&gt;Case Study: Relational Database Source and File Sink&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/09/29/case-study-remote-file-ingest-with-spring-cloud-data-flow"&gt;Case Study: Remote File Ingest with Spring Cloud Data Flow&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/10/26/case-study-aggregator-function-and-processor"&gt;Case Study: Aggregator Function and Processor&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/12/14/case-study-change-data-capture-cdc-analysis-with-cdc-debezium-source-and-analytics-sink-in-real-time"&gt;Case Study: Change Data Capture (CDC) Analysis with CDC Debezium source and Analytics sink in Real-Time&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="testing-considerations"&gt;&lt;a class="anchor" href="#testing-considerations"&gt;&lt;/a&gt;Testing Considerations&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="functions-and-applications"&gt;&lt;a class="anchor" href="#functions-and-applications"&gt;&lt;/a&gt;Functions and Applications&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For function-based stream applications, the core functionality is exposed as a function. The core functions for the pre-built  &lt;a href="https://spring.io/projects/spring-cloud-stream"&gt;Spring Cloud Stream&lt;/a&gt; applications are packaged as separate components to allow them  to be used by any application, independent of Spring Cloud Stream. Spring Cloud Stream natively supports Java functions and will bind to any bean that implements one of the core &lt;code&gt;java.util.function&lt;/code&gt; types: &lt;code&gt;Consumer&lt;/code&gt;, &lt;code&gt;Supplier&lt;/code&gt;, or &lt;code&gt;Function&lt;/code&gt;. Viewed as a separate component, the function need not depend on Spring or anything else. If you register any function as a bean in any application that includes a Spring Cloud Stream binder as a dependency, Spring Cloud Stream will bind it to a configured message destination.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In a data pipeline, a stream of data originates from a Source and flows into a Sink, with zero or more processing steps in between. In practice, the Source acts as a Supplier of data from some external resource, such as a data store, any service supporting a standard protocol, or a message broker.  The Sink acts as a consumer of data for some other external resource. Since Spring provides first class support for most commonly used external resources, it should come as no suprise that most of the pre-packaged sources and sinks rely on some combination of Spring Integration, Spring Data, and Spring Boot. Additionally, they are designed to be configured for many environments, domains and use cases, via &lt;code&gt;@ConfigurationProperties&lt;/code&gt;.  Although these functions themselves are not Spring Boot Applications, they must be imported into a Spring Boot application to run.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Since all the core functionality is implemented by the function, we want to focus most of our testing efforts at this level.  To ensure that our function behaves correctly under all expected success and error conditions, we need to write tests to cover these scenarios. These tests need to create an auto-configured application context and provision or mock required external resource.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If the function is configurable via &lt;code&gt;@ConfigurationProperties&lt;/code&gt;, then we can treat each properties combination as a different test case. Some properties are required, and some are optional. Since using the function requires the end user to provide these properties, expected scenarios include both valid and invalid configurations, such as required properties missing, invalid values, or an invalid combination (mutually exclusive properties).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="unit-vs-integration-tests"&gt;&lt;a class="anchor" href="#unit-vs-integration-tests"&gt;&lt;/a&gt;Unit vs Integration Tests&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;There are no widely accepted definitions that will help us here. Especially with sources and sinks, in which the core functionality &lt;em&gt;is&lt;/em&gt; integration, it&amp;#8217;s hard to know where to draw the line between unit and integration tests. On one hand, a Java function is a &lt;em&gt;unit&lt;/em&gt;, in that it is a single interface. However, if its sole purpose is to integrate with a remote system, it is difficult, if not impossible, to test in isolation. However, I think we can agree on some general characteristics:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Unit tests:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run automatically as part of a build in any developer or CI environment without any external configuration&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Are reasonably fast&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Are written by the developer and run frequently&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Integration tests:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run automatically in an integration environment&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Require the component under test, along with external dependencies to be deployed&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;May be slow&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Are run less often&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Given this definition of unit tests, Part 1 is about unit testing functions.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="test-containers"&gt;&lt;a class="anchor" href="#test-containers"&gt;&lt;/a&gt;Test Containers&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;a href="https://www.testcontainers.org/"&gt;Testcontainers&lt;/a&gt; is a recent and popular Java library that lets you programmatically spin up and throw away any external resource that can run in a Docker container. It includes dozens of out-of-the-box modules for commonly used resources. You can also use the library to create custom containers programmatically, from Dockerfiles, or docker-compose yaml. While intended primarily for integration tests, it is extremely useful for writing unit tests when mocking takes considerably more effort. Of course we have to sacrifice some speed and relax the "no external dependencies" rule to allow for a Docker daemon installed and running on the host. Since many development and CI environments today are already required to use and build images, this is a reasonable assumption.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="example"&gt;&lt;a class="anchor" href="#example"&gt;&lt;/a&gt;Example&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="couchbase-consumer-function"&gt;&lt;a class="anchor" href="#couchbase-consumer-function"&gt;&lt;/a&gt;Couchbase Consumer Function&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To illustrate, we will write a Couchbase consumer function to add some data to a Couchbase key-value store using the &lt;em&gt;upsert&lt;/em&gt; operation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For efficiency, we will implement the function using the Couchbase Java client&amp;#8217;s reactive API. This API returns a publisher of &lt;a href="https://docs.couchbase.com/sdk-api/couchbase-java-client/com/couchbase/client/java/kv/MutationResult.html"&gt;MutationResult&lt;/a&gt;, so our core interface is
&lt;code&gt;Function&amp;lt;Flux&amp;lt;Message&amp;lt;?&amp;gt;&amp;gt;, Flux&amp;lt;MutationResult&amp;gt;&amp;gt;&lt;/code&gt;.  This function will be configured with Spring, and can be embedded into any Spring Boot Application. To support a &lt;code&gt;couchbase-sink&lt;/code&gt;, we will wrap the function in a &lt;code&gt;Consumer&amp;lt;Flux&amp;lt;Message&amp;lt;?&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The &lt;code&gt;upsert&lt;/code&gt; operation inserts or updates data in a &lt;a href="https://docs.couchbase.com/server/current/learn/buckets-memory-and-storage/buckets.html"&gt;Bucket&lt;/a&gt;,
which is the primary data store abstraction for Couchbase. In our case, a &lt;code&gt;ReactiveBucket&lt;/code&gt;.  A bucket is specified by name and must exist in the Couchbase cluster beforehand. Starting with v6.5, Couchbase supports &lt;a href="https://docs.couchbase.com/server/current/developer-preview/collections/collections-overview.html"&gt;Collections&lt;/a&gt;. So the bucket may be partitioned into many collections, but this is an optional feature that must be enabled in the cluster. The &lt;code&gt;upsert&lt;/code&gt; method targets a named collection, or the &lt;em&gt;defaultCollection&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We pass the key and value to our function in a Spring Message, consisting of a payload and headers. The payload can be any object, and the headers are essentially a Map. To make this function generic, we can use a &lt;a href="https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#expressions"&gt;SpEL expression&lt;/a&gt; to specify the key. The key expression is evaluated against the Message, and may reference fields or methods in the payload, or a header. The value is the payload.  The function also requires the user to specify a bucket and collection name. To maximize flexibility, let&amp;#8217;s double down on SpEL and make everything an expression. Now, if we want, the function can extract all its input values from the message at runtime to upsert any data in any collection in any bucket. In the simplest case, the bucket and collection can be defined statically.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;So the function needs some configuration properties:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;@ConfigurationProperties("couchbase.consumer")
@Validated
public class CouchbaseConsumerProperties {
    private static final String DEFAULT_VALUE_EXPRESSION = "payload";
    private final SpelExpressionParser parser = new SpelExpressionParser();

   /**
    * A SpEL expression to specify the bucket.
    */
    private Expression bucketExpression;

   /**
      * A SpEL expression to specify the key.
     */
    private Expression keyExpression;

  /**
    * A SpEL expression to specify the collection.
    */
    private Expression collectionExpression;

  /**
    * A SpEL expression to specify the value (default is payload).
    */
    private Expression valueExpression =
                parser.parseExpression(DEFAULT_VALUE_EXPRESSION);
    ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="admonitionblock tip"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Tip&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
To statically confiugure some of these values, use a literal expression, enclosing the value in single quotes, e.g. &lt;code&gt;couchbase.consumer.bucketExpression='mybucket'&lt;/code&gt;. Normally, you would extract the key and value from the message contents.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We configure the reactive Function and corresponding Consumer with Spring:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;@Configuration
@EnableConfigurationProperties(CouchbaseConsumerProperties.class)
public class CouchbaseConsumerConfiguration {

    private static Logger logger =
            LoggerFactory.getLogger(CouchbaseConsumerConfiguration.class);

    @Bean
    public Consumer&amp;lt;Flux&amp;lt;Message&amp;lt;?&amp;gt;&amp;gt;&amp;gt; couchbaseConsumer(Function&amp;lt;Flux&amp;lt;Message&amp;lt;?&amp;gt;&amp;gt;,
                Flux&amp;lt;MutationResult&amp;gt;&amp;gt; couchbaseConsumerFunction) {
        return message -&amp;gt; couchbaseConsumerFunction.apply(message)
               .subscribe(mutationResult -&amp;gt; logger.debug("Processed " + message));
    }

    @Bean
    public Function&amp;lt;Flux&amp;lt;Message&amp;lt;?&amp;gt;&amp;gt;, Flux&amp;lt;MutationResult&amp;gt;&amp;gt; couchbaseConsumerFunction(
          Cluster cluster, CouchbaseConsumerProperties consumerProperties) {
        return flux -&amp;gt; flux.flatMap(message -&amp;gt; {
            logger.debug("Processing message " + message);
             String bucketName = bucket(message,
                          consumerProperties.getBucketExpression());
            String key = key(message, consumerProperties.getKeyExpression());
            ReactiveBucket bucket = cluster.bucket(bucketName).reactive();
             ReactiveCollection collection = collection(message,
                            consumerProperties.getCollectionExpression())
				  .map(name -&amp;gt; bucket.collection(name))
                                  .orElse(bucket.defaultCollection());
            return collection.upsert(key,
                              value(message, consumerProperties.getValueExpression()));
        });
    }

    private String bucket(Message&amp;lt;?&amp;gt; message, Expression expression) {
        return expression.getValue(message, String.class);
    }

    private String key(Message&amp;lt;?&amp;gt; message, Expression expression) {
        return expression.getValue(message, String.class);
    }

    private Object value(Message&amp;lt;?&amp;gt; message, Expression expression) {
        return expression.getValue(message);
    }

    private Optional&amp;lt;String&amp;gt; collection(Message&amp;lt;?&amp;gt; message,
                                             @Nullable Expression expression) {
        return expression == null ? Optional.empty() :
                Optional.of(expression.getValue(message, String.class));
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;These two classes are all we need to implement the function. The required dependencies are:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="xml"&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;com.couchbase.client&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;java-client&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;!-- Enable configuration properties metadata to be added to the jar --&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-configuration-processor&amp;lt;/artifactId&amp;gt;
    &amp;lt;optional&amp;gt;true&amp;lt;/optional&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;!-- This provides a Spring Converter to convert Strings to Expression, required for CouchbaseConsumerProperties as implemented --&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.cloud.fn&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;config-common&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As mentioned earlier, this is not a Spring Boot application, but a component that must be embedded in a Spring Boot application to run.
Spring Boot binds the &lt;code&gt;@ConfigurationPropeties&lt;/code&gt; and also provides &lt;a href="https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/autoconfigure/couchbase/CouchbaseAutoConfiguration.html"&gt;CouchbaseAutoConfiguration&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
This example does not use &lt;a href="https://spring.io/projects/spring-data-couchbase"&gt;spring-data-couchbase&lt;/a&gt; since it is intended for using Spring Data Repositories and automatically mapping specific domain objects. Since our function is intended to handle any payload type, we use boot to autoconfigure the Cluster along with the Couchbase Java SDK.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;So how did we end up with a function that actually works? The sample code above is the result of test driven development, refined over several iterations. Since the function depends on the Couchbase SDK &lt;code&gt;Cluster&lt;/code&gt; object which does all the work, we need to create a Cluster instance before we can do anything. The Cluster needs to connect to a Couchbase server.  If we happen to have a Couchbase cluster already running on our network, with a bucket we can use for testing, then we might use that initially. But even if we assume Couchbase is accessable from our development and CI environment,  what happens if we can&amp;#8217;t connect to Couchbase for some reason - the cluster is down, credentials expired, permissions changed, or some other reason?  Do we want to let that break our CI/CD pipeline or stop our progress?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Fortunately, we can use the Testcontainers &lt;a href="https://www.testcontainers.org/modules/databases/couchbase/"&gt;couchbase module&lt;/a&gt; to spin up our own Couchbase environment.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
Full disclosure: I also tried &lt;a href="https://github.com/couchbase/CouchbaseMock"&gt;CouchbaseMock&lt;/a&gt; but it appears to be incompatible with the current &lt;a href="https://github.com/couchbase/couchbase-java-client"&gt;couchbase Java client&lt;/a&gt;.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The required test libraries for Junit 5, are:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="xml"&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-test&amp;lt;/artifactId&amp;gt;
    &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;io.projectreactor&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;reactor-test&amp;lt;/artifactId&amp;gt;
    &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.testcontainers&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;couchbase&amp;lt;/artifactId&amp;gt;
    &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.testcontainers&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;junit-jupiter&amp;lt;/artifactId&amp;gt;
    &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To use Testcontainers in our Junit 5 test class, we start with a Couchbase container configured with a bucket named &lt;code&gt;test&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;@Testcontainers
public class CouchbaseConsumerTests {

	@Container
	static CouchbaseContainer container = new CouchbaseContainer("couchbase/server:6.6.0")
			.withBucket(new BucketDefinition("test"));&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The &lt;code&gt;@Testcontainers&lt;/code&gt; annotation enables lifecycle management for fields annotated with &lt;code&gt;@Container&lt;/code&gt;.
Here, we declare the &lt;code&gt;CouchbaseContainer&lt;/code&gt; as &lt;code&gt;static&lt;/code&gt;, so TestContainers will start the container once before the tests run and remove it after. This is a good thing, since it takes several seconds to start the container.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
Also take a look at &lt;a href="https://github.com/Playtika/testcontainers-spring-boot"&gt;Playtika Testcontainers for Spring Boot&lt;/a&gt;. This is an interesting project that abstracts "embedded" services using Spring Boot to autoconfigure a Testcontainer. This requires your preferred version of &lt;code&gt;org.springframework.cloud:spring-cloud-starter&lt;/code&gt;.  If you are using a Spring Cloud version compatible with Spring Boot 2.4+ you will need to set &lt;code&gt;"spring.cloud.bootstrap.enabled=true"&lt;/code&gt;.  The sample does not use this library because Spring beans cannot be declared &lt;code&gt;static&lt;/code&gt;, so we would have to start a new container instance for each test. Anyway, Testcontainers is really easy to use.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As mentioned above, different property configurations represent different test cases. Spring Boot binds properties from its properties sources when the application starts up. So we need to create a new application context for each combination of properties we want to test. We see a few different strategies used in the &lt;a href="https://github.com/spring-cloud/stream-applications"&gt;stream-applications&lt;/a&gt; repository:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Create an abstract &lt;code&gt;@SpringBootTest&lt;/code&gt; to configure a &lt;code&gt;@SpringBootApplication&lt;/code&gt; test context and shared configuration properties. Create a sub class, annotated with &lt;code&gt;@TestPropertySource&lt;/code&gt; for each test case, as shown &lt;a href="https://github.com/spring-cloud/stream-applications/tree/master/functions/consumer/s3-consumer/src/test/java/org/springframework/cloud/fn/consumer/s3"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;a href="https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/test/context/runner/ApplicationContextRunner.html"&gt;ApplicationContextRunner&lt;/a&gt; to create a new &lt;code&gt;ApplicationContext&lt;/code&gt; for each test case, as shown &lt;a href="https://github.com/spring-cloud/stream-applications/blob/master/functions/supplier/sftp-supplier/src/test/java/org/springframework/cloud/fn/supplier/sftp/SftpSupplierApplicationTests.java"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;a href="https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/builder/SpringApplicationBuilder.html"&gt;SpringApplicationBuilder&lt;/a&gt; to create a new &lt;code&gt;ApplicationContext&lt;/code&gt; for each test case, as shown &lt;a href="https://github.com/spring-cloud/stream-applications/blob/master/functions/function/task-launch-request-function/src/test/java/org/springframework/cloud/fn/task/launch/request/TaskLaunchRequestFunctionApplicationTests.java"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Which one you use depends largely on personal choice. The tests for the sample function use the &lt;code&gt;ApplicationContextRunner&lt;/code&gt;, pre-configured with the required boot Couchbase connection properties provided by the test container. A nice feature of Testcontainers is that it exposes standard ports as expected, mapping each exposed port to a random available port. The Couchbase testContainer includes &lt;code&gt;getConnectionString()&lt;/code&gt; which is specific to Couchbase. Generally, you can use &lt;code&gt;container.getMappedPort(int originalPort)&lt;/code&gt; as required.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="admonitionblock tip"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Tip&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
Using random TCP ports is essential for automated tests since 1) You do not know what ports may be in use for a given environment 2) Build tools typically run tests in parallel. This frequently results in errors due to an unavailable port when statically defined.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;@Testcontainers
public class CouchbaseConsumerTests {

    @Container
    static CouchbaseContainer container =
            new CouchbaseContainer("couchbase/server:6.6.0")
                   .withBucket(new BucketDefinition("test"));

	private ApplicationContextRunner applicationContextRunner;

    @BeforeEach
    void setup() {
        applicationContextRunner = new ApplicationContextRunner()
            .withUserConfiguration(TestConfig.class)
            .withPropertyValues(
                 "spring.couchbase.connection-string=" +
                                                container.getConnectionString(),
                 "spring.couchbase.username=" + container.getUsername(),
                 "spring.couchbase.password=" + container.getPassword());
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We use &lt;code&gt;TestConfig.class&lt;/code&gt; to start an application context, which we provide as an inner class:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;@SpringBootApplication
static class TestConfig {
    @Autowired
    Cluster cluster;

   @PreDestroy
    public void destroy() {
        cluster.disconnect();
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In many cases, this can be an empty class annotated with &lt;code&gt;@SpringBootApplication&lt;/code&gt; to trigger properties binding, and any required auto configuration - &lt;code&gt;CouchbaseAutoConfiguration&lt;/code&gt; in this case. Here, we disconnect from the cluster to prevent a superfluous stack trace when the context closes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For these tests, we will create a simple &lt;code&gt;User&lt;/code&gt; type with a name and an email address which we can use for the key:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;@JsonIgnoreProperties(ignoreUnknown = true)
public class User {
	private String name;

	private String email;

	public String getName() {
		return name;
	}

	public void setName(String name) {
		this.name = name;
	}

	public String getEmail() {
		return email;
	}

	public void setEmail(String email) {
		this.email = email;
	}

	public User() {
	}

	public User(String name, String email) {
		this.name = name;
		this.email = email;
	}
    ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now we are ready to test our function. Since the function is reactive, we will use the &lt;code&gt;StepVerifier&lt;/code&gt; from the &lt;code&gt;reactor-test&lt;/code&gt; library to verify the contents of the returned Flux.
We begin with the simplest happy path scenario:  &lt;em&gt;upsert&lt;/em&gt; a single User providing the minimum required configuration: The bucket name and the key expression. We will construct a &lt;code&gt;Message&lt;/code&gt; with a &lt;code&gt;User&lt;/code&gt; payload. To store the user into the &lt;code&gt;test&lt;/code&gt; bucket&amp;#8217;s default collection, using the user&amp;#8217;s email as the key, we just need to provide the bucket name as a literal and set the key expression to &lt;code&gt;payload.email&lt;/code&gt;. These properties need to use the &lt;code&gt;couchbase.consumer&lt;/code&gt; prefix configured in &lt;code&gt;CouchbaseConsumerProperties&lt;/code&gt;. At least, that&amp;#8217;s the intended behavior.
We can&amp;#8217;t be sure that all this works until we can verify that ,after calling the function, the data is present in the data store. We use the Couchbase API directly to retrieve the data and assert that the contents are what we expect.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;@Test
void singleUpsert() {
   applicationContextRunner.withPropertyValues(
           "couchbase.consumer.bucketExpression='test'",
            "couchbase.consumer.keyExpression=payload.email")
      .run(context -&amp;gt; {
           CouchbaseConsumerProperties properties =
                    context.getBean(CouchbaseConsumerProperties.class);
           String bucketName = properties.getBucketExpression().getValue(String.class);
           Cluster cluster = context.getBean(Cluster.class);
           Function&amp;lt;Flux&amp;lt;Message&amp;lt;?&amp;gt;&amp;gt;, Flux&amp;lt;MutationResult&amp;gt;&amp;gt;
                 couchbaseConsumerFunction =
                       context.getBean("couchbaseConsumerFunction", Function.class);
           StepVerifier.create(couchbaseConsumerFunction.apply(
               Flux.just(new GenericMessage&amp;lt;&amp;gt;(new User("David", "david@david.com")))))
            .expectNextMatches(mutationResult -&amp;gt;
                   mutationResult.mutationToken().get().bucketName().equals(bucketName))
            .verifyComplete();

        User saved = cluster.bucket(bucketName).defaultCollection()
                                   .get("david@david.com").contentAs(User.class);
       assertThat(saved.getName()).isEqualTo("David");
  });
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;With the function implemented as previously shown, we are ecstatic to see green when we run the test in our IDE. In reality, we need a test like this to write the function in the first place. That is why we put significant thought and effort into this simple test. We also want to test applying multiple objects, and setting a custom expression for the value, and bucket. We may want to also check the Java validation annotations in our properties class.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;@NotNull(message = "'keyExpression' is required")
public Expression getKeyExpression() {
    return keyExpression;
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I forget, does the annotation go on the getter or the setter?, do we really need the &lt;code&gt;@Validated&lt;/code&gt; class annotation? Let&amp;#8217;s find out. If we forget to set &lt;code&gt;couchbase.consumer.keyExpression&lt;/code&gt;, we should get an exception message &lt;code&gt;'keyExpression is required'&lt;/code&gt; somewhere in the stack trace. If not, then we did something wrong. Fortunately, &lt;code&gt;spring-boot-starter-test&lt;/code&gt; gives us everything we need for testing, including &lt;a href="https://assertj.github.io/doc/AssertJ"&gt;Assertj&lt;/a&gt;, a fluent DSL for assertions, Mockito, and Junit 5.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;@Test
void keyExpressionRequired() {
  assertThatExceptionOfType(RuntimeException.class).isThrownBy(
   () -&amp;gt; applicationContextRunner.withPropertyValues(
      "couchbase.consumer.bucket-expression='test'").run(context -&amp;gt; context.start()))
    .havingRootCause()
    .withMessageContaining("'keyExpression' is required");
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;By the time we are done, we will write more than twice the LOC needed to implement the function, and probably spend more than twice the time. But the effort is well worth it since it gives us proof that the function behaves as expected in common scenarios, and protection against introducing regressions when refactoring or adding new functionality.  The complete tests are &lt;a href="https://github.com/spring-cloud/spring-cloud-stream-samples/blob/master/function-based-stream-app-samples/couchbase-stream-applications/couchbase-consumer/src/test/java/io/spring/example/couchbase/consumer/CouchbaseConsumerTests.java"&gt;here&lt;/a&gt;.  I&amp;#8217;m happy to say that my IDE reports over 90% coverage.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="conclusion"&gt;&lt;a class="anchor" href="#conclusion"&gt;&lt;/a&gt;Conclusion&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This concludes Part 1 of the testing topic. In this post we explored strategies for testing functions that integrate with external resources, such as Couchbase. We also showed how useful the TestContainers library is for testing components of distributed systems, especially when using mocks, stubs, or embedded servers is impractical. &lt;a href="https://spring.io/blog/2020/12/15/testing-spring-cloud-stream-applications-part-2"&gt;Part 2&lt;/a&gt; will cover unit and integration testing of function based stream applications.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="stay-tuned"&gt;&lt;a class="anchor" href="#stay-tuned"&gt;&lt;/a&gt;Stay tuned&amp;#8230;&amp;#8203;&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Thanks for coming! We hope you found this content helpful. We have a couple more posts until we conclude this series.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Spring Cloud 2020.0.0-RC1 (aka Ilford) Is Available</title>
    <link rel="alternate" href="https://spring.io/blog/2020/12/15/spring-cloud-2020-0-0-rc1-aka-ilford-is-available" />
    <category term="releases" label="Releases" />
    <author>
      <name>Ryan Baxter</name>
    </author>
    <id>tag:spring.io,2020-12-14:4302</id>
    <updated>2020-12-15T14:22:35Z</updated>
    <content type="html">&lt;p&gt;On behalf of the community, I am pleased to announce that Release Candidate 1 (RC1) of the &lt;a href="https://cloud.spring.io"&gt;Spring Cloud 2020&lt;/a&gt; Release Train is available today. You can find the release in the &lt;a href="https://repo.spring.io/milestone/"&gt;Spring Milestone&lt;/a&gt; repository. See the 2020 &lt;a href="https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes"&gt;release notes for more information&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;&lt;a href="#notable-changes-in-the-2020-release-train" class="anchor" name="notable-changes-in-the-2020-release-train"&gt;&lt;/a&gt;Notable Changes in the 2020 Release Train&lt;/h2&gt;
&lt;p&gt;This release requires Spring Boot 2.4.0.&lt;/p&gt;
&lt;p&gt;See the &lt;a href="https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes#breaking-changes"&gt;wiki&lt;/a&gt; for a list of all breaking changes in this release train.&lt;/p&gt;
&lt;p&gt;See all of the included issues and pull requests at the &lt;a href="https://github.com/orgs/spring-cloud/projects/50"&gt;Github project&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;&lt;a href="#spring-cloud-contract" class="anchor" name="spring-cloud-contract"&gt;&lt;/a&gt;Spring Cloud Contract&lt;/h3&gt;
&lt;p&gt;The Gradle plugin &lt;a href="https://github.com/spring-cloud/spring-cloud-contract/pull/1558"&gt;creates a separate classpath when executing tasks&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;&lt;a href="#spring-cloud-kubernetes" class="anchor" name="spring-cloud-kubernetes"&gt;&lt;/a&gt;Spring Cloud Kubernetes&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Packages and starters have been refactored to &lt;a href="https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes#spring-cloud-kubernetes"&gt;accommodate new Kubernetes Java Client implementations&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Starters have been added for Kubernetes Java Client implementations (&lt;a href="https://github.com/spring-cloud/spring-cloud-kubernetes/pull/687"&gt;PR&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#spring-cloud-commons" class="anchor" name="spring-cloud-commons"&gt;&lt;/a&gt;Spring Cloud Commons&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;LoadBalancer - you can now use a custom health verification function and a RestTemplate-based mechanism with &lt;code&gt;HealthcheckServiceInstanceListSupplier&lt;/code&gt; (&lt;a href="https://github.com/spring-cloud/spring-cloud-commons/pull/866"&gt;PR&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;LoadBalancerProperties &lt;a href="https://github.com/spring-cloud/spring-cloud-commons/issues/830"&gt;have been repackaged&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Support has been added for &lt;code&gt;LoadBalancer&lt;/code&gt; selecting same instance if available (&lt;a href="https://github.com/spring-cloud/spring-cloud-gateway/pull/2066"&gt;PR&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;Support has been added for `LoadBalancer selecting the instance specified by a cookie, if available (&lt;a href="https://github.com/spring-cloud/spring-cloud-gateway/pull/2066"&gt;PR&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#spring-cloud-function" class="anchor" name="spring-cloud-function"&gt;&lt;/a&gt;Spring Cloud Function&lt;/h3&gt;
&lt;p&gt;Spring Cloud Function introduces two new features: support for &lt;a href="https://rsocket.io/"&gt;RSocket&lt;/a&gt; and &lt;a href="https://cloudevents.io/"&gt;Cloud Events&lt;/a&gt;.&lt;br/&gt;While were in the process of updating documentation with details on these features, you can check out samples and integration test cases to get additional information now.&lt;br/&gt;For Cloud Events support, you can look at the &lt;a href="https://github.com/spring-cloud/spring-cloud-function/tree/master/spring-cloud-function-samples/function-sample-cloudevent"&gt;Cloud Events samples&lt;/a&gt; as well as a recently published &lt;a href="https://spring.io/blog/2020/12/10/cloud-events-and-spring-part-1"&gt;blog post&lt;/a&gt;.&lt;br/&gt;For RSocket support, you can look at &lt;a href="https://github.com/spring-cloud/spring-cloud-function/tree/master/spring-cloud-function-rsocket/src/test/java/org/springframework/cloud/function/rsocket"&gt;some of the test cases&lt;/a&gt; demonstrating how functions can be invoked via RSocket. &lt;/p&gt;&lt;h3&gt;&lt;a href="#spring-cloud-sleuth" class="anchor" name="spring-cloud-sleuth"&gt;&lt;/a&gt;Spring Cloud Sleuth&lt;/h3&gt;&lt;h4&gt;&lt;a href="#moving-opentelemetry-support-to-incubator" class="anchor" name="moving-opentelemetry-support-to-incubator"&gt;&lt;/a&gt;Moving OpenTelemetry support to incubator&lt;/h4&gt;
&lt;p&gt;As OpenTelemetry continues to evolve, we have decided to move OpenTelemetry support from Spring Cloud Sleuth to an &lt;a href="https://github.com/spring-cloud-incubator/spring-cloud-sleuth-otel/"&gt;incubator project&lt;/a&gt; . To continue using OpenTelemetry with Spring Cloud Sleuth, you will need to add the Spring repositories, the &lt;code&gt;spring-cloud-sleuth-otel-dependencies&lt;/code&gt; BOM, and the &lt;code&gt;spring-cloud-sleuth-otel-autoconfigure&lt;/code&gt; dependency.&lt;/p&gt;
&lt;p&gt;We have released a &lt;code&gt;1.0.0-M1&lt;/code&gt; of Spring Cloud Sleuth OTel that is compatible with the &lt;code&gt;2020.0.0-RC1&lt;/code&gt; release train. The following listings show how to use it in Maven and Gradle:&lt;/p&gt;
&lt;p&gt;Maven&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint xml"&gt; &amp;lt;properties&amp;gt;&#xD;
   &amp;lt;spring-cloud-sleuth-otel.version&amp;gt;1.0.0-M1&amp;lt;/spring-cloud-sleuth-otel.version&amp;gt;&#xD;
   &amp;lt;spring-cloud.version&amp;gt;2020.0.0-RC1&amp;lt;/spring-cloud.version&amp;gt;&#xD;
 &amp;lt;/properties&amp;gt;&#xD;
&#xD;
 &amp;lt;dependencyManagement&amp;gt;&#xD;
		&amp;lt;dependencies&amp;gt;&#xD;
			&amp;lt;dependency&amp;gt;&#xD;
				&amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
				&amp;lt;artifactId&amp;gt;spring-cloud-dependencies&amp;lt;/artifactId&amp;gt;&#xD;
				&amp;lt;version&amp;gt;${spring-cloud.version}&amp;lt;/version&amp;gt;&#xD;
				&amp;lt;type&amp;gt;pom&amp;lt;/type&amp;gt;&#xD;
				&amp;lt;scope&amp;gt;import&amp;lt;/scope&amp;gt;&#xD;
			&amp;lt;/dependency&amp;gt;&#xD;
			&amp;lt;dependency&amp;gt;&#xD;
				&amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
				&amp;lt;artifactId&amp;gt;spring-cloud-sleuth-otel-dependencies&amp;lt;/artifactId&amp;gt;&#xD;
				&amp;lt;!-- Provide the version of the Spring Cloud Sleuth OpenTelemetry project --&amp;gt;&#xD;
				&amp;lt;version&amp;gt;${spring-cloud-sleuth-otel.version}&amp;lt;/version&amp;gt;&#xD;
				&amp;lt;scope&amp;gt;import&amp;lt;/scope&amp;gt;&#xD;
				&amp;lt;type&amp;gt;pom&amp;lt;/type&amp;gt;&#xD;
			&amp;lt;/dependency&amp;gt;&#xD;
		&amp;lt;/dependencies&amp;gt;&#xD;
	&amp;lt;/dependencyManagement&amp;gt;&#xD;
&#xD;
    &amp;lt;dependency&amp;gt;&#xD;
        &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
        &amp;lt;artifactId&amp;gt;spring-cloud-starter-sleuth&amp;lt;/artifactId&amp;gt;&#xD;
        &amp;lt;exclusions&amp;gt;&#xD;
            &amp;lt;exclusion&amp;gt;&#xD;
                &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
                &amp;lt;artifactId&amp;gt;spring-cloud-sleuth-brave&amp;lt;/artifactId&amp;gt;&#xD;
            &amp;lt;/exclusion&amp;gt;&#xD;
        &amp;lt;/exclusions&amp;gt;&#xD;
    &amp;lt;/dependency&amp;gt;&#xD;
    &amp;lt;dependency&amp;gt;&#xD;
        &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
        &amp;lt;artifactId&amp;gt;spring-cloud-sleuth-otel-autoconfigure&amp;lt;/artifactId&amp;gt;&#xD;
    &amp;lt;/dependency&amp;gt;&#xD;
&#xD;
		&amp;lt;repositories&amp;gt;&#xD;
			&amp;lt;repository&amp;gt;&#xD;
				&amp;lt;id&amp;gt;spring-snapshots&amp;lt;/id&amp;gt;&#xD;
				&amp;lt;url&amp;gt;https://repo.spring.io/snapshot&amp;lt;/url&amp;gt;&#xD;
				&amp;lt;snapshots&amp;gt;&amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt;&amp;lt;/snapshots&amp;gt;&#xD;
			&amp;lt;/repository&amp;gt;&#xD;
			&amp;lt;repository&amp;gt;&#xD;
				&amp;lt;id&amp;gt;spring-milestones&amp;lt;/id&amp;gt;&#xD;
				&amp;lt;url&amp;gt;https://repo.spring.io/milestone&amp;lt;/url&amp;gt;&#xD;
			&amp;lt;/repository&amp;gt;&#xD;
		&amp;lt;/repositories&amp;gt;&#xD;
		&amp;lt;pluginRepositories&amp;gt;&#xD;
			&amp;lt;pluginRepository&amp;gt;&#xD;
				&amp;lt;id&amp;gt;spring-snapshots&amp;lt;/id&amp;gt;&#xD;
				&amp;lt;url&amp;gt;https://repo.spring.io/snapshot&amp;lt;/url&amp;gt;&#xD;
			&amp;lt;/pluginRepository&amp;gt;&#xD;
			&amp;lt;pluginRepository&amp;gt;&#xD;
				&amp;lt;id&amp;gt;spring-milestones&amp;lt;/id&amp;gt;&#xD;
				&amp;lt;url&amp;gt;https://repo.spring.io/milestone&amp;lt;/url&amp;gt;&#xD;
			&amp;lt;/pluginRepository&amp;gt;&#xD;
		&amp;lt;/pluginRepositories&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Gradle&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;ext {&#xD;
  springCloudSleuthOtelVersion = &amp;quot;1.0.0-M1&amp;quot;&#xD;
  springCloudVersion = &amp;quot;2020.0.0-RC1&amp;quot;&#xD;
}&#xD;
&#xD;
dependencyManagement {&#xD;
    imports {&#xD;
        mavenBom &amp;quot;org.springframework.cloud:spring-cloud-dependencies:${springCloudVersion}&amp;quot;&#xD;
        mavenBom &amp;quot;org.springframework.cloud:spring-cloud-sleuth-otel-dependencies:${springCloudSleuthOtelVersion}&amp;quot;&#xD;
    }&#xD;
}&#xD;
&#xD;
dependencies {&#xD;
    implementation(&amp;quot;org.springframework.cloud:spring-cloud-starter-sleuth&amp;quot;) {&#xD;
        exclude group: &amp;#39;org.springframework.cloud&amp;#39;, module: &amp;#39;spring-cloud-sleuth-brave&amp;#39;&#xD;
    }&#xD;
    implementation &amp;quot;org.springframework.cloud:spring-cloud-sleuth-otel-autoconfigure&amp;quot;&#xD;
}&#xD;
&#xD;
repositories {&#xD;
    mavenCentral()&#xD;
    maven {&#xD;
            url &amp;quot;https://repo.spring.io/snapshot&amp;quot;&#xD;
    }&#xD;
    maven {&#xD;
            url &amp;quot;https://repo.spring.io/milestone&amp;quot;&#xD;
    }&#xD;
    maven {&#xD;
            url &amp;quot;https://repo.spring.io/release&amp;quot;&#xD;
    }&#xD;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;a href="#spring-cloud-task" class="anchor" name="spring-cloud-task"&gt;&lt;/a&gt;Spring Cloud Task&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Added ability for the user to utilize external DBs for Multi-DB &lt;a href="https://github.com/spring-cloud/spring-cloud-task/issues/690"&gt;sample&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Spring Cloud Task now supports &lt;a href="https://github.com/spring-cloud/spring-cloud-task/issues/645"&gt;&lt;code&gt;JobApplicationRunner&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Single-step Batch Job sample now supports &lt;a href="https://github.com/spring-cloud/spring-cloud-task/issues/745"&gt;AMQP and Kafka&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#spring-cloud-gateway" class="anchor" name="spring-cloud-gateway"&gt;&lt;/a&gt;Spring Cloud Gateway&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;LoadBalancer Lifecycle support has been added (&lt;a href="https://github.com/spring-cloud/spring-cloud-gateway/pull/2066"&gt;PR&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following modules were updated as part of 2020.0.0-RC1:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Module &lt;/th&gt;
      &lt;th&gt;Version &lt;/th&gt;
      &lt;th&gt;Issues&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Circuitbreaker &lt;/td&gt;
      &lt;td&gt;2.0.0-RC1 &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-circuitbreaker/milestone/7?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Contract &lt;/td&gt;
      &lt;td&gt;3.0.0-RC1 &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-contract/milestone/73?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Kubernetes &lt;/td&gt;
      &lt;td&gt;2.0.0-RC1 &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-kubernetes/milestone/27?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Commons &lt;/td&gt;
      &lt;td&gt;3.0.0-RC1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Openfeign &lt;/td&gt;
      &lt;td&gt;3.0.0-RC1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Cloudfoundry &lt;/td&gt;
      &lt;td&gt;3.0.0-RC1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Security &lt;/td&gt;
      &lt;td&gt;3.0.0-RC1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Bus &lt;/td&gt;
      &lt;td&gt;3.0.0-RC1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Cli &lt;/td&gt;
      &lt;td&gt;3.0.0-RC1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Zookeeper &lt;/td&gt;
      &lt;td&gt;3.0.0-RC1 &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-zookeeper/milestone/32?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Sleuth &lt;/td&gt;
      &lt;td&gt;3.0.0-RC1 &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-sleuth/milestone/85?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Consul &lt;/td&gt;
      &lt;td&gt;3.0.0-RC1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Gateway &lt;/td&gt;
      &lt;td&gt;3.0.0-RC1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Netflix &lt;/td&gt;
      &lt;td&gt;3.0.0-RC1 &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-netflix/milestone/97?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Vault &lt;/td&gt;
      &lt;td&gt;3.0.0-RC1 &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-vault/milestone/43?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Config &lt;/td&gt;
      &lt;td&gt;3.0.0-RC1 &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-config/milestone/83?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Task &lt;/td&gt;
      &lt;td&gt;2.3.0-RC1 &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-task/releases/tag/2.3.0-RC1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As always, we welcome feedback on &lt;a href="https://github.com/spring-cloud/"&gt;GitHub&lt;/a&gt;, on &lt;a href="https://gitter.im/spring-cloud/spring-cloud"&gt;Gitter&lt;/a&gt;, on &lt;a href="https://stackoverflow.com/questions/tagged/spring-cloud"&gt;Stack Overflow&lt;/a&gt;, or on &lt;a href="https://twitter.com/SpringCloud"&gt;Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The following listings show how to get started with Maven with a BOM (dependency management only) or with Gradle:&lt;/p&gt;
&lt;p&gt;Maven with BOM:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;&lt;br/&gt;    &amp;lt;repositories&amp;gt;&#xD;
        &amp;lt;repository&amp;gt;&#xD;
            &amp;lt;id&amp;gt;spring-milestones&amp;lt;/id&amp;gt;&#xD;
            &amp;lt;name&amp;gt;Spring Milestones&amp;lt;/name&amp;gt;&#xD;
            &amp;lt;url&amp;gt;https://repo.spring.io/milestone&amp;lt;/url&amp;gt;&#xD;
            &amp;lt;snapshots&amp;gt;&#xD;
                &amp;lt;enabled&amp;gt;false&amp;lt;/enabled&amp;gt;&#xD;
            &amp;lt;/snapshots&amp;gt;&#xD;
        &amp;lt;/repository&amp;gt;&#xD;
    &amp;lt;/repositories&amp;gt;&#xD;
&amp;lt;dependencyManagement&amp;gt;&#xD;
    &amp;lt;dependencies&amp;gt;&#xD;
        &amp;lt;dependency&amp;gt;&#xD;
            &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
            &amp;lt;artifactId&amp;gt;spring-cloud-dependencies&amp;lt;/artifactId&amp;gt;&#xD;
            &amp;lt;version&amp;gt;2020.0.0-RC1&amp;lt;/version&amp;gt;&#xD;
            &amp;lt;type&amp;gt;pom&amp;lt;/type&amp;gt;&#xD;
            &amp;lt;scope&amp;gt;import&amp;lt;/scope&amp;gt;&#xD;
        &amp;lt;/dependency&amp;gt;&#xD;
    &amp;lt;/dependencies&amp;gt;&#xD;
&amp;lt;/dependencyManagement&amp;gt;&#xD;
&amp;lt;dependencies&amp;gt;&#xD;
    &amp;lt;dependency&amp;gt;&#xD;
        &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
        &amp;lt;artifactId&amp;gt;spring-cloud-starter-config&amp;lt;/artifactId&amp;gt;&#xD;
    &amp;lt;/dependency&amp;gt;&#xD;
    &amp;lt;dependency&amp;gt;&#xD;
        &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
        &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-client&amp;lt;/artifactId&amp;gt;&#xD;
    &amp;lt;/dependency&amp;gt;&#xD;
    ...&#xD;
&amp;lt;/dependencies&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Gradle:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;buildscript {&#xD;
dependencies {&#xD;
classpath &amp;quot;io.spring.gradle:dependency-management-plugin:1.0.2.RELEASE&amp;quot;&#xD;
}&#xD;
}&#xD;
&#xD;
repositories {&#xD;
maven {&#xD;
url &amp;#39;https://repo.spring.io/milestone&amp;#39;&#xD;
}&#xD;
}&#xD;
&#xD;
apply plugin: &amp;quot;io.spring.dependency-management&amp;quot;&#xD;
&#xD;
dependencyManagement {&#xD;
imports {&#xD;
mavenBom &amp;#39;org.springframework.cloud:spring-cloud-dependencies:2020.0.0-RC1&amp;#39;&#xD;
}&#xD;
}&#xD;
&#xD;
dependencies {&#xD;
compile &amp;#39;org.springframework.cloud:spring-cloud-starter-config&amp;#39;&#xD;
compile &amp;#39;org.springframework.cloud:spring-cloud-starter-netflix-eureka-client&amp;#39;&#xD;
...&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>A Bootiful Podcast: Spring Batch co-lead Mahmoud Ben Hassine</title>
    <link rel="alternate" href="https://spring.io/blog/2020/12/15/a-bootiful-podcast-spring-batch-co-lead-mahmoud-ben-hassine" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-15:4305</id>
    <updated>2020-12-15T04:43:30Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! In this special midweek installment I correct a mistake I made last week when I inadvertently released the episode featuring Dion Almaer, with the interview I conducted with Spring Batch co-lead Mahmoud Ben Hassine. This is the actual episode with Mahmoud Ben Hassine, with the correct title and everything! Enjoy!&lt;/p&gt;
&lt;iframe title="Spring Batch co-lead Mahmoud Ben Hassine" height="122" width="100%" style="border: none;" scrolling="no" data-name="pb-iframe-player" src="https://www.podbean.com/media/player/rpgt4-f50e00?from=pb6admin&amp;download=1&amp;version=1&amp;auto=0&amp;share=1&amp;download=1&amp;rtl=0&amp;fonts=Helvetica&amp;skin=1&amp;pfauth=&amp;btn-skin=107"&gt;&lt;/iframe&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>A Bootiful Podcast: open-web legend Dion Almaer</title>
    <link rel="alternate" href="https://spring.io/blog/2020/12/14/a-bootiful-podcast-open-web-legend-dion-almaer" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-11:4297</id>
    <updated>2020-12-14T23:00:00Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! In this special midweek installment I (Josh Long) correct a mistake I made last week when I inadvertently released the episode featuring open-web legend Dion Almaer with the interview I conducted with the inspirational and oh-so-amazing Spring Batch co-lead Mahmoud Ben Hassine. This is the actual episode with &lt;a href="http://twitter.com/dalmaer"&gt;Dion Almaer (@dalmaer)&lt;/a&gt; who is known for so many contributions to the Java ecosystem and beyond. I know him as a former editor in chief of TheServerSide.com, but you may know him for his work championing the open web at Palm, Walmart, and Google, and many more. &lt;/p&gt;
&lt;iframe title="Open web legend Dion Almaer" height="122" width="100%" style="border: none;" scrolling="no" data-name="pb-iframe-player" src="https://www.podbean.com/media/player/awqpe-f50e26?from=pb6admin&amp;download=1&amp;version=1&amp;auto=0&amp;share=1&amp;download=1&amp;rtl=0&amp;fonts=Helvetica&amp;skin=1&amp;pfauth=&amp;btn-skin=107"&gt;&lt;/iframe&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Case Study: Change Data Capture (CDC) Analysis with CDC Debezium source and Analytics sink in Real-Time</title>
    <link rel="alternate" href="https://spring.io/blog/2020/12/14/case-study-change-data-capture-cdc-analysis-with-cdc-debezium-source-and-analytics-sink-in-real-time" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Christian Tzolov</name>
    </author>
    <id>tag:spring.io,2020-12-10:4295</id>
    <updated>2020-12-14T16:30:00Z</updated>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;This article is part of a blog series that explores the newly redesigned Spring Cloud Stream applications based on Java Functions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Here are all the previous parts of this blog series.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/07/13/introducing-java-functions-for-spring-cloud-stream-applications-part-0"&gt;Introducing Function Based Streaming Applications&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/07/20/introducing-java-functions-for-spring-cloud-stream-applications-part-1"&gt;Function Composition with Streaming Applications&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/07/27/creating-a-supplier-function-and-generating-spring-cloud-stream-source"&gt;How to Build a Supplier and Source Application&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/08/03/creating-a-function-for-consuming-data-and-generating-spring-cloud-stream-sink-applications"&gt;How to Build a Consumer and Sink Application&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/08/10/case-study-build-and-run-a-streaming-application-using-an-http-source-and-a-jdbc-sink"&gt;Build and Run a Simple Stream Application&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/08/17/case-study-http-request-function-and-processor"&gt;Case Study: HTTP Request Function and Processor&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/08/25/case-study-reading-from-a-file-and-writing-to-mongodb"&gt;Case Study: File Source and MongoDB Sink&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/09/10/case-study-relational-database-source-and-file-sink"&gt;Case Study: Relational Database Source and File Sink&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/09/29/case-study-remote-file-ingest-with-spring-cloud-data-flow"&gt;Case Study: Remote File Ingest with Spring Cloud Data Flow&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/10/26/case-study-aggregator-function-and-processor"&gt;Case Study: Aggregator Function and Processor&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://spring.io/blog/2020/11/16/case-study-elasticsearch-sink"&gt;Case Study: Elasticsearch sink&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this post, we will look at the &lt;a href="https://github.com/spring-cloud/stream-applications/blob/master/applications/source/cdc-debezium-source/README.adoc"&gt;Debezium CDC source&lt;/a&gt; that allows us to capture database changes from databases such as MySQL, PostgreSQL, MongoDB, Oracle, DB2 and SQL Server and process those changes, in real-time, over various message binders, such as RabbitMQ, Apache Kafka, Azure Event Hubs, Google PubSub and Solace PubSub+ to name a few.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Also we will reveal how to use the &lt;a href="https://github.com/spring-cloud/stream-applications/tree/master/applications/sink/analytics-sink"&gt;Analytics sink&lt;/a&gt; to convert the captured database changes into metrics and publish them to various monitoring systems for further analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This article starts by explaining the &lt;code&gt;CDC supplier&lt;/code&gt; and the &lt;code&gt;Analytics consumer&lt;/code&gt; components, showing how to customize and use them programmatically in your own Spring applications. Next we explain how the &lt;a href="https://github.com/spring-cloud/stream-applications/tree/master/applications/source/cdc-debezium-source"&gt;CDC source&lt;/a&gt; and the &lt;a href="https://github.com/spring-cloud/stream-applications/tree/master/applications/sink/analytics-sink"&gt;Analytics sink&lt;/a&gt;, build upon the supplier and the consumer,  to provide  out of the box, ready to use streaming applications.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Finally we will demo how easy is it to use &lt;a href="https://dataflow.spring.io"&gt;Spring Cloud Data Flow (SCDF)&lt;/a&gt; for deploying streaming pipelines that react, in real-time, to database updates, convert the change events into analytics metrics and publish them to Prometheus for analysis and visualization with Grafana:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="videoblock"&gt;
&lt;div class="content"&gt;
&lt;iframe width="100%" height="480" src="https://www.youtube.com/embed/nNHAw8Cj7pM?rel=0" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="change-data-capture"&gt;&lt;a class="anchor" href="#change-data-capture"&gt;&lt;/a&gt;Change Data Capture&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Change Data Capture (CDC) is a technique for observing all data changes written to a database and publishing them as events that can be processed in a streamed fashion.
As your application database is always changing, the CDC allows you to react to those  changes and lets your applications stream every row-level change in the same order as they were committed to the database.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;CDC enables a multitude of use-cases such as: cache invalidation, in-memory data views,  update search indexes, data replication by  keeping different data sources in sync, real-time fraud detection, storing audit trails, data provenance and much more.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The Spring Cloud Data Flow &lt;a href="https://github.com/spring-cloud/stream-applications/tree/master/applications/source/cdc-debezium-source"&gt;CDC Source&lt;/a&gt; application is built around &lt;a href="https://debezium.io/"&gt;Debezium&lt;/a&gt;, a popular, open source, log-based CDC implementation that supports various databases.
The CDC Source supports a variety of message binders, including Apache Kafka, Rabbit MQ, Azure Event Hubs, Google PubSub, Solace PubSub+.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
The &lt;code&gt;CDC source&lt;/code&gt; implementation embeds the &lt;a href="https://debezium.io/documentation/reference/development/engine.html"&gt;Debezium Engine&lt;/a&gt; and it does not depend on Apache Kafka nor ZooKeeper!
You can use the &lt;code&gt;CDC source&lt;/code&gt; along with any of the supported message binders!
The the &lt;code&gt;Debezium Engine&lt;/code&gt; though comes with some &lt;a href="https://debezium.io/documentation/reference/development/engine.html#_handling_failures"&gt;limitations&lt;/a&gt; to be considered.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="cdc-debezium-supplier"&gt;&lt;a class="anchor" href="#cdc-debezium-supplier"&gt;&lt;/a&gt;CDC Debezium Supplier&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The &lt;a href="https://github.com/spring-cloud/stream-applications/tree/master/functions/supplier/cdc-debezium-supplier"&gt;CDC Debezium Supplier&lt;/a&gt; is implemented as &lt;code&gt;java.util.function.Supplier&lt;/code&gt; bean which when invoked will deliver the contents of the files in a given directory. The file supplier has the following signature:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;Supplier&amp;lt;Flux&amp;lt;Message&amp;lt;?&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The users of the supplier can subscribe to the returned &lt;code&gt;Flux&amp;lt;Message&amp;lt;?&amp;gt;&lt;/code&gt;, which is a stream of messages or &lt;a href="https://debezium.io/documentation/reference/configuration/event-flattening.html#_change_event_structure"&gt;CDC Change Events&lt;/a&gt;, that have a complex structure. Each event consists of three parts (e.g. &lt;code&gt;metadata&lt;/code&gt;, &lt;code&gt;before&lt;/code&gt; and &lt;code&gt;after&lt;/code&gt;) as shown in the following payload sample:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="json"&gt;{
  "before": { ... },  // row data before the change.
  "after": { ... },  // row data after the change.
  "source": {  //  the names of the database and table where the change was made.
    "connector": "mysql", "server_id": 223344,"snapshot": "false",
    "name": "my-app-connector", "file": "mysql-bin.000003", "pos": 355, "row": 0,
    "db": "inventory",  // source database name.
    "table": "customers", // source table name.
  },
  "op": "u",  // operation that made the change.
  "ts_ms": 1607440256301, // timestamp - when the change was made.
  "transaction": null  // transaction information (optional).
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If the &lt;code&gt;cdc.flattening.enabled&lt;/code&gt; property is set to &lt;code&gt;true&lt;/code&gt;, then only the &lt;code&gt;after&lt;/code&gt; section is passed as a standalone message.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In order to invoke the CDC supplier, we need to specify a source database to receive the CDC events from. The &lt;code&gt;cdc.connector&lt;/code&gt; property is used to choose between the supported &lt;code&gt;mysql&lt;/code&gt;, &lt;code&gt;postgres&lt;/code&gt;, &lt;code&gt;sql server&lt;/code&gt;, &lt;code&gt;db2&lt;/code&gt;, &lt;code&gt;oracle&lt;/code&gt;, &lt;code&gt;cassandra&lt;/code&gt; and &lt;code&gt;mongo&lt;/code&gt; source database types..
The &lt;code&gt;cdc.config.database.*&lt;/code&gt; properties help to configure the the source access. Here is a sample configuration for connecting to a MySQL databases:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code&gt;# DB type
cdc.connector=mysql

# DB access
cdc.config.database.user=debezium
cdc.config.database.password=dbz
cdc.config.database.hostname=localhost
cdc.config.database.port=3306

# DB source metadata
cdc.name=my-sql-connector
cdc.config.database.server.id=85744
cdc.config.database.server.name=my-app-connector&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The &lt;code&gt;cdc.name, cdc.config.database.server.id&lt;/code&gt; and &lt;code&gt;cdc.config.database.server.name&lt;/code&gt; properties are used to identify and dispatch the incoming events.
Optionally you can set the &lt;code&gt;cdc.flattening.enabled=true&lt;/code&gt; to flatten the CDC events to replace the original change event with only its after field to create a simple Kafka record.
Optionally use the &lt;code&gt;cdc.schema=true&lt;/code&gt; to include the DB schema to the CDC events.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
The source database must be configured to expose its &lt;code&gt;Write-Ahead Log API&lt;/code&gt; for the Debezium to be able to connect and consume CDC events. The &lt;a href="https://debezium.io/documentation/reference/connectors/index.html"&gt;Debezium Connector Documentation&lt;/a&gt; provides fine description of how to enable the CDC for any of the supported databases.
For the purpose of our demos here we will use a preconfigured &lt;a href="https://hub.docker.com/r/debezium/example-mysql"&gt;MySQL docker image&lt;/a&gt;.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="reusing-cdc-supplier-in-custom-applications"&gt;&lt;a class="anchor" href="#reusing-cdc-supplier-in-custom-applications"&gt;&lt;/a&gt;Reusing CDC Supplier in custom applications&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The CDC supplier is a reusable Spring bean that we can inject in end-user custom applications. Once injected, this can be directly invoked and combined with custom processing of the data. Here is an example.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;@Autowired
Supplier&amp;lt;Flux&amp;lt;Message&amp;lt;?&amp;gt;&amp;gt;&amp;gt; cdcSupplier;

public void consumeDataAndSendEmail() {
  Flux&amp;lt;Message&amp;lt;?&amp;gt; cdcData = cdcSupplier.get();
  messageFlux.subscribe(t -&amp;gt; {
      if (t == something)
         //send the email here.
      }
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In the above pseudo-code, we inject the CDC supplier bean and then use it to invoke its &lt;code&gt;get()&lt;/code&gt; method to get a Flux. We then subscribe to that &lt;a href="https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Flux.html"&gt;Flux&lt;/a&gt; and each time we receive any data through the Flux, apply some filtering, and take actions based on that. This is just a simple illustration to show how we can reuse the CDC supplier. When you try this in a real application, you probably need to make more adjustments in your implementation, such as converting the default data type of the received data from &lt;code&gt;byte[]&lt;/code&gt; into something else before doing the conditional check.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="admonitionblock tip"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Tip&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
For building a standalone, non-streaming, application you can leverage the &lt;a href="https://github.com/spring-cloud/stream-applications/tree/master/functions/common/cdc-debezium-boot-starter"&gt;cdc-debezium-boot-starter&lt;/a&gt;. Just add the &lt;code&gt;cdc-debezium-boot-starter&lt;/code&gt; dependency and implement your custom &lt;code&gt;Consumer&amp;lt;SourceRecord&amp;gt;&lt;/code&gt; handler to process the incoming database change events.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="cdc-debezium-source"&gt;&lt;a class="anchor" href="#cdc-debezium-source"&gt;&lt;/a&gt;CDC Debezium Source&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As we have seen in this blog series, all the out of the box Spring Cloud Stream source applications are already autoconfigured with several out of the box general-purpose processors. You can activate these processors as part of the &lt;a href="https://github.com/spring-cloud/stream-applications/tree/master/applications/source/cdc-debezium-source"&gt;CDC source&lt;/a&gt;. Here is an example, where we run the CDC source and receive the data and then transforms the consumed data before sending it out to the destination on middleware.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="bash"&gt;java -jar cdc-debezium-source.jar
 --cdc.connector=mysql --cdc.name=my-sql-connector
 --cdc.config.database.server.name=my-app-connector
 --cdc.config.database.user=debezium --cdc.config.database.password=dbz
 --cdc.config.database.hostname=localhost --cdc.config.database.port=3306
 --cdc.schema=true
 --cdc.flattening.enabled=true
 --spring.cloud.function.definition=cdcSupplier|spelFunction
 --spel.function.expression=payload.toUpperCase()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;By providing the value, &lt;code&gt;cdcSupplier|spelFunction&lt;/code&gt; for the &lt;code&gt;spring.cloud.function.definition&lt;/code&gt; property, we are activating the spel function composed with the CDC supplier. Then we provide a SpEL expression that we want to use to transform the data using &lt;code&gt;spel.function.expression&lt;/code&gt;. There are several other functions available to compose this way. Take a look &lt;a href="https://github.com/spring-cloud/stream-applications/blob/master/docs/FunctionComposition.adoc"&gt;here&lt;/a&gt; for more details.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="analytics-consumer"&gt;&lt;a class="anchor" href="#analytics-consumer"&gt;&lt;/a&gt;Analytics Consumer&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The &lt;a href="https://github.com/spring-cloud/stream-applications/tree/master/functions/consumer/analytics-consumer"&gt;Analytics consumer&lt;/a&gt; provides a function that computes analytics from the input data messages and publishes them as metrics to various monitoring systems. It leverages the &lt;a href="https://micrometer.io/"&gt;micrometer library&lt;/a&gt; for providing a uniform programming experience across the most popular &lt;a href="https://micrometer.io/docs"&gt;monitoring systems&lt;/a&gt; and uses &lt;a href="https://docs.spring.io/spring-integration/reference/html/spel.html#spel"&gt;Spring Expression Language (SpEL)&lt;/a&gt; for defining how the metric names, values and tags are computed from the input data.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We can use the consumer bean directly in our custom applications to compute analytics from the passing messages. Here is the type signature of the Analytics consumer bean:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="java"&gt;Consumer&amp;lt;Message&amp;lt;?&amp;gt;&amp;gt; analyticsConsumer&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Once injected into a custom application, users can directly invoke the &lt;code&gt;accept()&lt;/code&gt; method of the consumer and provide a &lt;code&gt;Message&amp;lt;?&amp;gt;&lt;/code&gt; object to compute and publish the analytics to the backend monitoring system.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The &lt;a href="https://docs.spring.io/spring-integration/reference/html/message.html"&gt;Message&lt;/a&gt; is a generic container for data. Each Message instance includes a &lt;code&gt;payload&lt;/code&gt; and &lt;code&gt;headers&lt;/code&gt; containing user-extensible properties as key-value pairs.
The SpEL expressions are used to access messages headers and payload to compute metrics amounts and tags.
For example a counter metrics can have a value &lt;code&gt;amount&lt;/code&gt; computed from the size of the input message payload add a &lt;code&gt;my_tag&lt;/code&gt; tag, extracted from the &lt;code&gt;kind&lt;/code&gt; header value:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code&gt;analytics.amount-expression=payload.lenght()
analytics.tag.expression.my_tag=headers['kind']&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The Analytics consumer configuration properties start with the &lt;code&gt;analytics.*&lt;/code&gt; prefix. Consult the &lt;a href="https://github.com/spring-cloud/stream-applications/blob/master/functions/consumer/analytics-consumer/src/main/java/org/springframework/cloud/fn/consumer/analytics/AnalyticsConsumerProperties.java"&gt;AnalyticsConsumerProperties&lt;/a&gt; for the available analytics properties.
The monitoring configuration properties start with a &lt;code&gt;management.metrics.export&lt;/code&gt; prefix. For configuring a particular monitoring system follow the provided &lt;a href="https://docs.spring.io/spring-boot/docs/2.3.1.RELEASE/reference/html/production-ready-features.html#production-ready-metrics-export"&gt;configuration instructions&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="analytics-sink"&gt;&lt;a class="anchor" href="#analytics-sink"&gt;&lt;/a&gt;Analytics Sink&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As in the case of &lt;code&gt;CDC Source&lt;/code&gt;, the Spring Cloud Stream out of the box applications already provide an &lt;a href="https://github.com/spring-cloud/stream-applications/tree/master/applications/sink/analytics-sink"&gt;Analytics sink&lt;/a&gt; based on the &lt;code&gt;Analytics consumer&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The sink is available for both &lt;a href="https://repo.spring.io/libs-snapshot-local/org/springframework/cloud/stream/app/mongodb-sink-kafka/3.0.0-SNAPSHOT"&gt;Apache Kafka&lt;/a&gt; and &lt;a href="https://repo.spring.io/libs-snapshot-local/org/springframework/cloud/stream/app/mongodb-sink-rabbit/3.0.0-SNAPSHOT"&gt;RabbitMQ&lt;/a&gt; binder variants.
When used as a Spring Cloud Stream sink, the Analytics consumer is automatically configured to accept data from the respective middleware system, for example, from a Kafka topic or RabbitMQ exchange.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="running-on-spring-cloud-data-flow"&gt;&lt;a class="anchor" href="#running-on-spring-cloud-data-flow"&gt;&lt;/a&gt;Running on Spring Cloud Data Flow&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Running both &lt;code&gt;CDC source&lt;/code&gt; and &lt;code&gt;Analytics sink&lt;/code&gt; standalone was fine, but Spring Cloud Data Flow makes it really easy to run them as a pipeline. Basically we want to orchestrate data flows that looks like this:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="https://github.com/spring-cloud/stream-applications/blob/gh-pages/img/cdc-analytics/scdf-pipelines.png?raw=true" alt="scdf pipelines" width="30%"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The &lt;code&gt;cdc-log&lt;/code&gt; pipeline deploys a &lt;code&gt;cdc-source&lt;/code&gt; that streams all database changes into a &lt;code&gt;log-sink&lt;/code&gt; using  JSON message format. In parallel the &lt;code&gt;cdc-analytics-tap&lt;/code&gt;  pipeline &lt;a href="https://dataflow.spring.io/docs/feature-guides/streams/fanin-fanout/"&gt;taps&lt;/a&gt; the &lt;code&gt;cdc-source&lt;/code&gt; output into an &lt;code&gt;analytics-sink&lt;/code&gt; to compute DB statistics from the CDC events and publish them to time-series database (TSDB) such as Prometheus or Wavefront. The Grafana dashboard is used to visualize those changes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The Spring Cloud Data Flow &lt;a href="https://dataflow.spring.io/docs/installation/"&gt;installation instructions&lt;/a&gt; explains how to install Spring Cloud Data Flow fore any of the supported cloud platforms.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Below, we will briefly provide the steps to set up Spring Cloud Data Flow.
First, we need to get the docker-compose files for running Spring Cloud Data Flow, &lt;a href="https://dataflow.spring.io/docs/installation/local/docker-customize/#prometheus&amp;#8212;&amp;#8203;grafana"&gt;Prometheus and Grafana&lt;/a&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code&gt;wget -O docker-compose.yml https://raw.githubusercontent.com/spring-cloud/spring-cloud-dataflow/v2.7.0/spring-cloud-dataflow-server/docker-compose.yml&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code&gt;wget -O docker-compose-prometheus.yml https://raw.githubusercontent.com/spring-cloud/spring-cloud-dataflow/v2.7.0/spring-cloud-dataflow-server/docker-compose-prometheus.yml&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Also, get this additional docker-compose file to install a source MySQL database configured to expose its write-ahead log that the cdc-debezium connects to.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code&gt;wget -O mysql-cdc.yml https://gist.githubusercontent.com/tzolov/48dec8c0db44e8086916129201cc2c8c/raw/26e1bf435d58e25ff836e415dae308edeeef2784/mysql-cdc.yml&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The mysql-cdc uses the &lt;a href="https://hub.docker.com/r/debezium/example-mysql"&gt;debezium/example-mysql&lt;/a&gt; image and comes with an inventory, sample database:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="https://github.com/spring-cloud/stream-applications/blob/gh-pages/img/cdc-analytics/invetory-db.png?raw=true" alt="invetory db" width="50%"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We need to set up a few environment variables in order to run Spring Cloud Data Flow properly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="shell"&gt;export DATAFLOW_VERSION=2.7.0
export SKIPPER_VERSION=2.6.0
export STREAM_APPS_URI=https://dataflow.spring.io/kafka-maven-latest-v2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now that we have everything ready to go, it is time to start running Spring Cloud Data Flow and all the other ancillary components.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="shell"&gt;docker-compose -f docker-compose.yml -f docker-compose-prometheus.yml -f mysql-cdc.yml up&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="admonitionblock tip"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Tip&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
To use &lt;code&gt;RabbitMQ&lt;/code&gt; instead of &lt;code&gt;Apache Kafka&lt;/code&gt; you can download an additional docker-compose file as explained in the  &lt;a href="https://dataflow.spring.io/docs/installation/local/docker-customize/#rabbitmq-instead-of-kafka"&gt;RabbitMQ Instead of Kafka
&lt;/a&gt; instructions, and set the &lt;code&gt;STREAM_APPS_URI&lt;/code&gt; variable to &lt;a href="https://repo.spring.io/libs-snapshot-local/org/springframework/cloud/stream/app/stream-applications-descriptor/2020.0.0-SNAPSHOT/stream-applications-descriptor-2020.0.0-SNAPSHOT.stream-apps-rabbit-maven" class="bare"&gt;https://repo.spring.io/libs-snapshot-local/org/springframework/cloud/stream/app/stream-applications-descriptor/2020.0.0-SNAPSHOT/stream-applications-descriptor-2020.0.0-SNAPSHOT.stream-apps-rabbit-maven&lt;/a&gt; instead.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="admonitionblock tip"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Tip&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
To use Wavefront instead of Prometheus &amp;amp; Grafana, follow the &lt;a href="https://dataflow.spring.io/docs/installation/local/docker-customize/#wavefront"&gt;Wavefront&lt;/a&gt; instructions.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Once SCDF is up and running, go to &lt;a href="http://localhost:9393/dashboard"&gt;http://localhost:9393/dashboard&lt;/a&gt;. Then go to &lt;code&gt;Streams&lt;/code&gt; on the left-hand side and select &lt;code&gt;Create Stream&lt;/code&gt;. Select &lt;code&gt;cdc-debezium&lt;/code&gt; from the source applications and &lt;code&gt;log&lt;/code&gt; and &lt;code&gt;analytics&lt;/code&gt; from the sink applications to define the &lt;code&gt;cdc-log = cdc-debezium | log&lt;/code&gt; and the &lt;code&gt;cdc-analytic-tap = :cdc-log.cdc-debezium &amp;gt; analytics&lt;/code&gt; pipelines. You can click on the application&amp;#8217;s options to select the desired properties.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For a quicker bootstrap,  you can copy/paste the following ready to use pipeline definition snippets:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code&gt;cdc-log = cdc-debezium --cdc.name=mycdc --cdc.flattening.enabled=false --cdc.connector=mysql --cdc.config.database.user=debezium --cdc.config.database.password=dbz --cdc.config.database.dbname=inventory --cdc.config.database.hostname=mysql-cdc --cdc.config.database.port=3307 --cdc.stream.header.offset=true --cdc.config.database.server.name=my-app-connector --cdc.config.tombstones.on.delete=false | log&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code&gt;cdc-analytic-tap = :cdc-log.cdc-debezium &amp;gt; analytics --analytics.name=cdc --analytics.tag.expression.table=#jsonPath(payload,'$..table') --analytics.tag.expression.operation=#jsonPath(payload,'$..op') --analytics.tag.expression.db=#jsonPath(payload,'$..db')&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The &lt;code&gt;cdc-log&lt;/code&gt; pipeline deploys a &lt;code&gt;cdc-debezium source&lt;/code&gt; that connects to an MySQL database at &lt;code&gt;mysql-cdc:3307&lt;/code&gt; and streams the  DB change events to the &lt;code&gt;log sink&lt;/code&gt;. Consult the &lt;a href="https://github.com/spring-cloud/stream-applications/blob/master/applications/source/cdc-debezium-source/README.adoc"&gt;cdc-debezium docs&lt;/a&gt; for the available configuration options.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The &lt;code&gt;cdc-analytic-tap&lt;/code&gt; pipeline taps into the output of the &lt;code&gt;cdc-debezium source&lt;/code&gt; and streams the cdc events to an &lt;code&gt;analytics sink&lt;/code&gt;. The analytics creates a &lt;a href="https://micrometer.io/docs/concepts#_counters"&gt;metrics counter&lt;/a&gt; (called cdc) and uses &lt;a href="https://docs.spring.io/spring-integration/reference/html/spel.html#built-in-spel-functions"&gt;SpEL expressions&lt;/a&gt; to compute metrics tags (e.g. db, table and operations) from the streamed message payloads.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For example, lets modify the &lt;code&gt;customers&lt;/code&gt; table in the MySQL &lt;code&gt;inventory&lt;/code&gt; database. The update transaction is sent as a change event to the &lt;code&gt;cdc-debezium source&lt;/code&gt;, that converts the native DB event into an uniform message payload like this:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="json"&gt;{
  "before": {
    "id": 1004, "first_name": "Anne", "last_name": "Kretchmar", "email": "annek@noanswer.org"
  },
  "after": {
    "id": 1004, "first_name": "Anne2", "last_name": "Kretchmar", "email": "annek@noanswer.org"
  },
  "source": {
    "version": "1.3.1.Final", "connector": "mysql", "server_id": 223344, "thread": 5,
    "name": "my-app-connector", "file": "mysql-bin.000003", "pos": 355, "row": 0,
    "db": "inventory",
    "table": "customers",
  },
  "op": "u",
  "ts_ms": 1607440256301,
  "transaction": null
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The following SpEL expressions are used to compute 3 tags (&lt;code&gt;db&lt;/code&gt;, &lt;code&gt;table&lt;/code&gt;, &lt;code&gt;operation&lt;/code&gt;) from the CDC message payload. Those tags are assigned to every cdc metrics published to Prometheus.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code&gt;--analytics.tag.expression.db=#jsonPath(payload,'$..db')
--analytics.tag.expression.table=#jsonPath(payload,'$..table')
--analytics.tag.expression.operation=#jsonPath(payload,'$..op')&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Here is a screenshot of how it should look after all the properties are selected:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="https://github.com/spring-cloud/stream-applications/blob/gh-pages/img/cdc-analytics/scdf-create-streams.png?raw=true" alt="scdf create streams" width="100%"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;a href="https://dataflow.spring.io/docs/stream-developer-guides/getting-started/stream/#creating-the-stream"&gt;Create&lt;/a&gt; and  &lt;a href="https://dataflow.spring.io/docs/stream-developer-guides/getting-started/stream/#deploying-a-stream"&gt;deploy&lt;/a&gt; the &lt;code&gt;cdc-log&lt;/code&gt; and the &lt;code&gt;cdc-analytics-tap&lt;/code&gt; pipelines, accepting all the default options. Optionally you can use the &lt;code&gt;Group Actions&lt;/code&gt; to deploy both streams simultaneously.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Once the streams are deployed you can check the logs of the deployed applications via the SCDF UI or using the Skipper docker container as &lt;a href="https://dataflow.spring.io/docs/stream-developer-guides/getting-started/stream/#results"&gt;explained&lt;/a&gt; in the documentation.
If you check the logs of the Log sink application you should see the CDC JSON messages similar to those:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="https://github.com/spring-cloud/stream-applications/blob/gh-pages/img/cdc-analytics/cdc-event-log.png?raw=true" alt="cdc event log" width="100%"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Next go to the Grafana Dashboard using the &lt;a href="https://dataflow.spring.io/docs/feature-guides/streams/monitoring/#data-flow-metric-buttons"&gt;buttons&lt;/a&gt; (or just open &lt;a href="http://localhost:3000"&gt;localhost:3000&lt;/a&gt;) and login as user:`admin` and password:`admin`. You can explore the &lt;code&gt;Applications&lt;/code&gt; dashboard to check the performance of the deployed pipelines.
Now you can import the &lt;a href="https://gist.github.com/tzolov/d2a71fc58616278fb8852f5fc43d242f#file-cdc-grafana-dashboard-prometheus-json"&gt;CDC Grafana Dashboard-Prometheus.json&lt;/a&gt; dashboard and see a dashboard similar to this:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="https://github.com/spring-cloud/stream-applications/blob/gh-pages/img/cdc-analytics/grafana-dashboard.png?raw=true" alt="grafana dashboard" width="100%"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The following queries have been used to aggregate the &lt;code&gt;cdc_total&lt;/code&gt; metrics inside Prometheus:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code&gt;sort_desc(topk(10, sum(cdc_total) by (db, table)))
sort_desc(topk(100, sum(cdc_total) by (op)))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="admonitionblock tip"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Tip&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
You can open the Prometheus UI at &lt;a href="http://localhost:9090"&gt;http://localhost:9090&lt;/a&gt; to check the configuration as well as run some ad hoc PQL queries.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="sect3"&gt;
&lt;h4 id="generate-db-activity"&gt;&lt;a class="anchor" href="#generate-db-activity"&gt;&lt;/a&gt;Generate DB activity&lt;/h4&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You can connect to the inventory CDC MySQL databases at &lt;code&gt;localhost:3307&lt;/code&gt; (user: &lt;code&gt;root&lt;/code&gt; and password: &lt;code&gt;debezium&lt;/code&gt;) and start modifying the data.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The following docker command shows how to connect to the mysql-cdc:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="bash"&gt;docker exec -it mysql-cdc  mysql -uroot -pdebezium --database=inventory&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The following  script helps to generate multiple insert, update and delete DB transactions:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="bash"&gt;for i in {1..100}; do docker exec -it mysql-cdc  mysql -uroot -pdebezium --database=inventory -e'INSERT INTO customers (first_name, last_name, email) VALUES ("value1", "value2", "val@bla"); UPDATE customers SET first_name="value2" WHERE first_name="value1"; DELETE FROM customers where first_name="value2";'; done&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You will see the &lt;code&gt;log-sink&lt;/code&gt; logs reflecting those changes as well as the CDC dashboard charts updates.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="conclusions-and-future-work"&gt;&lt;a class="anchor" href="#conclusions-and-future-work"&gt;&lt;/a&gt;Conclusions and future work&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this blog, we saw how the CDC-debezium supplier and the Analytics consumer functions and their corresponding Spring Cloud Stream source and sink work. The supplier and consumer functions can be injected into custom applications for combining with other business logic.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The source and the sink applications are provided out of the box for use with Kafka and RabbitMQ middleware variants.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You can easily build standalone applications combining the Cdc-debezium supplier with Geode consumer to create and maintain an in-memory view of your database data. Similarly you can combine the Cdc-debezium supplier with the Elasticsearch consumer for maintaining in real-time a searchable index for your database data.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;What is more exciting is that you can realize the above scenarios using the OOTB &lt;a href="https://github.com/spring-cloud/stream-applications/tree/master/applications/source/cdc-debezium-source"&gt;cdc-debezium source&lt;/a&gt; , &lt;a href="https://github.com/spring-cloud/stream-applications/tree/master/applications/sink/geode-sink"&gt;geode sink&lt;/a&gt; and &lt;a href="https://github.com/spring-cloud/stream-applications/tree/master/applications/sink/elasticsearch-sink"&gt;elasticsearch sink&lt;/a&gt; applications. You can build those pipelines over different message binders and source databases.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This &lt;a href="https://www.infoq.com/presentations/spring-pipeline-prometheus-grafana/?utm_campaign=infoq_content&amp;amp;utm_source=twitter&amp;amp;utm_medium=feed&amp;amp;utm_term=Devops"&gt;Spring One presentation&lt;/a&gt; demonstrates an advanced use-case,  using CDC-debezium and Machine Learning to build a streaming data pipeline for credit card fraud detection.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="https://github.com/spring-cloud/stream-applications/blob/gh-pages/img/cdc-analytics/cdc-fraud-detection.png?raw=true" alt="cdc fraud detection" width="50%"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We still have a few more episodes coming up in this blog series. Please stay tuned.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
</feed>
